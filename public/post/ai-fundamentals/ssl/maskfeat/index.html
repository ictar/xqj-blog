

<!DOCTYPE html>
<html lang="en" itemscope itemtype="http://schema.org/WebPage">
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0">

 


      <title>MaskFeat: Masked Feature Prediction for Self-Supervised Visual Pre-Training - </title>

  <meta name="description" content="Predict handcrafted features (e.g., HOG) of masked regions instead of raw pixels.">
  <meta name="author" content="Qiongjie.X"/><script type="application/ld+json">
{
    "@context": "http://schema.org",
    "@type": "WebSite",
    "name": "Qiongjie\u0027s Notes",
    
    "url": "http:\/\/localhost:1313\/"
}
</script><script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "Organization",
  "name": "",
  "url": "http:\/\/localhost:1313\/"
  
  
  
  
}
</script>
<script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [{
        "@type": "ListItem",
        "position": 1,
        "item": {
          "@id": "http:\/\/localhost:1313\/",
          "name": "home"
        }
    },{
        "@type": "ListItem",
        "position": 3,
        "item": {
          "@id": "http:\/\/localhost:1313\/post\/ai-fundamentals\/ssl\/maskfeat\/",
          "name": "Mask feat masked feature prediction for self supervised visual pre training"
        }
    }]
}
</script><script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "Article",
  "author": {
    "name" : "Qiongjie.X"
  },
  "headline": "MaskFeat: Masked Feature Prediction for Self-Supervised Visual Pre-Training",
  "description" : "Predict handcrafted features (e.g., HOG) of masked regions instead of raw pixels.",
  "inLanguage" : "en",
  "wordCount":  1026 ,
  "datePublished" : "2025-10-09T00:00:00\u002b00:00",
  "dateModified" : "2025-10-09T00:00:00\u002b00:00",
  "image" : "http:\/\/localhost:1313\/img\/avatar-icon.png",
  "keywords" : [ "SSL, Vision, Representation Learning, Masked Image Modeling" ],
  "mainEntityOfPage" : "http:\/\/localhost:1313\/post\/ai-fundamentals\/ssl\/maskfeat\/",
  "publisher" : {
    "@type": "Organization",
    "name" : "http:\/\/localhost:1313\/",
    "logo" : {
        "@type" : "ImageObject",
        "url" : "http:\/\/localhost:1313\/img\/avatar-icon.png",
        "height" :  60 ,
        "width" :  60
    }
  }
}
</script>


<meta property="og:title" content="MaskFeat: Masked Feature Prediction for Self-Supervised Visual Pre-Training" />
<meta property="og:description" content="Predict handcrafted features (e.g., HOG) of masked regions instead of raw pixels.">
<meta property="og:image" content="http://localhost:1313/img/avatar-icon.png" />
<meta property="og:url" content="http://localhost:1313/post/ai-fundamentals/ssl/maskfeat/" />
<meta property="og:type" content="website" />
<meta property="og:site_name" content="Qiongjie&#39;s Notes" />

  <meta name="twitter:title" content="MaskFeat: Masked Feature Prediction for Self-Supervised Visual ‚Ä¶" />
  <meta name="twitter:description" content="Predict handcrafted features (e.g., HOG) of masked regions instead of raw pixels.">
  <meta name="twitter:image" content="http://localhost:1313/img/avatar-icon.png" />
  <meta name="twitter:card" content="summary_large_image" />
  <link href='http://localhost:1313/img/favicon.ico' rel='icon' type='image/x-icon'/>
  <meta name="generator" content="Hugo 0.147.4">
  <link rel="alternate" href="http://localhost:1313/index.xml" type="application/rss+xml" title="Qiongjie&#39;s Notes"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/katex.min.css" integrity="sha384-3UiQGuEI4TTMaFmGIZumfRPtfKQ3trwQE2JgosJxCnGmQpL/lJdjpcHkaaFwHlcI" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.6.0/css/all.css" integrity="sha384-h/hnnw1Bi4nbpD6kE7nYfCXzovi622sY5WBxww8ARKwpdLj5kUWjRuyiXaD1U2JT" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@3.4.1/dist/css/bootstrap.min.css" integrity="sha384-HSMxcRTRxnN+Bdg0JdbxYKrThecOKuH5zCYotlSAcp1+c8xmyTe9GYg1l9a69psu" crossorigin="anonymous"><link rel="stylesheet" href="http://localhost:1313/css/main.css" /><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" />
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" /><link rel="stylesheet" href="http://localhost:1313/css/syntax.css" /><link rel="stylesheet" href="http://localhost:1313/css/codeblock.css" /><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.css" integrity="sha384-h/L2W9KefUClHWaty3SLE5F/qvc4djlyR4qY3NUV5HGQBBW7stbcfff1+I/vmsHh" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/default-skin/default-skin.min.css" integrity="sha384-iD0dNku6PYSIQLyfTOpB06F2KCZJAKLOThS5HRe8b3ibhdEQ6eKsFf/EeFxdOt5R" crossorigin="anonymous">



<link
  rel="stylesheet"
  href="https://unpkg.com/leaflet@1.9.4/dist/leaflet.css"
  crossorigin="anonymous"
/>
<link rel="stylesheet" href="http://localhost:1313/css/custom.css">

<script
  src="https://unpkg.com/leaflet@1.9.4/dist/leaflet.js"
  crossorigin="anonymous"
></script>

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js"></script>


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">


<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
  onload="renderMathInElement(document.body, {
    delimiters: [
      {left: '$$', right: '$$', display: true},
      {left: '$', right: '$', display: false}
    ]
  });"></script>

  </head>
  <body>
    <nav class="navbar navbar-default navbar-fixed-top navbar-custom">
  <div class="container-fluid">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#main-navbar">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="http://localhost:1313/">Qiongjie&#39;s Notes</a>
    </div>

    <div class="collapse navbar-collapse" id="main-navbar">
      <ul class="nav navbar-nav navbar-right">
        
          
            <li>
              <a title="PROJECT" href="/">PROJECT</a>
            </li>
          
        
          
            <li>
              <a title="NOTE" href="/notes">NOTE</a>
            </li>
          
        
          
            <li>
              <a title="TAG" href="/tags">TAG</a>
            </li>
          
        
          
            <li>
              <a title="ABOUT ME" href="/page/about/">ABOUT ME</a>
            </li>
          
        
          
            <li class="navlinks-container">
              <a class="navlinks-parent" role="button" tabindex="0">post</a>
              <div class="navlinks-children">
                
                  <a href="/post/python-geodata">Remote Sensing with Python</a>
                
                  <a href="/post/mcmc-statics">Monte Carlo‚ÄìMarkov Chains Statistical Methods</a>
                
                  <a href="/post/ai-fundamentals">AI Fundamentals</a>
                
              </div>
            </li>
          
        

        
          
            <li>
              
            </li>
          
        

        
      </ul>
    </div>

    
      <div class="avatar-container">
        <div class="avatar-img-border">
          <a title="Qiongjie&#39;s Notes" href="http://localhost:1313/">
            <img class="avatar-img" src="http://localhost:1313/img/avatar-icon.png" alt="Qiongjie&#39;s Notes" />
           
          </a>
        </div>
      </div>
    

  </div>
</nav>




    


<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

<div class="pswp__bg"></div>

<div class="pswp__scroll-wrap">
    
    <div class="pswp__container">
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
    </div>
    
    <div class="pswp__ui pswp__ui--hidden">
    <div class="pswp__top-bar">
      
      <div class="pswp__counter"></div>
      <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
      <button class="pswp__button pswp__button--share" title="Share"></button>
      <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
      <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
      
      
      <div class="pswp__preloader">
        <div class="pswp__preloader__icn">
          <div class="pswp__preloader__cut">
            <div class="pswp__preloader__donut"></div>
          </div>
        </div>
      </div>
    </div>
    <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
      <div class="pswp__share-tooltip"></div>
    </div>
    <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
    </button>
    <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
    </button>
    <div class="pswp__caption">
      <div class="pswp__caption__center"></div>
    </div>
    </div>
    </div>
</div>


  
  
  






  

  <header class="header-section ">
    
    
    <div class="intro-header no-img">
      <div class="container">
        <div class="row">
          <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
            <div class="post-heading">
              
                <h1>MaskFeat: Masked Feature Prediction for Self-Supervised Visual Pre-Training</h1>
              
              
              
              
                <span class="post-meta">
  
  
  <i class="fas fa-calendar"></i>&nbsp;Posted on October 9, 2025
  
  
  
    &nbsp;|&nbsp;<i class="fas fa-book"></i>&nbsp;1026&nbsp;words
  
  
  
</span>


              
            </div>
          </div>
        </div>
      </div>
    </div>
  
  </header>


    
<div class="container" role="main">
  <div class="row">
    <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
      <article role="main" class="blog-post">
        <div class="model-card">
<h3 id="-model-name">üè∑Ô∏è Model Name</h3>
<p><strong>MaskFeat ‚Äì Masked Feature Prediction for Self-Supervised Visual Pre-Training</strong></p>
<h2 id="-core-idea">üß† Core Idea</h2>
<blockquote>
<p>Predict handcrafted features (e.g., <a href="https://en.wikipedia.org/wiki/Histogram_of_oriented_gradients">HOG</a>) of masked regions instead of raw pixels.</p></blockquote>
<h2 id="-architecture">üñºÔ∏è Architecture</h2>
<p><img src="" alt="MaskFeat architecture"></p>
<p>Pseudocode of MaskFeat:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-py" data-lang="py"><span style="display:flex;"><span><span style="color:#75715e"># simplified MaskFeat pseudocode</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> batch <span style="color:#f92672">in</span> loader:               <span style="color:#75715e"># video clips or image patches</span>
</span></span><span style="display:flex;"><span>    tokens <span style="color:#f92672">=</span> patchify(batch)       <span style="color:#75715e"># shape: (B, T, H, W, C)-&gt;tokens</span>
</span></span><span style="display:flex;"><span>    mask <span style="color:#f92672">=</span> sample_mask(tokens, ratio<span style="color:#f92672">=</span><span style="color:#ae81ff">0.4</span>, blockwise<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>)  <span style="color:#75715e"># cube/block masking</span>
</span></span><span style="display:flex;"><span>    masked_tokens <span style="color:#f92672">=</span> replace_with_mask_token(tokens, mask)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># forward</span>
</span></span><span style="display:flex;"><span>    outputs <span style="color:#f92672">=</span> vision_transformer(masked_tokens)   <span style="color:#75715e"># outputs for all token positions</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># compute targets from original (unmasked) inputs</span>
</span></span><span style="display:flex;"><span>    target_features <span style="color:#f92672">=</span> compute_target_features(original_batch)  <span style="color:#75715e"># e.g., HOG per patch</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># take outputs only at masked positions &amp; compute regression loss</span>
</span></span><span style="display:flex;"><span>    pred <span style="color:#f92672">=</span> project_to_target_dim(outputs[mask_positions])
</span></span><span style="display:flex;"><span>    loss <span style="color:#f92672">=</span> L2(pred, target_features[mask_positions])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>    loss<span style="color:#f92672">.</span>backward(); optimizer<span style="color:#f92672">.</span>step()
</span></span></code></pre></div><h3 id="1-input-preparation-and-tokenization">1Ô∏è‚É£ Input Preparation and Tokenization</h3>
<p>The input is a <strong>video</strong> (or an image, which is treated as a video with a single frame).</p>
<ul>
<li>The video is initially divided into <strong>regular space-time cubes</strong>.</li>
<li>These cubes are then projected (e.g., via convolution) to form a sequence of <strong>tokens</strong>.</li>
</ul>
<h3 id="2-masking">2Ô∏è‚É£ Masking</h3>
<ol>
<li>A portion of these input tokens (representing space-time cubes) is <strong>randomly masked out</strong>.</li>
<li>The masked tokens are replaced with a <strong>[MASK] token</strong>, which is a shared, learnable embedding indicating the masked regions.
<ul>
<li>For spatiotemporal video data, <strong>cube masking</strong> is used, involving sampling random cubes that include both spatial and temporal blocks. MaskFeat commonly uses a <strong>40% masking rati</strong>o.</li>
</ul>
</li>
</ol>
<h3 id="3-encoder-processing-transformer-backbone">3Ô∏è‚É£ Encoder Processing (Transformer Backbone)</h3>
<p>The sequence of tokens, including the encoded visible patches and the [MASK] tokens, is input to a <text style="color:purple">Vision Transformer (ViT)</text> backbone.</p>
<ul>
<li>Positional embeddings are added to the token sequence before processing by the Transformer.</li>
<li>The Transformer backbone processes this masked space-time input.</li>
</ul>
<h3 id="4-prediction-head">4Ô∏è‚É£ Prediction Head</h3>
<p>The output tokens from the Transformer backbone corresponding to the masked cubes are passed through <text style="color:purple">a linear layer</text>.</p>
<ul>
<li>This linear layer projects the tokens into the prediction space, where the number of output channels is adjusted to match the dimensionality of the specific target feature being predicted.</li>
</ul>
<h3 id="5-target-feature-generation">5Ô∏è‚É£ Target Feature Generation</h3>
<p>The <text style="color:green">prediction target</text> is a feature extracted from the corresponding region of the original, intact sample. This feature serves as the supervision.</p>
<ul>
<li>MaskFeat typically uses <text style="color:purple">Histograms of Oriented Gradients (HOG)</text>, a hand-crafted feature descriptor, as the effective target feature.</li>
<li>For video input, the prediction target for a masked space-time cube is typically the <strong>HOG feature of the 2-D spatial patch temporally centered within that cube</strong>.</li>
</ul>
<h3 id="6-loss-calculation-and-optimization">6Ô∏è‚É£ Loss Calculation and Optimization</h3>
<p>The model is trained to minimize the difference between the predicted feature and the target feature.</p>
<ul>
<li>The loss function (a regression loss, e.g., mean squared error) is computed <strong>only on the masked cubes</strong>.</li>
<li>The model&rsquo;s weights (the Transformer backbone) are optimized to minimize this loss.</li>
</ul>
<h3 id="-post-training-usage">üéâ Post-training Usage</h3>
<p>After pre-training is complete, the <strong>Transformer (encoder) is fine-tuned</strong> on downstream tasks (such as video classification or action detection).</p>
<h2 id="-downstream-tasks">üéØ Downstream Tasks</h2>
<ul>
<li><strong>Video Recognition/Classification</strong> (Kinetics Datasets)</li>
<li><strong>Action Detection</strong>: This task involves spatio-temporal localization of human actions</li>
<li><strong>Human-Object Interaction Classification</strong>: This task requires fine-grained motion distinctions and temporal modeling</li>
<li><strong>Image Recognition/Classification</strong>: MaskFeat can be generalized to the image domain, treating an image as a video with a single frame</li>
</ul>
<h2 id="-strengths">üí° Strengths</h2>
<ul>
<li>Architectural Simplicity and Efficiency
<ul>
<li>The approach is <strong>conceptually and practically simple</strong>.</li>
<li>It typically uses a **single network with a single view **of each sample, unlike contrastive methods which require a Siamese structure and multiple views.</li>
<li>When using Histograms of Oriented Gradients (HOG) as the target feature, the method is efficient and does not rely on an external model. This avoids the need for an extra pre-training stage (such as dVAE tokenization used by BEiT) and the resulting computational overhead.</li>
<li>HOG calculation itself is cheap and introduces negligible computational overhead.</li>
</ul>
</li>
<li>Performance and Scalability
<ul>
<li>MaskFeat learns abundant visual knowledge.</li>
<li>It is <strong>scalable to large models</strong> for both video and image domains. Larger models benefit significantly more from longer pre-training schedules, indicating the scalability of the MaskFeat task to high-capacity models (e.g., MViT-L vs. MViT-S).</li>
<li>For video understanding, MaskFeat has been shown to close the large performance gap (over 5% accuracy) between supervised pre-training on massive image datasets (like IN-21K) and models trained solely on unlabeled videos.</li>
<li>It achieves unprecedented results on video benchmarks such as Kinetics, AVA (Action detection), and SSv2 (Human-object interaction classification).</li>
<li>The strong performance on localization-sensitive tasks like AVA suggests a clear advantage of masked modeling on video over supervised image pre-training.</li>
<li>It successfully uses continuous feature regression (like HOG) as a target, demonstrating that discretization (tokenization) of visual signals is not necessary for effective masked visual prediction.</li>
<li>The method is effective when coupled with the end-to-end fine-tuning protocol, maximizing final model performance for downstream tasks.</li>
</ul>
</li>
<li>Robustness and Flexibility
<ul>
<li>MaskFeat generally works fairly well with minimal augmentation, and stronger augmentations (like RandAugment or color jittering) sometimes degrade results.</li>
<li>In the video domain, MaskFeat is robust across a wide range of masking ratios (from 40% up to 80%).</li>
<li>HOG is a particularly effective target feature because its implementation uses local contrast normalization, which is essential for good results and provides invariance to photometric changes.</li>
</ul>
</li>
</ul>
<h2 id="-limitations">‚ö†Ô∏è Limitations</h2>
<ul>
<li>Feature Properties (Linear Separability)
<ul>
<li>The representations learned by MaskFeat tend to be <strong>less linearly separable</strong>.</li>
<li>Linear probing results, a common metric for evaluating self-supervised methods, lag significantly behind contrastive learning methods like MoCo v3.</li>
<li>MaskFeat learns good visual knowledge revealed by fine-tuning but <strong>does not learn linearly separable features</strong>.</li>
</ul>
</li>
<li>Architectural Constraints and Performance Trade-offs
<ul>
<li>Masked Image Modeling (MIM) approaches generally require a ViT backbone.</li>
<li>MIM approaches are often deemed weaker for abstract (higher-level) tasks such as classification compared to Joint Embedding methods.</li>
<li>In the image domain, <strong>optimal masking ratios are sensitive</strong>: accuracy degrades when masking out too high a percentage of patches (e.g., above 40% with block-wise masking in ViT-B image pre-training).</li>
</ul>
</li>
<li>Dependence on Target Feature Choice
<ul>
<li>The performance critically depends on selecting an appropriate prediction target (e.g., HOG). Prediction targets utilizing human annotations, such as supervised features (from ResNet or ViT) or pseudo-labels, yield poor results and lead to overfitting.</li>
<li>When attempting multi-task learning by combining targets (e.g., pixel color and HOG), the objectives may conflict, resulting in lower performance compared to using HOG alone. Pixel targets specifically introduce ambiguities related to color and texture.</li>
</ul>
</li>
</ul>
<h2 id="-reference">üìö Reference</h2>
<ul>
<li><em>Wei et al., 2022</em>  <em>[Masked Feature Prediction for Self-Supervised Visual Pre-Training]</em>  üîó <a href="https://arxiv.org/abs/2112.09133">arXiv:2112.09133</a></li>
</ul>
</div>


        
          <div class="blog-tags">
            
              
              <a href="http://localhost:1313/tags/ssl/">SSL</a>&nbsp;
            
              
              <a href="http://localhost:1313/tags/vision/">Vision</a>&nbsp;
            
              
              <a href="http://localhost:1313/tags/representation-learning/">Representation Learning</a>&nbsp;
            
              
              <a href="http://localhost:1313/tags/masked-image-modeling/">Masked Image Modeling</a>&nbsp;
            
          </div>
        

        
            <hr/>
            <section id="social-share">
              <div class="list-inline footer-links">
                

<div class="share-box" aria-hidden="true">
    <ul class="share">
      
      <li>
        <a href="//twitter.com/share?url=http%3a%2f%2flocalhost%3a1313%2fpost%2fai-fundamentals%2fssl%2fmaskfeat%2f&amp;text=MaskFeat%3a%20Masked%20Feature%20Prediction%20for%20Self-Supervised%20Visual%20Pre-Training&amp;via=" target="_blank" title="Share on Twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
  
      
      <li>
        <a href="//www.facebook.com/sharer/sharer.php?u=http%3a%2f%2flocalhost%3a1313%2fpost%2fai-fundamentals%2fssl%2fmaskfeat%2f" target="_blank" title="Share on Facebook">
          <i class="fab fa-facebook"></i>
        </a>
      </li>
  
      
      <li>
        <a href="//reddit.com/submit?url=http%3a%2f%2flocalhost%3a1313%2fpost%2fai-fundamentals%2fssl%2fmaskfeat%2f&amp;title=MaskFeat%3a%20Masked%20Feature%20Prediction%20for%20Self-Supervised%20Visual%20Pre-Training" target="_blank" title="Share on Reddit">
          <i class="fab fa-reddit"></i>
        </a>
      </li>
  
      
      <li>
        <a href="//www.linkedin.com/shareArticle?url=http%3a%2f%2flocalhost%3a1313%2fpost%2fai-fundamentals%2fssl%2fmaskfeat%2f&amp;title=MaskFeat%3a%20Masked%20Feature%20Prediction%20for%20Self-Supervised%20Visual%20Pre-Training" target="_blank" title="Share on LinkedIn">
          <i class="fab fa-linkedin"></i>
        </a>
      </li>
  
      
      <li>
        <a href="//www.stumbleupon.com/submit?url=http%3a%2f%2flocalhost%3a1313%2fpost%2fai-fundamentals%2fssl%2fmaskfeat%2f&amp;title=MaskFeat%3a%20Masked%20Feature%20Prediction%20for%20Self-Supervised%20Visual%20Pre-Training" target="_blank" title="Share on StumbleUpon">
          <i class="fab fa-stumbleupon"></i>
        </a>
      </li>
  
      
      <li>
        <a href="//www.pinterest.com/pin/create/button/?url=http%3a%2f%2flocalhost%3a1313%2fpost%2fai-fundamentals%2fssl%2fmaskfeat%2f&amp;description=MaskFeat%3a%20Masked%20Feature%20Prediction%20for%20Self-Supervised%20Visual%20Pre-Training" target="_blank" title="Share on Pinterest">
          <i class="fab fa-pinterest"></i>
        </a>
      </li>
    </ul>
  </div>
  

              </div>
            </section>
        

        
          
            
          

          
                  <h4 class="see-also">See also</h4>
                  <ul>
                
                
                    <li><a href="/post/ai-fundamentals/ssl/byol/">BYOL: Bootstrap Your Own Latent</a></li>
                
                    <li><a href="/post/ai-fundamentals/ssl/dino/">DINO: Self-Distillation with No Labels</a></li>
                
                    <li><a href="/post/ai-fundamentals/ssl/mae/">MAE: Masked Autoencoders Are Scalable Vision Learners</a></li>
                
                    <li><a href="/post/ai-fundamentals/ssl/swav/">SwAV: Swapping Assignments between Views</a></li>
                
                    <li><a href="/post/ai-fundamentals/ssl/moco/">MoCo: Momentum Contrast for Unsupervised Visual Representation Learning</a></li>
                
              </ul>

          
        
      </article>

      
        <ul class="pager blog-pager">
          
            <li class="previous">
              <a href="http://localhost:1313/post/ai-fundamentals/ssl/byol/" data-toggle="tooltip" data-placement="top" title="BYOL: Bootstrap Your Own Latent">&larr; Previous Post</a>
            </li>
          
          
        </ul>
      


      

    </div>
  </div>
</div>

      <footer>
  <div class="container">
    
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <ul class="list-inline text-center footer-links">
          
              <li>
		
		  <a href="mailto:ele.qiong@gmail.com" title="Email me">
		
                  <span class="fa-stack fa-lg">
                    <i class="fas fa-circle fa-stack-2x"></i>
                    <i class="fas fa-envelope fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
              <li>
		
		  <a href="https://github.com/ictar" title="GitHub">
		
                  <span class="fa-stack fa-lg">
                    <i class="fas fa-circle fa-stack-2x"></i>
                    <i class="fab fa-github fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
              <li>
		
		  <a href="https://linkedin.com/in/qiongjie-xu" title="LinkedIn">
		
                  <span class="fa-stack fa-lg">
                    <i class="fas fa-circle fa-stack-2x"></i>
                    <i class="fab fa-linkedin fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
          
          
          
        </ul>
        <p class="credits copyright text-muted">
          
            
              <a href="https://www.xuqiongjie.com">Qiongjie.X</a>
            
          

          &nbsp;&bull;&nbsp;&copy;
          
            2025
          

          
            &nbsp;&bull;&nbsp;
            <a href="http://localhost:1313/">Qiongjie&#39;s Notes</a>
          
        </p>
        
        <p class="credits theme-by text-muted">
          <a href="https://gohugo.io">Hugo v0.147.4</a> powered &nbsp;&bull;&nbsp; Theme <a href="https://github.com/halogenica/beautifulhugo">Beautiful Hugo</a> adapted from <a href="https://deanattali.com/beautiful-jekyll/">Beautiful Jekyll</a>
          
        </p>
      </div>
    </div>
  </div>
</footer><script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/katex.min.js" integrity="sha384-G0zcxDFp5LWZtDuRMnBkk3EphCK1lhEf4UEyEM693ka574TZGwo4IWwS6QLzM/2t" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>
<script src="https://code.jquery.com/jquery-3.7.0.slim.min.js" integrity="sha384-w5y/xIeYixWvfM+A1cEbmHPURnvyqmVg5eVENruEdDjcyRLUSNej7512JQGspFUr" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@3.4.1/dist/js/bootstrap.min.js" integrity="sha384-aJ21OjlMXNL5UyIl/XNwTMqvzeRMZH2w8c5cRVpzpU8Y5bApTppSuUkhZXN0VxHd" crossorigin="anonymous"></script>

<script src="http://localhost:1313/js/main.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.js" integrity="sha384-QELNnmcmU8IR9ZAykt67vGr9/rZJdHbiWi64V88fCPaOohUlHCqUD/unNN0BXSqy" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe-ui-default.min.js" integrity="sha384-m67o7SkQ1ALzKZIFh4CiTA8tmadaujiTa9Vu+nqPSwDOqHrDmxLezTdFln8077+q" crossorigin="anonymous"></script><script src="http://localhost:1313/js/load-photoswipe.js"></script>










    
  </body>
</html>

