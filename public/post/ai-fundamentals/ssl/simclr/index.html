

<!DOCTYPE html>
<html lang="en" itemscope itemtype="http://schema.org/WebPage">
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0">

 


      <title>SimCLR: A Simple Framework for Contrastive Learning of Visual Representations - </title>

  <meta name="description" content="Learn invariant representations by maximizing similarity between augmented views of the same image while contrasting with others.">
  <meta name="author" content="Qiongjie.X"/><script type="application/ld+json">
{
    "@context": "http://schema.org",
    "@type": "WebSite",
    "name": "Qiongjie\u0027s Notes",
    
    "url": "http:\/\/localhost:1313\/"
}
</script><script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "Organization",
  "name": "",
  "url": "http:\/\/localhost:1313\/"
  
  
  
  
}
</script>
<script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [{
        "@type": "ListItem",
        "position": 1,
        "item": {
          "@id": "http:\/\/localhost:1313\/",
          "name": "home"
        }
    },{
        "@type": "ListItem",
        "position": 3,
        "item": {
          "@id": "http:\/\/localhost:1313\/post\/ai-fundamentals\/ssl\/simclr\/",
          "name": "Sim clr a simple framework for contrastive learning of visual representations"
        }
    }]
}
</script><script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "Article",
  "author": {
    "name" : "Qiongjie.X"
  },
  "headline": "SimCLR: A Simple Framework for Contrastive Learning of Visual Representations",
  "description" : "Learn invariant representations by maximizing similarity between augmented views of the same image while contrasting with others.",
  "inLanguage" : "en",
  "wordCount":  1029 ,
  "datePublished" : "2025-10-07T00:00:00\u002b00:00",
  "dateModified" : "2025-10-07T00:00:00\u002b00:00",
  "image" : "http:\/\/localhost:1313\/img\/avatar-icon.png",
  "keywords" : [ "SSL, Vision, Representation Learning, Joint Embedding, Contrastive Methods" ],
  "mainEntityOfPage" : "http:\/\/localhost:1313\/post\/ai-fundamentals\/ssl\/simclr\/",
  "publisher" : {
    "@type": "Organization",
    "name" : "http:\/\/localhost:1313\/",
    "logo" : {
        "@type" : "ImageObject",
        "url" : "http:\/\/localhost:1313\/img\/avatar-icon.png",
        "height" :  60 ,
        "width" :  60
    }
  }
}
</script>


<meta property="og:title" content="SimCLR: A Simple Framework for Contrastive Learning of Visual Representations" />
<meta property="og:description" content="Learn invariant representations by maximizing similarity between augmented views of the same image while contrasting with others.">
<meta property="og:image" content="http://localhost:1313/img/avatar-icon.png" />
<meta property="og:url" content="http://localhost:1313/post/ai-fundamentals/ssl/simclr/" />
<meta property="og:type" content="website" />
<meta property="og:site_name" content="Qiongjie&#39;s Notes" />

  <meta name="twitter:title" content="SimCLR: A Simple Framework for Contrastive Learning of Visual â€¦" />
  <meta name="twitter:description" content="Learn invariant representations by maximizing similarity between augmented views of the same image while contrasting with others.">
  <meta name="twitter:image" content="http://localhost:1313/img/avatar-icon.png" />
  <meta name="twitter:card" content="summary_large_image" />
  <link href='http://localhost:1313/img/favicon.ico' rel='icon' type='image/x-icon'/>
  <meta name="generator" content="Hugo 0.147.4">
  <link rel="alternate" href="http://localhost:1313/index.xml" type="application/rss+xml" title="Qiongjie&#39;s Notes"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/katex.min.css" integrity="sha384-3UiQGuEI4TTMaFmGIZumfRPtfKQ3trwQE2JgosJxCnGmQpL/lJdjpcHkaaFwHlcI" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.6.0/css/all.css" integrity="sha384-h/hnnw1Bi4nbpD6kE7nYfCXzovi622sY5WBxww8ARKwpdLj5kUWjRuyiXaD1U2JT" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@3.4.1/dist/css/bootstrap.min.css" integrity="sha384-HSMxcRTRxnN+Bdg0JdbxYKrThecOKuH5zCYotlSAcp1+c8xmyTe9GYg1l9a69psu" crossorigin="anonymous"><link rel="stylesheet" href="http://localhost:1313/css/main.css" /><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" />
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" /><link rel="stylesheet" href="http://localhost:1313/css/syntax.css" /><link rel="stylesheet" href="http://localhost:1313/css/codeblock.css" /><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.css" integrity="sha384-h/L2W9KefUClHWaty3SLE5F/qvc4djlyR4qY3NUV5HGQBBW7stbcfff1+I/vmsHh" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/default-skin/default-skin.min.css" integrity="sha384-iD0dNku6PYSIQLyfTOpB06F2KCZJAKLOThS5HRe8b3ibhdEQ6eKsFf/EeFxdOt5R" crossorigin="anonymous">



<link
  rel="stylesheet"
  href="https://unpkg.com/leaflet@1.9.4/dist/leaflet.css"
  crossorigin="anonymous"
/>
<link rel="stylesheet" href="http://localhost:1313/css/custom.css">

<script
  src="https://unpkg.com/leaflet@1.9.4/dist/leaflet.js"
  crossorigin="anonymous"
></script>

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js"></script>


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">


<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
  onload="renderMathInElement(document.body, {
    delimiters: [
      {left: '$$', right: '$$', display: true},
      {left: '$', right: '$', display: false}
    ]
  });"></script>


<link rel="icon" type="image/png" href="http://localhost:1313/img/favicon-96x96.png" sizes="96x96" />
<link rel="icon" type="image/svg+xml" href="http://localhost:1313/img/favicon.svg" />
<link rel="apple-touch-icon" sizes="180x180" href="http://localhost:1313/img/apple-touch-icon.png" />
<link rel="manifest" href="http://localhost:1313/img/site.webmanifest" />

  </head>
  <body>
    <nav class="navbar navbar-default navbar-fixed-top navbar-custom">
  <div class="container-fluid">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#main-navbar">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="http://localhost:1313/">Qiongjie&#39;s Notes</a>
    </div>

    <div class="collapse navbar-collapse" id="main-navbar">
      <ul class="nav navbar-nav navbar-right">
        
          
            <li class="navlinks-container">
              <a class="navlinks-parent" role="button" tabindex="0" href="/post">BLOG</a>
              <div class="navlinks-children">
                
                  <a href="/post/python-geodata">Remote Sensing with Python</a>
                
                  <a href="/post/mcmc-statics">Monte Carloâ€“Markov Chains Statistical Methods</a>
                
                  <a href="/post/ai-fundamentals">AI Fundamentals</a>
                
              </div>
            </li>
          
        
          
            <li class="navlinks-container">
              <a class="navlinks-parent" role="button" tabindex="0" href="/projects">PROJECT</a>
              <div class="navlinks-children">
                
                  <a href="https://ictar.github.io/TerraFlow/">TerraFlow</a>
                
              </div>
            </li>
          
        
          
            <li>
              <a title="NOTE" href="/notes">NOTE</a>
            </li>
          
        
          
            <li>
              <a title="TAG" href="/tags">TAG</a>
            </li>
          
        
          
            <li>
              <a title="ABOUT ME" href="/page/about/">ABOUT ME</a>
            </li>
          
        

        
          
            <li>
              
                
                  <a href="http://localhost:1313/zh-cn/post/ai-fundamentals/ssl/simclr/">CH</a>
                
              
            </li>
          
        

        
      </ul>
    </div>

    
      <div class="avatar-container">
        <div class="avatar-img-border">
          <a title="Qiongjie&#39;s Notes" href="http://localhost:1313/">
            <img class="avatar-img" src="http://localhost:1313/img/avatar-icon.png" alt="Qiongjie&#39;s Notes" />
           
          </a>
        </div>
      </div>
    

  </div>
</nav>




    


<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

<div class="pswp__bg"></div>

<div class="pswp__scroll-wrap">
    
    <div class="pswp__container">
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
    </div>
    
    <div class="pswp__ui pswp__ui--hidden">
    <div class="pswp__top-bar">
      
      <div class="pswp__counter"></div>
      <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
      <button class="pswp__button pswp__button--share" title="Share"></button>
      <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
      <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
      
      
      <div class="pswp__preloader">
        <div class="pswp__preloader__icn">
          <div class="pswp__preloader__cut">
            <div class="pswp__preloader__donut"></div>
          </div>
        </div>
      </div>
    </div>
    <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
      <div class="pswp__share-tooltip"></div>
    </div>
    <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
    </button>
    <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
    </button>
    <div class="pswp__caption">
      <div class="pswp__caption__center"></div>
    </div>
    </div>
    </div>
</div>


  
  
  






  

  <header class="header-section ">
    
    
    <div class="intro-header no-img">
      <div class="container">
        <div class="row">
          <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
            <div class="post-heading">
              
                <h1>SimCLR: A Simple Framework for Contrastive Learning of Visual Representations</h1>
              
              
              
              
                <span class="post-meta">
  
  
  <i class="fas fa-calendar"></i>&nbsp;Posted on October 7, 2025
  
  
  
    &nbsp;|&nbsp;<i class="fas fa-book"></i>&nbsp;1029&nbsp;words
  
  
  &nbsp;&bull;&nbsp;Other languages: <a href="http://localhost:1313/zh-cn/post/ai-fundamentals/ssl/simclr/" lang="zh-cn">CH</a>
</span>


              
            </div>
          </div>
        </div>
      </div>
    </div>
  
  </header>


    
<div class="container" role="main">
  <div class="row">
    <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
      <article role="main" class="blog-post">
        <div class="model-card">
<h2 id="-model-name">ğŸ·ï¸ Model Name</h2>
<p><strong>SimCLR â€“ A Simple Framework for Contrastive Learning of Visual Representations</strong></p>
<h2 id="-core-idea">ğŸ§  Core Idea</h2>
<blockquote>
<p>Learn visual representations by maximizing agreement between differently augmented views of the same data example via a contrastive loss in the latent space, effectively pulling <text style="color: green">positive pairs</text> (two augmented views of the same image) close together while pushing them away from all other images in the batch (<text style="color: green">negatives</text>)</p></blockquote>
<p><img src="https://storage.googleapis.com/gweb-research2023-media/original_images/bf6397fbc50404a2be05c2ff6370ed9a-image4.gif" alt="SimCLR architecture"></p>
<h2 id="-architecture">ğŸ–¼ï¸ Architecture</h2>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-plaintext" data-lang="plaintext"><span style="display:flex;"><span>            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
</span></span><span style="display:flex;"><span>            â”‚          Raw image x        â”‚
</span></span><span style="display:flex;"><span>            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</span></span><span style="display:flex;"><span>                            â”‚
</span></span><span style="display:flex;"><span>         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
</span></span><span style="display:flex;"><span>         â”‚                              â”‚
</span></span><span style="display:flex;"><span> â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
</span></span><span style="display:flex;"><span> â”‚ Data Augmentation1 aug1â”‚   â”‚ Data Augmentation2 aug2â”‚
</span></span><span style="display:flex;"><span> â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</span></span><span style="display:flex;"><span>         â”‚                              â”‚
</span></span><span style="display:flex;"><span>         â–¼                              â–¼
</span></span><span style="display:flex;"><span> Encoder (ResNet) f()            Encoder (ResNet) f()
</span></span><span style="display:flex;"><span>         â”‚                              â”‚
</span></span><span style="display:flex;"><span>         â–¼                              â–¼
</span></span><span style="display:flex;"><span>      Feature hâ‚                    Feature hâ‚‚
</span></span><span style="display:flex;"><span>         â”‚                              â”‚
</span></span><span style="display:flex;"><span>         â–¼                              â–¼
</span></span><span style="display:flex;"><span>Projection Head (MLP) g()      Projection Head (MLP) g()
</span></span><span style="display:flex;"><span>         â”‚                              â”‚
</span></span><span style="display:flex;"><span>         â–¼                              â–¼
</span></span><span style="display:flex;"><span>      Vector zâ‚                        Vector zâ‚‚
</span></span><span style="display:flex;"><span>         â”‚                              â”‚
</span></span><span style="display:flex;"><span>         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
</span></span><span style="display:flex;"><span>                          â–¼
</span></span><span style="display:flex;"><span>                  Contrastive Loss NT-Xent
</span></span></code></pre></div><p>And the pseudocode of SimCLR&rsquo;s main learning algorithm:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-sh" data-lang="sh"><span style="display:flex;"><span>input: batch size N, constant Ï„, structure of f, g, T.
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> sampled minibatch <span style="color:#f92672">{</span>x_k<span style="color:#f92672">}</span>^N_<span style="color:#f92672">{</span>k<span style="color:#f92672">=</span>1<span style="color:#f92672">}</span> <span style="color:#66d9ef">do</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> all kâˆˆ<span style="color:#f92672">{</span>1,...,N<span style="color:#f92672">}</span> <span style="color:#66d9ef">do</span>
</span></span><span style="display:flex;"><span>        draw two augmentation functions tâˆ¼T, tâ€²âˆ¼T
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># the first augmentation</span>
</span></span><span style="display:flex;"><span>        x_<span style="color:#f92672">{</span>2kâˆ’1<span style="color:#f92672">}</span> <span style="color:#f92672">=</span> t<span style="color:#f92672">(</span>x_k<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>        h_<span style="color:#f92672">{</span>2kâˆ’1<span style="color:#f92672">}</span> <span style="color:#f92672">=</span> f<span style="color:#f92672">(</span>x_<span style="color:#f92672">{</span>2kâˆ’1<span style="color:#f92672">})</span> <span style="color:#75715e"># representation</span>
</span></span><span style="display:flex;"><span>        z_<span style="color:#f92672">{</span>2kâˆ’1<span style="color:#f92672">}</span> <span style="color:#f92672">=</span> g<span style="color:#f92672">(</span>h_<span style="color:#f92672">{</span>2kâˆ’1<span style="color:#f92672">})</span> <span style="color:#75715e"># projection</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># the second augmentation</span>
</span></span><span style="display:flex;"><span>        x_<span style="color:#f92672">{</span>2k<span style="color:#f92672">}</span> <span style="color:#f92672">=</span> tâ€²<span style="color:#f92672">(</span>x_k<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>        h_<span style="color:#f92672">{</span>2k<span style="color:#f92672">}</span> <span style="color:#f92672">=</span> f<span style="color:#f92672">(</span>x_<span style="color:#f92672">{</span>2k<span style="color:#f92672">})</span> <span style="color:#75715e"># representation</span>
</span></span><span style="display:flex;"><span>        z_<span style="color:#f92672">{</span>2k<span style="color:#f92672">}</span> <span style="color:#f92672">=</span> g<span style="color:#f92672">(</span>h_<span style="color:#f92672">{</span>2k<span style="color:#f92672">})</span> <span style="color:#75715e"># projection</span>
</span></span><span style="display:flex;"><span>    end <span style="color:#66d9ef">for</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> all iâˆˆ<span style="color:#f92672">{</span>1,...,2N<span style="color:#f92672">}</span> and j âˆˆ<span style="color:#f92672">{</span>1,...,2N<span style="color:#f92672">}</span> <span style="color:#66d9ef">do</span>
</span></span><span style="display:flex;"><span>        s_<span style="color:#f92672">{</span>i,j<span style="color:#f92672">}</span> <span style="color:#f92672">=</span> sim<span style="color:#f92672">(</span>z_i, z_j<span style="color:#f92672">)</span> <span style="color:#75715e"># pairwise similarity</span>
</span></span><span style="display:flex;"><span>    end <span style="color:#66d9ef">for</span>
</span></span><span style="display:flex;"><span>    define â„“<span style="color:#f92672">(</span>i,j<span style="color:#f92672">)</span> as NT-Xent <span style="color:#75715e"># the normalized temperature-scaled cross entropy loss)</span>
</span></span><span style="display:flex;"><span>    L<span style="color:#f92672">=</span>1/<span style="color:#f92672">(</span>2N<span style="color:#f92672">)</span>*sum<span style="color:#f92672">[</span>â„“<span style="color:#f92672">(</span>2kâˆ’1,2k<span style="color:#f92672">)</span> + â„“<span style="color:#f92672">(</span>2k,2kâˆ’1<span style="color:#f92672">)</span> <span style="color:#66d9ef">for</span> k from <span style="color:#ae81ff">1</span> to N<span style="color:#f92672">]</span>
</span></span><span style="display:flex;"><span>    update networks f and g to minimize L
</span></span><span style="display:flex;"><span>end <span style="color:#66d9ef">for</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">return</span> encoder network f<span style="color:#f92672">(</span>Â·<span style="color:#f92672">)</span>, and throw away g<span style="color:#f92672">(</span>Â·<span style="color:#f92672">)</span>
</span></span></code></pre></div><h3 id="1-stochastic-data-augmentation-">1ï¸âƒ£ Stochastic Data Augmentation ($x \rightarrow (\tilde{x}_i, \tilde{x}_j)$)</h3>
<p>Randomly transforms any given input data example ($x$) to generate two correlated views, denoted $\tilde{x}_i$ and $\tilde{x}_j$, which are considered a <strong>positive pair</strong>.</p>
<p>The standard augmentation policy sequentially applies three simple augmentations:</p>
<ul>
<li>Random <strong>cropping</strong> followed by <strong>resizing</strong> back to the original size (which often includes random horizontal flipping).</li>
<li>Random <strong>color distortions</strong> (including color jittering and color dropping). The combination of random crop and color distortion is crucial for good performance.</li>
<li>Random <strong>Gaussian blur</strong>.</li>
</ul>
<h3 id="2-neural-network-base-encoder">2ï¸âƒ£ Neural Network Base Encoder $f(\cdot)$</h3>
<p>The encoder network extracts the representation vectors ($h$) from the augmented data examples. The SimCLR framework allows various network architectures without constraints. The authors typically adopt the commonly used <text style="color: purple">ResNet</text> architecture. The output $h_i = f(\tilde{x}_i)$ is obtained after the average pooling layer.</p>
<h3 id="3-small-neural-network-projection-head">3ï¸âƒ£ Small Neural Network Projection Head $g(\cdot)$</h3>
<p>This component maps the representation $h$ to the space $z$ where the contrastive loss is applied. The use of a learnable nonlinear transformation here substantially improves the quality of the learned representations</p>
<ul>
<li>The authors use a <text style="color: purple">Multi-Layer Perceptron (MLP) with one hidden layer</text> and a <text style="color: purple">ReLU non-linearity</text>: $z_i = g(h_i) = W^{(2)}\sigma(W^{(1)}h_i)$</li>
</ul>
<p>After training is completed, the projection head $g(\cdot)$ is discarded, and the encoder $f(\cdot)$ and representation $h$ are used for downstream tasks.</p>
<h3 id="4-contrastive-loss-function">4ï¸âƒ£ Contrastive Loss Function</h3>
<p>The contrastive prediction task aims to identify $\tilde{x}_j$ (the positive counterpart) within a set of augmented examples ${\tilde{x}_k}$, given $\tilde{x}_i$</p>
<ul>
<li>SimCLR utilizes a minibatch of $N$ examples, generating $2N$ augmented data points. The other $2(N-1)$ augmented examples within the minibatch are treated as <text style="color: green">negative examples</text> for a given positive pair.</li>
<li>The specific loss function used is the <text style="color: purple">Normalized Temperature-scaled Cross Entropy loss (NT-Xent)</text>.
$$
L_{i,j} = -\log \frac{\exp(\text{sim}(z_i, z_j) / \tau)}{\sum_{k=1}^{2N} \mathbf{1}_{[k \neq i]} \exp(\text{sim}(z_i, z_k) / \tau)}
$$
<ul>
<li>$sim(Â·,Â·)$: cosine similarity, which is the dot product between $\ell_2$ normalized vectors $u$ and $v$ (i.e., $\text{sim}(u, v) = u^T v / |u| |v|$)</li>
<li>$\tau$: temperature parameter. Using $\ell_2$ normalization along with an appropriate temperature parameter effectively weights different examples and helps the model learn from hard negatives</li>
</ul>
</li>
</ul>
<h2 id="-downstream-tasks">ğŸ¯ Downstream Tasks</h2>
<p>After the self-supervised pretraining phase is complete, the projection head $g(\cdot)$ is discarded, and the encoder network $f(\cdot)$ and the representation $h$ (the layer before the projection head) are used as the feature extractor for the downstream tasks.</p>
<ul>
<li>Linear Evaluation Protocol</li>
<li>Semi-Supervised Learning</li>
<li>Transfer Learning</li>
</ul>
<h2 id="-strengths">ğŸ’¡ Strengths</h2>
<ul>
<li><strong>Simplicity and Architecture Agnosticism</strong>: SimCLR is a <strong>simple</strong> framework for contrastive learning. It <strong>does not require specialized architectures</strong> or an explicit <strong>memory bank</strong>. The framework allows for various choices of network architecture without constraints, typically adopting the standard <strong>ResNet</strong>.</li>
<li><strong>State-of-the-Art Performance</strong>: By combining its core components, SimCLR considerably outperforms previous methods in self-supervised, semi-supervised, and transfer learning on ImageNet.
<ul>
<li>Its representations achieve <strong>76.5% top-1 accuracy</strong> on linear evaluation, matching the performance of a supervised ResNet-50.</li>
<li>When fine-tuned with only 1% of ImageNet labels, it achieves <strong>85.8% top-5 accuracy</strong>.</li>
</ul>
</li>
<li><strong>Effective Feature Extraction for High-Level Tasks</strong>: SimCLR, as a Joint Embedding method, produces <strong>highly semantic features, which are great for classification tasks</strong>. The representations achieve competitive results in linear probing.</li>
<li><strong>Improved Representation Quality</strong>: The introduction of a <strong>learnable nonlinear projection head</strong> ($g(\cdot)$) substantially improves the quality of the learned representations in the layer before the head ($h$)</li>
</ul>
<h2 id="-limitations">âš ï¸ Limitations</h2>
<ul>
<li><text style="background-color: yellow">Reliance on Large Batch Sizes</text>: Contrastive learning with SimCLR benefits from significantly larger batch sizes (e.g., up to 8192 examples). This <strong>requires a very large batch size</strong> to accumulate sufficient negative examples.</li>
<li><text style="background-color: yellow">High Computational and Training Demand</text>:
<ul>
<li>The framework benefits from longer training compared to its supervised counterpart.</li>
<li>The model benefits more from bigger models (increased depth and width) than supervised learning.</li>
<li>Training with large batch sizes may be unstable using standard optimizers, requiring specialized methods like the LARS optimizer.</li>
</ul>
</li>
<li><text style="background-color: yellow">Need for Architectural/Optimization Specifics</text>:
<ul>
<li>To prevent the model from exploiting local information shortcuts, SimCLR requires specialized techniques like Global Batch Normalization (BN) during distributed training.</li>
<li>Special care is required to handle negative samples/collapse. The use of in-batch negatives can lead to false negatives.</li>
</ul>
</li>
<li><text style="background-color: yellow">Sensitivity to Augmentation Policy</text>: The system requires tuning the augmentations. Specifically, the composition of multiple data augmentation operations is crucial for defining effective predictive tasks and learning good representations.</li>
<li><text style="background-color: yellow">Suboptimal for Low-Level Tasks</text>: SimCLR, being a Joint Embedding model, is not fit for low-level tasks such as denoising or superresolution (compared to Masked Image Modeling approaches).</li>
</ul>
<h2 id="-reference">ğŸ“š Reference</h2>
<ul>
<li><em>Chen et al., 2020</em>  <em>[A Simple Framework for Contrastive Learning of Visual Representations]</em>  ğŸ”— <a href="https://arxiv.org/abs/2002.05709">arXiv:2002.05709</a></li>
<li><em>Chen et al., 2020</em>  <em>[Big Self-Supervised Models are Strong Semi-Supervised Learners]</em> ğŸ”— <a href="https://arxiv.org/abs/2006.10029">arXiv:2006.10029</a></li>
<li><a href="https://github.com/google-research/simclr">Github: SimCLR - A Simple Framework for Contrastive Learning of Visual Representations</a></li>
<li><a href="https://research.google/blog/advancing-self-supervised-and-semi-supervised-learning-with-simclr/">Google Research Blog: Advancing Self-Supervised and Semi-Supervised Learning with SimCLR</a></li>
</ul>
</div>


        
          <div class="blog-tags">
            
              
              <a href="http://localhost:1313/tags/ssl/">SSL</a>&nbsp;
            
              
              <a href="http://localhost:1313/tags/vision/">Vision</a>&nbsp;
            
              
              <a href="http://localhost:1313/tags/representation-learning/">Representation Learning</a>&nbsp;
            
              
              <a href="http://localhost:1313/tags/joint-embedding/">Joint Embedding</a>&nbsp;
            
              
              <a href="http://localhost:1313/tags/contrastive-methods/">Contrastive Methods</a>&nbsp;
            
          </div>
        

        
            <hr/>
            <section id="social-share">
              <div class="list-inline footer-links">
                

<div class="share-box" aria-hidden="true">
    <ul class="share">
      
      <li>
        <a href="//twitter.com/share?url=http%3a%2f%2flocalhost%3a1313%2fpost%2fai-fundamentals%2fssl%2fsimclr%2f&amp;text=SimCLR%3a%20A%20Simple%20Framework%20for%20Contrastive%20Learning%20of%20Visual%20Representations&amp;via=" target="_blank" title="Share on Twitter">
          <i class="fab fa-twitter"></i>
        </a>
      </li>
  
      
      <li>
        <a href="//www.facebook.com/sharer/sharer.php?u=http%3a%2f%2flocalhost%3a1313%2fpost%2fai-fundamentals%2fssl%2fsimclr%2f" target="_blank" title="Share on Facebook">
          <i class="fab fa-facebook"></i>
        </a>
      </li>
  
      
      <li>
        <a href="//reddit.com/submit?url=http%3a%2f%2flocalhost%3a1313%2fpost%2fai-fundamentals%2fssl%2fsimclr%2f&amp;title=SimCLR%3a%20A%20Simple%20Framework%20for%20Contrastive%20Learning%20of%20Visual%20Representations" target="_blank" title="Share on Reddit">
          <i class="fab fa-reddit"></i>
        </a>
      </li>
  
      
      <li>
        <a href="//www.linkedin.com/shareArticle?url=http%3a%2f%2flocalhost%3a1313%2fpost%2fai-fundamentals%2fssl%2fsimclr%2f&amp;title=SimCLR%3a%20A%20Simple%20Framework%20for%20Contrastive%20Learning%20of%20Visual%20Representations" target="_blank" title="Share on LinkedIn">
          <i class="fab fa-linkedin"></i>
        </a>
      </li>
  
      
      <li>
        <a href="//www.stumbleupon.com/submit?url=http%3a%2f%2flocalhost%3a1313%2fpost%2fai-fundamentals%2fssl%2fsimclr%2f&amp;title=SimCLR%3a%20A%20Simple%20Framework%20for%20Contrastive%20Learning%20of%20Visual%20Representations" target="_blank" title="Share on StumbleUpon">
          <i class="fab fa-stumbleupon"></i>
        </a>
      </li>
  
      
      <li>
        <a href="//www.pinterest.com/pin/create/button/?url=http%3a%2f%2flocalhost%3a1313%2fpost%2fai-fundamentals%2fssl%2fsimclr%2f&amp;description=SimCLR%3a%20A%20Simple%20Framework%20for%20Contrastive%20Learning%20of%20Visual%20Representations" target="_blank" title="Share on Pinterest">
          <i class="fab fa-pinterest"></i>
        </a>
      </li>
    </ul>
  </div>
  

              </div>
            </section>
        

        
          
            
          

          
                  <h4 class="see-also">See also</h4>
                  <ul>
                
                
                    <li><a href="/post/ai-fundamentals/ssl/i-jepa/">I-JEPA: Image-based Joint Embedding Predictive Architecture</a></li>
                
                    <li><a href="/post/ai-fundamentals/ssl/maskfeat/">MaskFeat: Masked Feature Prediction for Self-Supervised Visual Pre-Training</a></li>
                
                    <li><a href="/post/ai-fundamentals/ssl/byol/">BYOL: Bootstrap Your Own Latent</a></li>
                
                    <li><a href="/post/ai-fundamentals/ssl/dino/">DINO: Self-Distillation with No Labels</a></li>
                
                    <li><a href="/post/ai-fundamentals/ssl/mae/">MAE: Masked Autoencoders Are Scalable Vision Learners</a></li>
                
              </ul>

          
        
      </article>

      
        <ul class="pager blog-pager">
          
          
            <li class="next">
              <a href="http://localhost:1313/post/ai-fundamentals/ssl/moco/" data-toggle="tooltip" data-placement="top" title="MoCo: Momentum Contrast for Unsupervised Visual Representation Learning">Next Post &rarr;</a>
            </li>
          
        </ul>
      


      

    </div>
  </div>
</div>

      <footer>
  <div class="container">
    
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <ul class="list-inline text-center footer-links">
          
              <li>
		
		  <a href="mailto:ele.qiong@gmail.com" title="Email me">
		
                  <span class="fa-stack fa-lg">
                    <i class="fas fa-circle fa-stack-2x"></i>
                    <i class="fas fa-envelope fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
              <li>
		
		  <a href="https://github.com/ictar" title="GitHub">
		
                  <span class="fa-stack fa-lg">
                    <i class="fas fa-circle fa-stack-2x"></i>
                    <i class="fab fa-github fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
              <li>
		
		  <a href="https://linkedin.com/in/qiongjie-xu" title="LinkedIn">
		
                  <span class="fa-stack fa-lg">
                    <i class="fas fa-circle fa-stack-2x"></i>
                    <i class="fab fa-linkedin fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
          
          
          
        </ul>
        <p class="credits copyright text-muted">
          
            
              <a href="https://www.xuqiongjie.com">Qiongjie.X</a>
            
          

          &nbsp;&bull;&nbsp;&copy;
          
            2025
          

          
            &nbsp;&bull;&nbsp;
            <a href="http://localhost:1313/">Qiongjie&#39;s Notes</a>
          
        </p>
        
        <p class="credits theme-by text-muted">
          <a href="https://gohugo.io">Hugo v0.147.4</a> powered &nbsp;&bull;&nbsp; Theme <a href="https://github.com/halogenica/beautifulhugo">Beautiful Hugo</a> adapted from <a href="https://deanattali.com/beautiful-jekyll/">Beautiful Jekyll</a>
          
        </p>
      </div>
    </div>
  </div>
</footer><script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/katex.min.js" integrity="sha384-G0zcxDFp5LWZtDuRMnBkk3EphCK1lhEf4UEyEM693ka574TZGwo4IWwS6QLzM/2t" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>
<script src="https://code.jquery.com/jquery-3.7.0.slim.min.js" integrity="sha384-w5y/xIeYixWvfM+A1cEbmHPURnvyqmVg5eVENruEdDjcyRLUSNej7512JQGspFUr" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@3.4.1/dist/js/bootstrap.min.js" integrity="sha384-aJ21OjlMXNL5UyIl/XNwTMqvzeRMZH2w8c5cRVpzpU8Y5bApTppSuUkhZXN0VxHd" crossorigin="anonymous"></script>

<script src="http://localhost:1313/js/main.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.js" integrity="sha384-QELNnmcmU8IR9ZAykt67vGr9/rZJdHbiWi64V88fCPaOohUlHCqUD/unNN0BXSqy" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe-ui-default.min.js" integrity="sha384-m67o7SkQ1ALzKZIFh4CiTA8tmadaujiTa9Vu+nqPSwDOqHrDmxLezTdFln8077+q" crossorigin="anonymous"></script><script src="http://localhost:1313/js/load-photoswipe.js"></script>










    
  </body>
</html>

