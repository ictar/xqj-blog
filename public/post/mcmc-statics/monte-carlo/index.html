

<!DOCTYPE html>
<html lang="en" itemscope itemtype="http://schema.org/WebPage">
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0">

 


      <title>Monte Carlo Sampling - </title>

  <meta name="description" content="Understand the core concepts of Monte Carlo: Law of Large Numbers, rejection sampling, importance sampling, variance reduction techniques (antithetic variates, control variates, stratified sampling).">
  <meta name="author" content="Qiongjie.X"/>


<link rel="canonical" href="http://localhost:1313/post/mcmc-statics/monte-carlo/" />


<meta name="keywords" content="Monte Carlo, Sampling, Mathematics, python" /><script type="application/ld+json">
{
    "@context": "http://schema.org",
    "@type": "WebSite",
    "name": "Qiongjie\u0027s Notes",
    
    "url": "http:\/\/localhost:1313\/"
}
</script>

<script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "BreadcrumbList",
  "itemListElement": [{
        "@type": "ListItem",
        "position": 1,
        "item": {
          "@id": "http:\/\/localhost:1313\/",
          "name": "home"
        }
    },{
        "@type": "ListItem",
        "position": 3,
        "item": {
          "@id": "http:\/\/localhost:1313\/post\/mcmc-statics\/monte-carlo\/",
          "name": "Monte carlo sampling"
        }
    }]
}
</script><script type="application/ld+json">
{
  "@context": "http://schema.org",
  "@type": "Article",
  "author": {
    "name" : "Qiongjie.X"
  },
  "headline": "Monte Carlo Sampling",
  "description" : "Understand the core concepts of Monte Carlo: Law of Large Numbers, rejection sampling, importance sampling, variance reduction techniques (antithetic variates, control variates, stratified sampling).",
  "inLanguage" : "en",
  "wordCount":  2912 ,
  "datePublished" : "2025-08-30T00:00:00\u002b00:00",
  "dateModified" : "2025-08-30T00:00:00\u002b00:00",
  "image" : "http:\/\/localhost:1313\/img\/avatar-icon.png",
  "keywords" : [ "Monte Carlo, Sampling, Mathematics, python" ],
  "mainEntityOfPage" : "http:\/\/localhost:1313\/post\/mcmc-statics\/monte-carlo\/",
  "publisher" : {
    "@type": "Organization",
    "name" : "http:\/\/localhost:1313\/",
    "logo" : {
        "@type" : "ImageObject",
        "url" : "http:\/\/localhost:1313\/img\/avatar-icon.png",
        "height" :  60 ,
        "width" :  60
    }
  }
}
</script>



<meta property="og:title" content="Monte Carlo Sampling" />
<meta property="og:description" content="Understand the core concepts of Monte Carlo: Law of Large Numbers, rejection sampling, importance sampling, variance reduction techniques (antithetic variates, control variates, stratified sampling).">
<meta property="og:image" content="http://localhost:1313/img/avatar-icon.png" />
<meta property="og:url" content="http://localhost:1313/post/mcmc-statics/monte-carlo/" />
<meta property="og:type" content="website" />
<meta property="og:site_name" content="Qiongjie&#39;s Notes" />

  <meta name="twitter:title" content="Monte Carlo Sampling" />
  <meta name="twitter:description" content="Understand the core concepts of Monte Carlo: Law of Large Numbers, rejection sampling, importance sampling, variance reduction techniques (antithetic variates, control variates, stratified sampling).">
  <meta name="twitter:image" content="http://localhost:1313/img/avatar-icon.png" />
  <meta name="twitter:card" content="summary_large_image" />
  <link href='http://localhost:1313/favicon.ico' rel='icon' type='image/x-icon'/>
  <meta name="generator" content="Hugo 0.147.4">
  <link rel="alternate" href="http://localhost:1313/index.xml" type="application/rss+xml" title="Qiongjie&#39;s Notes"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/katex.min.css" integrity="sha384-3UiQGuEI4TTMaFmGIZumfRPtfKQ3trwQE2JgosJxCnGmQpL/lJdjpcHkaaFwHlcI" crossorigin="anonymous">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v6.6.0/css/all.css" integrity="sha384-h/hnnw1Bi4nbpD6kE7nYfCXzovi622sY5WBxww8ARKwpdLj5kUWjRuyiXaD1U2JT" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@3.4.1/dist/css/bootstrap.min.css" integrity="sha384-HSMxcRTRxnN+Bdg0JdbxYKrThecOKuH5zCYotlSAcp1+c8xmyTe9GYg1l9a69psu" crossorigin="anonymous"><link rel="stylesheet" href="http://localhost:1313/css/main.css" /><link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" />
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" /><link rel="stylesheet" href="http://localhost:1313/css/syntax.css" /><link rel="stylesheet" href="http://localhost:1313/css/codeblock.css" /><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.css" integrity="sha384-h/L2W9KefUClHWaty3SLE5F/qvc4djlyR4qY3NUV5HGQBBW7stbcfff1+I/vmsHh" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/default-skin/default-skin.min.css" integrity="sha384-iD0dNku6PYSIQLyfTOpB06F2KCZJAKLOThS5HRe8b3ibhdEQ6eKsFf/EeFxdOt5R" crossorigin="anonymous">



<link
  rel="stylesheet"
  href="https://unpkg.com/leaflet@1.9.4/dist/leaflet.css"
  crossorigin="anonymous"
/>
<link rel="stylesheet" href="http://localhost:1313/css/custom.css"><link rel="stylesheet" href="http://localhost:1313/css/toc.css">

<script
  src="https://unpkg.com/leaflet@1.9.4/dist/leaflet.js"
  crossorigin="anonymous"
></script>

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.css">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/all.min.css">
<script src="https://cdnjs.cloudflare.com/ajax/libs/Leaflet.awesome-markers/2.0.2/leaflet.awesome-markers.js"></script>


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.css">


<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/katex.min.js"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.9/dist/contrib/auto-render.min.js"
  onload="renderMathInElement(document.body, {
    delimiters: [
      {left: '$$', right: '$$', display: true},
      {left: '$', right: '$', display: false}
    ]
  });"></script>


<link rel="icon" type="image/png" href="http://localhost:1313/img/favicon-96x96.png" sizes="96x96" />
<link rel="icon" type="image/svg+xml" href="http://localhost:1313/img/favicon.svg" />
<link rel="apple-touch-icon" sizes="180x180" href="http://localhost:1313/img/apple-touch-icon.png" />
<link rel="manifest" href="http://localhost:1313/img/site.webmanifest" />

  </head>
  <body>
    <nav class="navbar navbar-default navbar-fixed-top navbar-custom">
  <div class="container-fluid">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#main-navbar">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="http://localhost:1313/">Qiongjie&#39;s Notes</a>
    </div>

    <div class="collapse navbar-collapse" id="main-navbar">
      <ul class="nav navbar-nav navbar-right">
        
          
            <li class="navlinks-container">
              <a class="navlinks-parent" role="button" tabindex="0" href="/post">BLOG</a>
              <div class="navlinks-children">
                
                  <a href="/post/python-geodata">Remote Sensing with Python</a>
                
                  <a href="/post/mcmc-statics">Monte Carlo–Markov Chains Statistical Methods</a>
                
                  <a href="/post/ai-fundamentals">AI Fundamentals</a>
                
              </div>
            </li>
          
        
          
            <li class="navlinks-container">
              <a class="navlinks-parent" role="button" tabindex="0" href="/projects">PROJECT</a>
              <div class="navlinks-children">
                
                  <a href="https://ictar.github.io/TerraFlow/">TerraFlow</a>
                
              </div>
            </li>
          
        
          
            <li>
              <a title="NOTE" href="/notes">NOTE</a>
            </li>
          
        
          
            <li>
              <a title="TAG" href="/tags">TAG</a>
            </li>
          
        
          
            <li>
              <a title="ABOUT ME" href="/page/about/">ABOUT ME</a>
            </li>
          
        

        
          
            <li>
              
                
                  <a href="http://localhost:1313/zh-cn/post/mcmc-statics/monte-carlo/">CH</a>
                
              
            </li>
          
        

        
      </ul>
    </div>

    
      <div class="avatar-container">
        <div class="avatar-img-border">
          <a title="Qiongjie&#39;s Notes" href="http://localhost:1313/">
            <img class="avatar-img" src="http://localhost:1313/img/avatar-icon.png" alt="Qiongjie&#39;s Notes" />
           
          </a>
        </div>
      </div>
    

  </div>
</nav>




    


<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

<div class="pswp__bg"></div>

<div class="pswp__scroll-wrap">
    
    <div class="pswp__container">
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
      <div class="pswp__item"></div>
    </div>
    
    <div class="pswp__ui pswp__ui--hidden">
    <div class="pswp__top-bar">
      
      <div class="pswp__counter"></div>
      <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
      <button class="pswp__button pswp__button--share" title="Share"></button>
      <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
      <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>
      
      
      <div class="pswp__preloader">
        <div class="pswp__preloader__icn">
          <div class="pswp__preloader__cut">
            <div class="pswp__preloader__donut"></div>
          </div>
        </div>
      </div>
    </div>
    <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
      <div class="pswp__share-tooltip"></div>
    </div>
    <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
    </button>
    <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
    </button>
    <div class="pswp__caption">
      <div class="pswp__caption__center"></div>
    </div>
    </div>
    </div>
</div>


  
  
  






  

  <header class="header-section ">
    
    
    <div class="intro-header no-img">
      <div class="container">
        <div class="row">
          <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
            <div class="post-heading">
              
                <h1>Monte Carlo Sampling</h1>
              
              
              
              
                <span class="post-meta">
  
  
  <i class="fas fa-calendar"></i>&nbsp;Posted on August 30, 2025
  
  
  
    &nbsp;|&nbsp;<i class="fas fa-book"></i>&nbsp;2912&nbsp;words
  
  
  &nbsp;&bull;&nbsp;Other languages: <a href="http://localhost:1313/zh-cn/post/mcmc-statics/monte-carlo/" lang="zh-cn">CH</a>
</span>


              
            </div>
          </div>
        </div>
      </div>
    </div>
  
  </header>


    
<div class="container" role="main">
  <div class="row" style="display: flex; flex-wrap: wrap;">
    
    
    <div class="col-lg-8 col-lg-offset-1 col-md-10 col-md-offset-1">
      <article role="main" class="blog-post">
        
  <aside class="toc">
    <h2>目录</h2>
    <nav id="TableOfContents">
  <ul>
    <li><a href="#monte-carlo-method">Monte Carlo Method</a>
      <ul>
        <li><a href="#core-idea">Core Idea</a></li>
        <li><a href="#law-of-large-numbers--central-limit-theorem">Law of Large Numbers &amp; Central Limit Theorem</a>
          <ul>
            <li><a href="#example-1-estimating--via-monte-carlo-implementation">Example 1: Estimating  via Monte Carlo Implementation</a></li>
            <li><a href="#example-2-convergence-speed-visualization">Example 2: Convergence Speed Visualization</a></li>
          </ul>
        </li>
        <li><a href="#rejection-sampling">Rejection Sampling</a>
          <ul>
            <li><a href="#core-idea-1">Core Idea</a></li>
            <li><a href="#algorithm-steps">Algorithm Steps</a></li>
            <li><a href="#examples-in-code">Examples in Code</a></li>
            <li><a href="#example-3-estimating--via-rejection-sampling-wait-this-is-redundant-with-first-example-no-different-perspective">Example 3: Estimating  via Rejection Sampling (Wait, this is redundant with first example? No, different perspective)</a></li>
            <li><a href="#summary">Summary</a></li>
          </ul>
        </li>
        <li><a href="#importance-sampling-is">Importance Sampling (IS)</a>
          <ul>
            <li><a href="#goal-and-core-idea">Goal and Core Idea</a></li>
            <li><a href="#intuition-why-it-works">Intuition (Why it works)</a></li>
            <li><a href="#algorithm">Algorithm</a></li>
            <li><a href="#examples">Examples</a></li>
          </ul>
        </li>
        <li><a href="#variance-reduction-techniques">Variance Reduction Techniques</a>
          <ul>
            <li><a href="#method-1-antithetic-variates">Method 1️⃣ Antithetic Variates</a></li>
            <li><a href="#method-2-control-variates">Method 2️⃣ Control Variates</a></li>
            <li><a href="#method-3-stratified-sampling-1d--lhs">Method 3️⃣ Stratified Sampling (1D  LHS)</a></li>
          </ul>
        </li>
        <li><a href="#practical-guide">Practical Guide</a></li>
      </ul>
    </li>
    <li><a href="#further-reading">Further Reading</a></li>
  </ul>
</nav>
  </aside>

<h1 id="monte-carlo-method">Monte Carlo Method</h1>
<h2 id="core-idea">Core Idea</h2>
<p>Using randomness to solve deterministic (or stochastic) problems.</p>
<p>We want to calculate an integral (or expectation):
</p>
$$
I = \int_{\Omega} f(x) p(x) dx = \mathbb{E}_{p}[f(X)]
$$<p>
where $p(x)$ is a probability density.</p>
<p>Monte Carlo approximation: Draw $N$ independent samples $X_1, ..., X_N \sim p(x)$, then
</p>
$$
\hat{I}_N = \frac{1}{N} \sum_{i=1}^N f(X_i) \xrightarrow{N\to\infty} I
$$<h2 id="law-of-large-numbers--central-limit-theorem">Law of Large Numbers &amp; Central Limit Theorem</h2>
<ul>
<li><strong>Law of Large Numbers (LLN)</strong>: guarantees convergence $\hat{I}_N \to I$.</li>
<li><strong>Central Limit Theorem (CLT)</strong>: describes the error distribution.
$$
  \sqrt{N}(\hat{I}_N - I) \xrightarrow{d} \mathcal{N}(0, \sigma^2)
  $$
where $\sigma^2 = \text{Var}(f(X))$.
This means the error decreases at a rate of $O(1/\sqrt{N})$.</li>
</ul>
<h3 id="example-1-estimating--via-monte-carlo-implementation">Example 1: Estimating $\pi$ via Monte Carlo Implementation</h3>
<ul>
<li><strong>Goal</strong>: Estimate $\pi$.</li>
<li><strong>Method</strong>:
<ol>
<li>Sample uniform points $(x,y)$ in the square $[-1,1] \times [-1,1]$. Area $A_{sq} = 4$.</li>
<li>The unit circle is defined by $x^2 + y^2 \le 1$. Area $A_{circ} = \pi \cdot 1^2 = \pi$.</li>
<li>The probability of a point falling inside the circle is $P(\text{circle}) = \frac{\pi}{4}$.</li>
<li>Estimate $\hat{P} = \frac{N_{in}}{N}$, then $\hat{\pi} = 4 \hat{P}$.</li>
</ol>
</li>
</ul>
<p>We also compute the 95% Confidence Interval (CI) using the Wilson score interval or normal approximation.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#66d9ef">as</span> plt
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">estimate_pi</span>(N<span style="color:#f92672">=</span><span style="color:#ae81ff">1000</span>):
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 1. Sample N points in square [-1, 1] x [-1, 1]</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># np.random.rand generates [0, 1), so scaled to [-1, 1)</span>
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>uniform(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, N)
</span></span><span style="display:flex;"><span>    y <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>uniform(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, N)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 2. Check how many fall inside unit circle</span>
</span></span><span style="display:flex;"><span>    r2 <span style="color:#f92672">=</span> x<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span> <span style="color:#f92672">+</span> y<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>    inside <span style="color:#f92672">=</span> (r2 <span style="color:#f92672">&lt;=</span> <span style="color:#ae81ff">1.0</span>)
</span></span><span style="display:flex;"><span>    k <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>sum(inside)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 3. Estimate pi</span>
</span></span><span style="display:flex;"><span>    pi_hat <span style="color:#f92672">=</span> <span style="color:#ae81ff">4.0</span> <span style="color:#f92672">*</span> k <span style="color:#f92672">/</span> N
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># 4. Standard Error &amp; 95% Confidence Interval (Normal approx)</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Variance of the Bernoulli indicator is p(1-p), where p = pi/4</span>
</span></span><span style="display:flex;"><span>    p_hat <span style="color:#f92672">=</span> k <span style="color:#f92672">/</span> N
</span></span><span style="display:flex;"><span>    se_p <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>sqrt(p_hat <span style="color:#f92672">*</span> (<span style="color:#ae81ff">1</span> <span style="color:#f92672">-</span> p_hat) <span style="color:#f92672">/</span> N)
</span></span><span style="display:flex;"><span>    se_pi <span style="color:#f92672">=</span> <span style="color:#ae81ff">4.0</span> <span style="color:#f92672">*</span> se_p
</span></span><span style="display:flex;"><span>    ci_lower <span style="color:#f92672">=</span> pi_hat <span style="color:#f92672">-</span> <span style="color:#ae81ff">1.96</span> <span style="color:#f92672">*</span> se_pi
</span></span><span style="display:flex;"><span>    ci_upper <span style="color:#f92672">=</span> pi_hat <span style="color:#f92672">+</span> <span style="color:#ae81ff">1.96</span> <span style="color:#f92672">*</span> se_pi
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> pi_hat, (ci_lower, ci_upper), x, y, inside
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Run</span>
</span></span><span style="display:flex;"><span>np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>seed(<span style="color:#ae81ff">42</span>)
</span></span><span style="display:flex;"><span>N <span style="color:#f92672">=</span> <span style="color:#ae81ff">2000</span>
</span></span><span style="display:flex;"><span>pi_est, pi_ci, x, y, ins <span style="color:#f92672">=</span> estimate_pi(N)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Monte Carlo Estimation of π (N=</span><span style="color:#e6db74">{</span>N<span style="color:#e6db74">}</span><span style="color:#e6db74">)&#34;</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Estimated π = </span><span style="color:#e6db74">{</span>pi_est<span style="color:#e6db74">:</span><span style="color:#e6db74">.5f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;95% CI = [</span><span style="color:#e6db74">{</span>pi_ci[<span style="color:#ae81ff">0</span>]<span style="color:#e6db74">:</span><span style="color:#e6db74">.5f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">, </span><span style="color:#e6db74">{</span>pi_ci[<span style="color:#ae81ff">1</span>]<span style="color:#e6db74">:</span><span style="color:#e6db74">.5f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">]&#34;</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;True π = </span><span style="color:#e6db74">{</span>np<span style="color:#f92672">.</span>pi<span style="color:#e6db74">:</span><span style="color:#e6db74">.5f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Plot</span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>figure(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">6</span>,<span style="color:#ae81ff">6</span>))
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>scatter(x[ins], y[ins], s<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>, alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.6</span>, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Inside&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>scatter(x[<span style="color:#f92672">~</span>ins], y[<span style="color:#f92672">~</span>ins], s<span style="color:#f92672">=</span><span style="color:#ae81ff">10</span>, alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.6</span>, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Outside&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Monte Carlo Pi Estimation (N=</span><span style="color:#e6db74">{</span>N<span style="color:#e6db74">}</span><span style="color:#e6db74">)</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">$</span><span style="color:#ae81ff">\\</span><span style="color:#e6db74">hat</span><span style="color:#ae81ff">{{\\</span><span style="color:#e6db74">pi</span><span style="color:#ae81ff">}}</span><span style="color:#e6db74"> = </span><span style="color:#e6db74">{</span>pi_est<span style="color:#e6db74">:</span><span style="color:#e6db74">.4f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">$&#34;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;x&#34;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;y&#34;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>legend(loc<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;upper right&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>axis(<span style="color:#e6db74">&#39;equal&#39;</span>) <span style="color:#75715e"># Keep aspect ratio circular</span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>show()
</span></span></code></pre></div><pre><code>Monte Carlo Estimation of π (N=2000)
Estimated π = 3.16600
95% CI = [3.08208, 3.24992]
True π = 3.14159
</code></pre>
<p><img src="/img/contents/post/mcmc-statics/3_monte-carlo/3_mcmc_monte-carlo_3_1.png" alt="png"></p>
<h3 id="example-2-convergence-speed-visualization">Example 2: Convergence Speed Visualization</h3>
<p>How does the error of Monte Carlo estimation change as $N$ increases?
Theoretical prediction: Error $\propto 1/\sqrt{N}$. On a log-log plot, the slope should be -0.5.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Compute relative error for different N</span>
</span></span><span style="display:flex;"><span>Ns <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>logspace(<span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">6</span>, <span style="color:#ae81ff">20</span>)<span style="color:#f92672">.</span>astype(int) <span style="color:#75715e"># N from 100 to 1,000,000</span>
</span></span><span style="display:flex;"><span>errors <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>true_pi <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>pi
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># To smooth the curve, average over multiple runs for each N</span>
</span></span><span style="display:flex;"><span>trials <span style="color:#f92672">=</span> <span style="color:#ae81ff">50</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> n_val <span style="color:#f92672">in</span> Ns:
</span></span><span style="display:flex;"><span>    estimates <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> _ <span style="color:#f92672">in</span> range(trials):
</span></span><span style="display:flex;"><span>        est, _, _, _, _ <span style="color:#f92672">=</span> estimate_pi(n_val)
</span></span><span style="display:flex;"><span>        estimates<span style="color:#f92672">.</span>append(est)
</span></span><span style="display:flex;"><span>    mean_est <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>mean(estimates)
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Relative error of the mean estimate</span>
</span></span><span style="display:flex;"><span>    rel_err <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>abs(mean_est <span style="color:#f92672">-</span> true_pi) <span style="color:#f92672">/</span> true_pi
</span></span><span style="display:flex;"><span>    errors<span style="color:#f92672">.</span>append(rel_err)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Plot</span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>figure(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">8</span>,<span style="color:#ae81ff">5</span>))
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>loglog(Ns, errors, <span style="color:#e6db74">&#39;o-&#39;</span>, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Simulation Error&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>loglog(Ns, <span style="color:#ae81ff">1.0</span><span style="color:#f92672">/</span>np<span style="color:#f92672">.</span>sqrt(Ns), <span style="color:#e6db74">&#39;k--&#39;</span>, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Theoretical Rate $O(1/</span><span style="color:#ae81ff">\\</span><span style="color:#e6db74">sqrt</span><span style="color:#e6db74">{N}</span><span style="color:#e6db74">)$&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#39;Number of Samples N&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#39;Relative Error |$</span><span style="color:#ae81ff">\\</span><span style="color:#e6db74">hat{</span><span style="color:#ae81ff">\\</span><span style="color:#e6db74">pi} - </span><span style="color:#ae81ff">\\</span><span style="color:#e6db74">pi$| / $</span><span style="color:#ae81ff">\\</span><span style="color:#e6db74">pi$&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#39;Monte Carlo Convergence Rate&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>legend()
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>grid(<span style="color:#66d9ef">True</span>, which<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;both&#34;</span>, ls<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;-&#34;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>show()
</span></span></code></pre></div><p><img src="/img/contents/post/mcmc-statics/3_monte-carlo/3_mcmc_monte-carlo_5_0.png" alt="png"></p>
<h2 id="rejection-sampling">Rejection Sampling</h2>
<h3 id="core-idea-1">Core Idea</h3>
<p><strong>Goal</strong>: Sample from a complex target distribution $p(x)$ (can evaluate $p(x)$ or unnormalized $\tilde{p}(x)$), but cannot direct sample (no <code>inverse_cdf</code>).</p>
<p><strong>Method</strong>:</p>
<ol>
<li>Find a simpler <strong>Proposal Distribution</strong> $q(x)$ (e.g., Uniform, Gaussian) that we can sample from.</li>
<li>Find constant $M$ such that $M q(x) \ge \tilde{p}(x)$ for all $x$. (Envelope function).</li>
<li><strong>Sampling Step</strong>:
<ul>
<li>Draw $x \sim q(x)$.</li>
<li>Draw $u \sim \text{Uniform}(0, 1)$.</li>
<li><strong>Accept</strong> $x$ if $u \le \frac{\tilde{p}(x)}{M q(x)}$.</li>
<li>Else <strong>Reject</strong>.</li>
</ul>
</li>
</ol>
<p><strong>Intuition</strong>: We sprinkle points uniformly under the curve $M q(x)$. If a point falls under $\tilde{p}(x)$, keep it. The x-coordinates of kept points follow $p(x)$.</p>
<h3 id="algorithm-steps">Algorithm Steps</h3>
<ol>
<li>Choose $q(x)$ to cover $p(x)$ (heavier tails).</li>
<li>Choose $M \ge \sup_x \frac{\tilde{p}(x)}{q(x)}$.</li>
<li>Repeat:
<ul>
<li>Sample $x^* \sim q$.</li>
<li>Sample $u \sim \text{Unif}(0,1)$.</li>
<li>Calculate acceptance ratio $\alpha = \frac{\tilde{p}(x^*)}{M q(x^*)}$.</li>
<li>If $u \le \alpha$, return $x^*$.</li>
</ul>
</li>
</ol>
<p><strong>Efficiency</strong>: Acceptance rate $\approx 1/M$ (for normalized $p, q$). Smaller $M$ is better ($M \ge 1$).</p>
<h3 id="examples-in-code">Examples in Code</h3>
<h4 id="example-1-sampling-from-beta2-5-using-uniform01">Example 1: Sampling from Beta(2, 5) using Uniform(0,1)</h4>
<ul>
<li>Target: $p(x) = \text{Beta}(2,5) \propto x^{2-1}(1-x)^{5-1} = x(1-x)^4$, $x \in [0,1]$.</li>
<li>Proposal: $q(x) = \text{Uniform}(0,1) = 1$.</li>
<li>Find $M$: Maximize $f(x)=x(1-x)^4$. Derivative $1(1-x)^4 + x \cdot 4(1-x)^3(-1) = (1-x)^3 [ (1-x) - 4x ] = (1-x)^3 [ 1 - 5x ]$. Max at $x=1/5$. $M = f(0.2) = 0.2 \cdot (0.8)^4 = 0.2 \cdot 0.4096 = 0.08192$.</li>
<li>Note: This is unnormalized max. Real PDF max is higher. If using normalized <code>scipy.stats.beta.pdf</code>, peak is around 2.46. Let&rsquo;s use <code>scipy.stats</code> for correct $M$.</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">from</span> scipy.stats <span style="color:#f92672">import</span> beta, uniform
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Target: Beta(2, 5)</span>
</span></span><span style="display:flex;"><span>a, b <span style="color:#f92672">=</span> <span style="color:#ae81ff">2</span>, <span style="color:#ae81ff">5</span>
</span></span><span style="display:flex;"><span>target_dist <span style="color:#f92672">=</span> beta(a, b)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Proposal: Uniform(0, 1)</span>
</span></span><span style="display:flex;"><span>proposal_dist <span style="color:#f92672">=</span> uniform(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Find M: Max of p(x)/q(x)</span>
</span></span><span style="display:flex;"><span>x_vals <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>linspace(<span style="color:#ae81ff">0.001</span>, <span style="color:#ae81ff">0.999</span>, <span style="color:#ae81ff">1000</span>)
</span></span><span style="display:flex;"><span>M <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>max(target_dist<span style="color:#f92672">.</span>pdf(x_vals) <span style="color:#f92672">/</span> proposal_dist<span style="color:#f92672">.</span>pdf(x_vals))
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Optimal M = </span><span style="color:#e6db74">{</span>M<span style="color:#e6db74">:</span><span style="color:#e6db74">.4f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># In practice, use slightly larger M to be safe (e.g., M=2.6) or exactly calculated max.</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">rejection_sampling_beta</span>(n_samples, M_val):
</span></span><span style="display:flex;"><span>    samples <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>    attempts <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">while</span> len(samples) <span style="color:#f92672">&lt;</span> n_samples:
</span></span><span style="display:flex;"><span>        attempts <span style="color:#f92672">+=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>uniform(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>) <span style="color:#75715e"># Sample from q</span>
</span></span><span style="display:flex;"><span>        u <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>uniform(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>) <span style="color:#75715e"># Decision variable</span>
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Accept condition</span>
</span></span><span style="display:flex;"><span>        ratio <span style="color:#f92672">=</span> target_dist<span style="color:#f92672">.</span>pdf(x) <span style="color:#f92672">/</span> (M_val <span style="color:#f92672">*</span> proposal_dist<span style="color:#f92672">.</span>pdf(x))
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> u <span style="color:#f92672">&lt;=</span> ratio:
</span></span><span style="display:flex;"><span>            samples<span style="color:#f92672">.</span>append(x)
</span></span><span style="display:flex;"><span>            
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> np<span style="color:#f92672">.</span>array(samples), attempts
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>n_draws <span style="color:#f92672">=</span> <span style="color:#ae81ff">5000</span>
</span></span><span style="display:flex;"><span>samples, total_attempts <span style="color:#f92672">=</span> rejection_sampling_beta(n_draws, M_val<span style="color:#f92672">=</span>M)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Acceptance Rate: </span><span style="color:#e6db74">{</span>n_draws <span style="color:#f92672">/</span> total_attempts<span style="color:#e6db74">:</span><span style="color:#e6db74">.2%</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Theoretical Rate (1/M): </span><span style="color:#e6db74">{</span><span style="color:#ae81ff">1</span><span style="color:#f92672">/</span>M<span style="color:#e6db74">:</span><span style="color:#e6db74">.2%</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Plot</span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>figure(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">8</span>,<span style="color:#ae81ff">5</span>))
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Histogram of samples</span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>hist(samples, bins<span style="color:#f92672">=</span><span style="color:#ae81ff">40</span>, density<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.6</span>, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Rejection Samples&#39;</span>)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Theoretical Target PDF</span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>plot(x_vals, target_dist<span style="color:#f92672">.</span>pdf(x_vals), <span style="color:#e6db74">&#39;r-&#39;</span>, lw<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Target Beta(2,5)&#39;</span>)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># M * q(x)</span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>plot(x_vals, M <span style="color:#f92672">*</span> proposal_dist<span style="color:#f92672">.</span>pdf(x_vals), <span style="color:#e6db74">&#39;k--&#39;</span>, lw<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Proposal M*q(x)&#39;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>legend()
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#34;Rejection Sampling: Beta(2,5) from Uniform&#34;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>show()
</span></span></code></pre></div><pre><code>Optimal M = 2.4576
Acceptance Rate: 40.85%
Theoretical Rate (1/M): 40.69%
</code></pre>
<p><img src="/img/contents/post/mcmc-statics/3_monte-carlo/3_mcmc_monte-carlo_11_1.png" alt="png"></p>
<h4 id="example-2-sampling-from-half-normal-using-exponential">Example 2: Sampling from Half-Normal using Exponential</h4>
<p>Reference: Techniques often used in intro stats courses.</p>
<ul>
<li>Target: $p(x) \propto e^{-x^2/2}$ (Half-normal, $x>0$)</li>
<li>Proposal: $q(x) = \lambda e^{-\lambda x}$ (Exponential, $x>0$)</li>
</ul>
<p>Let&rsquo;s try to sample standard half-normal (target) using Exp(1) (proposal).
$p(x) = \sqrt{\frac{2}{\pi}} e^{-x^2/2}$ for $x>0$.
$q(x) = e^{-x}$.
Ratio $p(x)/q(x) = \sqrt{2/\pi} e^{-x^2/2 + x}$.
Max of $-x^2/2+x$ at $x=1$. Max value $e^{0.5}$.
So $M = \sqrt{2/\pi} e^{0.5} \approx 1.315$.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Rejection Sampling: Standard Normal (positive half) via Exponential(1)</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Target p(x) = (2/sqrt(2pi)) * exp(-x^2/2) for x&gt;=0</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Proposal q(x) = exp(-x) for x&gt;=0</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">target_pdf</span>(x):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> (<span style="color:#ae81ff">2.0</span> <span style="color:#f92672">/</span> np<span style="color:#f92672">.</span>sqrt(<span style="color:#ae81ff">2</span> <span style="color:#f92672">*</span> np<span style="color:#f92672">.</span>pi)) <span style="color:#f92672">*</span> np<span style="color:#f92672">.</span>exp(<span style="color:#f92672">-</span>x<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span> <span style="color:#f92672">/</span> <span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">proposal_pdf</span>(x):
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> np<span style="color:#f92672">.</span>exp(<span style="color:#f92672">-</span>x)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Optimal M</span>
</span></span><span style="display:flex;"><span>M <span style="color:#f92672">=</span> <span style="color:#ae81ff">1.32</span>  <span style="color:#75715e"># calculated approx 1.315...</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">rejection_normal_from_exp</span>(n):
</span></span><span style="display:flex;"><span>    res <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>    tot <span style="color:#f92672">=</span> <span style="color:#ae81ff">0</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">while</span> len(res) <span style="color:#f92672">&lt;</span> n:
</span></span><span style="display:flex;"><span>        tot <span style="color:#f92672">+=</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>        <span style="color:#75715e"># Sample from Exp(1)</span>
</span></span><span style="display:flex;"><span>        x <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>exponential(scale<span style="color:#f92672">=</span><span style="color:#ae81ff">1.0</span>)
</span></span><span style="display:flex;"><span>        u <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>rand()
</span></span><span style="display:flex;"><span>        
</span></span><span style="display:flex;"><span>        acc_prob <span style="color:#f92672">=</span> target_pdf(x) <span style="color:#f92672">/</span> (M <span style="color:#f92672">*</span> proposal_pdf(x))
</span></span><span style="display:flex;"><span>        <span style="color:#66d9ef">if</span> u <span style="color:#f92672">&lt;=</span> acc_prob:
</span></span><span style="display:flex;"><span>            res<span style="color:#f92672">.</span>append(x)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> np<span style="color:#f92672">.</span>array(res), tot
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>s_norm, tot_N <span style="color:#f92672">=</span> rejection_normal_from_exp(<span style="color:#ae81ff">2000</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Empirical Acceptance Rate: </span><span style="color:#e6db74">{</span><span style="color:#ae81ff">2000</span><span style="color:#f92672">/</span>tot_N<span style="color:#e6db74">:</span><span style="color:#e6db74">.3%</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Theoretical (1/M): </span><span style="color:#e6db74">{</span><span style="color:#ae81ff">1</span><span style="color:#f92672">/</span>M<span style="color:#e6db74">:</span><span style="color:#e6db74">.3%</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>figure(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">8</span>,<span style="color:#ae81ff">5</span>))
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>hist(s_norm, bins<span style="color:#f92672">=</span><span style="color:#ae81ff">30</span>, density<span style="color:#f92672">=</span><span style="color:#66d9ef">True</span>, alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.5</span>, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Samples&#39;</span>)
</span></span><span style="display:flex;"><span>xx <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>linspace(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">4</span>, <span style="color:#ae81ff">200</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>plot(xx, target_pdf(xx), <span style="color:#e6db74">&#39;r&#39;</span>, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Half-Normal PDF&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>plot(xx, M<span style="color:#f92672">*</span>proposal_pdf(xx), <span style="color:#e6db74">&#39;g--&#39;</span>, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;Envelope M*Exp(1)&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>legend()
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#34;Rejection Sampling: Half-Normal from Exp(1)&#34;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>show()
</span></span></code></pre></div><pre><code>Empirical Acceptance Rate: 74.963%
Theoretical (1/M): 75.758%
</code></pre>
<p><img src="/img/contents/post/mcmc-statics/3_monte-carlo/3_mcmc_monte-carlo_13_1.png" alt="png"></p>
<h3 id="example-3-estimating--via-rejection-sampling-wait-this-is-redundant-with-first-example-no-different-perspective">Example 3: Estimating $\pi$ via Rejection Sampling (Wait, this is redundant with first example? No, different perspective)</h3>
<p>Actually, the &ldquo;dart throwing&rdquo; for $\pi$ is exactly rejection sampling!</p>
<ul>
<li>Target: Uniform on Circle.</li>
<li>Proposal: Uniform on Square.</li>
<li>Acceptance: If inside circle.</li>
<li>Acceptance Rate: Area(Circ) / Area(Square) = $\pi/4$.</li>
<li>So $\pi \approx 4 \times \text{AcceptanceRate}$.</li>
</ul>
<p>This allows us to write a script estimating $\pi$ from the acceptance rate.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Code to re-illustrate the connection between Rejection Sampling and Pi estimation</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># We count how many &#39;accepted&#39; from Uniform Square</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># p_hat = accepted / total ~ pi / 4</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> scipy.stats <span style="color:#66d9ef">as</span> stats
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">rejection_sampling_pi</span>(N):
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>uniform(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, N)
</span></span><span style="display:flex;"><span>    y <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>uniform(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1</span>, N)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    r2 <span style="color:#f92672">=</span> x<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span> <span style="color:#f92672">+</span> y<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>    inside <span style="color:#f92672">=</span> (r2 <span style="color:#f92672">&lt;=</span> <span style="color:#ae81ff">1.0</span>)
</span></span><span style="display:flex;"><span>    k <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>sum(inside)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    p_hat <span style="color:#f92672">=</span> k <span style="color:#f92672">/</span> N
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Wilson interval for binomial proportion p</span>
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># z=1.96 (95%)</span>
</span></span><span style="display:flex;"><span>    z <span style="color:#f92672">=</span> <span style="color:#ae81ff">1.96</span>
</span></span><span style="display:flex;"><span>    denom <span style="color:#f92672">=</span> <span style="color:#ae81ff">1</span> <span style="color:#f92672">+</span> z<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span><span style="color:#f92672">/</span>N
</span></span><span style="display:flex;"><span>    center <span style="color:#f92672">=</span> (p_hat <span style="color:#f92672">+</span> z<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span><span style="color:#f92672">/</span>(<span style="color:#ae81ff">2</span><span style="color:#f92672">*</span>N)) <span style="color:#f92672">/</span> denom
</span></span><span style="display:flex;"><span>    hw <span style="color:#f92672">=</span> z <span style="color:#f92672">*</span> np<span style="color:#f92672">.</span>sqrt(p_hat<span style="color:#f92672">*</span>(<span style="color:#ae81ff">1</span><span style="color:#f92672">-</span>p_hat)<span style="color:#f92672">/</span>N <span style="color:#f92672">+</span> z<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span><span style="color:#f92672">/</span>(<span style="color:#ae81ff">4</span><span style="color:#f92672">*</span>N<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span>)) <span style="color:#f92672">/</span> denom
</span></span><span style="display:flex;"><span>    ci_p <span style="color:#f92672">=</span> (center <span style="color:#f92672">-</span> hw, center <span style="color:#f92672">+</span> hw)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    pi_hat <span style="color:#f92672">=</span> p_hat <span style="color:#f92672">*</span> <span style="color:#ae81ff">4</span>
</span></span><span style="display:flex;"><span>    pi_ci <span style="color:#f92672">=</span> (ci_p[<span style="color:#ae81ff">0</span>]<span style="color:#f92672">*</span><span style="color:#ae81ff">4</span>, ci_p[<span style="color:#ae81ff">1</span>]<span style="color:#f92672">*</span><span style="color:#ae81ff">4</span>)
</span></span><span style="display:flex;"><span>    
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> {
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;x&#34;</span>: x, <span style="color:#e6db74">&#34;y&#34;</span>: y, <span style="color:#e6db74">&#34;inside&#34;</span>: inside,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;k_inside&#34;</span>: k, <span style="color:#e6db74">&#34;N&#34;</span>: N,
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;p_hat&#34;</span>: p_hat, <span style="color:#e6db74">&#34;pi_hat&#34;</span>: pi_hat, <span style="color:#e6db74">&#34;pi_CI95&#34;</span>: pi_ci
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>res <span style="color:#f92672">=</span> rejection_sampling_pi(N<span style="color:#f92672">=</span><span style="color:#ae81ff">30000</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;N=</span><span style="color:#e6db74">{</span>res[<span style="color:#e6db74">&#39;N&#39;</span>]<span style="color:#e6db74">}</span><span style="color:#e6db74">, inside=</span><span style="color:#e6db74">{</span>res[<span style="color:#e6db74">&#39;k_inside&#39;</span>]<span style="color:#e6db74">}</span><span style="color:#e6db74"> -&gt; p_hat=</span><span style="color:#e6db74">{</span>res[<span style="color:#e6db74">&#39;p_hat&#39;</span>]<span style="color:#e6db74">:</span><span style="color:#e6db74">.6f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;π̂ = </span><span style="color:#e6db74">{</span>res[<span style="color:#e6db74">&#39;pi_hat&#39;</span>]<span style="color:#e6db74">:</span><span style="color:#e6db74">.6f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;95% Wilson CI for π: [</span><span style="color:#e6db74">{</span>res[<span style="color:#e6db74">&#39;pi_CI95&#39;</span>][<span style="color:#ae81ff">0</span>]<span style="color:#e6db74">:</span><span style="color:#e6db74">.6f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">, </span><span style="color:#e6db74">{</span>res[<span style="color:#e6db74">&#39;pi_CI95&#39;</span>][<span style="color:#ae81ff">1</span>]<span style="color:#e6db74">:</span><span style="color:#e6db74">.6f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">]&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>m <span style="color:#f92672">=</span> <span style="color:#ae81ff">6000</span>
</span></span><span style="display:flex;"><span>xv <span style="color:#f92672">=</span> res[<span style="color:#e6db74">&#34;x&#34;</span>][:m]
</span></span><span style="display:flex;"><span>yv <span style="color:#f92672">=</span> res[<span style="color:#e6db74">&#34;y&#34;</span>][:m]
</span></span><span style="display:flex;"><span>insv <span style="color:#f92672">=</span> res[<span style="color:#e6db74">&#34;inside&#34;</span>][:m]
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>theta <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>linspace(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">2</span><span style="color:#f92672">*</span>np<span style="color:#f92672">.</span>pi, <span style="color:#ae81ff">600</span>)
</span></span><span style="display:flex;"><span>cx <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>cos(theta)
</span></span><span style="display:flex;"><span>cy <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>sin(theta)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>figure(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">6</span>,<span style="color:#ae81ff">6</span>))
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>scatter(xv[<span style="color:#f92672">~</span>insv], yv[<span style="color:#f92672">~</span>insv], s<span style="color:#f92672">=</span><span style="color:#ae81ff">8</span>, alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.6</span>, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;rejected (outside circle)&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>scatter(xv[insv], yv[insv], s<span style="color:#f92672">=</span><span style="color:#ae81ff">8</span>, alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.6</span>, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;accepted (inside circle)&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>plot(cx, cy, linewidth<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;unit circle boundary&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>text(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, <span style="color:#f92672">-</span><span style="color:#ae81ff">1.2</span>, <span style="color:#e6db74">&#39;Proposal points in square (Blue=Reject, Orange=Accept) &amp; Unit Circle&#39;</span>, fontsize<span style="color:#f92672">=</span><span style="color:#ae81ff">12</span>, color<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;red&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#39;Rejection Sampling for π: points in square, accept if x²+y² ≤ 1&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>gca()<span style="color:#f92672">.</span>set_aspect(<span style="color:#e6db74">&#39;equal&#39;</span>, <span style="color:#e6db74">&#39;box&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>xlim(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">1</span>); plt<span style="color:#f92672">.</span>ylim(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>legend()
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>show()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>inside_prefix <span style="color:#f92672">=</span> res[<span style="color:#e6db74">&#34;inside&#34;</span>]<span style="color:#f92672">.</span>astype(float)
</span></span><span style="display:flex;"><span>running_p <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>cumsum(inside_prefix) <span style="color:#f92672">/</span> np<span style="color:#f92672">.</span>arange(<span style="color:#ae81ff">1</span>, res[<span style="color:#e6db74">&#34;N&#34;</span>]<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>running_pi <span style="color:#f92672">=</span> <span style="color:#ae81ff">4.0</span> <span style="color:#f92672">*</span> running_p
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>figure(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">9</span>,<span style="color:#ae81ff">4</span>))
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>plot(running_pi)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>axhline(np<span style="color:#f92672">.</span>pi, linestyle<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;--&#39;</span>, linewidth<span style="color:#f92672">=</span><span style="color:#ae81ff">1.5</span>, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;π (true)&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>text(<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>, <span style="color:#ae81ff">1.5</span>, <span style="color:#e6db74">&#39;Running estimate of π converges to π&#39;</span>, fontsize<span style="color:#f92672">=</span><span style="color:#ae81ff">12</span>, color<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;red&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#39;Running estimate of π via rejection sampling (Uniform on square)&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#39;N (number of proposals)&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#39;estimate of π&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>legend()
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>show()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># {&#34;pi_hat&#34;: float(res[&#34;pi_hat&#34;]), &#34;pi_CI95&#34;: [float(res[&#34;pi_CI95&#34;][0]), float(res[&#34;pi_CI95&#34;][1])], &#34;N&#34;: int(res[&#34;N&#34;]), &#34;accepted_ratio&#34;: float(res[&#34;k_inside&#34;]/res[&#34;N&#34;])}</span>
</span></span></code></pre></div><pre><code>N=30000, inside=23506 -&gt; p_hat=0.783533
π̂ = 3.134133
95% Wilson CI for π: [3.115348, 3.152629]
</code></pre>
<p><img src="/img/contents/post/mcmc-statics/3_monte-carlo/3_mcmc_monte-carlo_19_1.png" alt="png"></p>
<p><img src="/img/contents/post/mcmc-statics/3_monte-carlo/3_mcmc_monte-carlo_19_2.png" alt="png"></p>
<h3 id="summary">Summary</h3>
<ul>
<li>Rejection sampling is a direct, exact method to sample from complex distributions, needing only relative values of target density (unnormalized ok).</li>
<li>Correctness is simple: the conditional distribution of accepted samples equals the target distribution.</li>
<li>Performance bottleneck is finding a good proposal $q$ and small M; hard in high dimensions, where MCMC is preferred.</li>
<li>Implementation notes: numerical stability (avoid divide by zero), counting method for empirical acceptance rate.</li>
</ul>
<h2 id="importance-sampling-is">Importance Sampling (IS)</h2>
<h3 id="goal-and-core-idea">Goal and Core Idea</h3>
<p><strong>Goal</strong>: Compute (or estimate) an expectation/integral
</p>
$$
I \;=\; \mathbb{E}_{\pi}[h(X)] \;=\; \int h(x)\,\pi(x)\,dx,
$$<p>
where $\pi(x)$ is target density (known or unnormalized $f(x)=Z\pi(x)$).</p>
<p><strong>Idea</strong>: When direct sampling from $\pi$ is hard, sample from an easy <strong>Proposal Distribution</strong> $q(x)$, and correct with <strong>weights</strong>:</p>
$$
I \;=\; \int h(x)\,\frac{\pi(x)}{q(x)}\,q(x)\,dx \;\\
Let\quad w(x)=\frac{\pi(x)}{q(x)} \\
Then\quad I \;=\; \int h(x)\,\frac{\pi(x)}{q(x)}\,q(x)\,dx \;=\; \int h(x)\,w(x)\,q(x)\,dx \;=\; \int [h(x)\,w(x)]\,q(x)\,dx \;=\; \mathbb{E}_q\!\big[h(X)\,w(X)\big],
$$<p>1️⃣ When $\pi$ is normalized, <strong>IS Estimator</strong>:
</p>
$$
\widehat I_{\text{IS}} \;=\; \frac{1}{n}\sum_{i=1}^n h(X_i)\,w(X_i),\quad X_i\overset{iid}{\sim}q.
$$<p>
It is <strong>unbiased</strong>: $\mathbb{E}_q[\hat I_{\text{IS}}] = I$.
Variance: $\operatorname{Var}(\widehat I_{\text{IS}})=\frac{1}{n}\,\operatorname{Var}_q\big(h(X)w(X)\big)$.</p>
<blockquote>
<p>Variance depends on fluctuation of $w(x)h(x)$ under $q$.</p></blockquote>
<p>2️⃣ When target is <strong>unnormalized</strong> $f(x)=Z\pi(x)$ ($Z$ unknown), use <strong>Self-Normalized Importance Sampling (SNIS)</strong>:
</p>
$$
\widehat I_{\text{SNIS}}
=\frac{\sum_{i=1}^n h(X_i)\,\tilde w_i}{\sum_{i=1}^n \tilde w_i},
\qquad \tilde w_i=\frac{f(X_i)}{q(X_i)} \;\propto\; \frac{\pi(X_i)}{q(X_i)}.
$$<p>
SNIS has <strong>small bias</strong> (finite samples) but is <strong>consistent</strong>.</p>
<h3 id="intuition-why-it-works">Intuition (Why it works)</h3>
<p>Separate &ldquo;who to sample&rdquo; from &ldquo;how to weight&rdquo;:</p>
<ul>
<li>$q$ is responsible for <strong>scattering samples to important regions</strong> (where $h\pi$ is large).</li>
<li>$w=\pi/q$ is responsible for <strong>correcting density differences</strong>, ensuring expectation is still wrt $\pi$.</li>
</ul>
<p>Key to variance reduction: if $q$ focuses on &ldquo;high contribution&rdquo; regions, $\operatorname{Var}(h\,w)$ drops significantly.</p>
<blockquote>
<p>Theoretically optimal $q^{\star}(x)\ \propto\ |h(x)|\,\pi(x)$.</p></blockquote>
<h3 id="algorithm">Algorithm</h3>
<p><strong>Input</strong>: Want $I=\mathbb{E}_\pi[h(X)]$; proposal $q$; sample size $n$.</p>
<p><strong>Steps</strong>:</p>
<ol>
<li>Sample $X_1,\dots,X_n \sim q$ i.i.d.</li>
<li>Compute weights $w_i = \pi(X_i)/q(X_i)$ (or $\tilde w_i = f(X_i)/q(X_i)$).</li>
<li>If $\pi$ normalized: $\widehat I = \frac{1}{n}\sum h(X_i)w_i$.
If unnormalized $f$: $\widehat I = \frac{\sum h(X_i)\tilde w_i}{\sum \tilde w_i}$.</li>
<li>Diagnostics: Check <strong>Weight Degeneracy</strong> and <strong>Effective Sample Size (ESS)</strong>:
$$
   \mathrm{ESS}=\frac{\big(\sum_i w_i\big)^2}{\sum_i w_i^2} \quad \text{(unnormalized weights)}
   $$
Rule of thumb: ESS close to $n$ is good. Small ESS means weights concentrated (few samples dominate).</li>
</ol>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#66d9ef">as</span> plt
</span></span><span style="display:flex;"><span><span style="color:#f92672">from</span> scipy.stats <span style="color:#f92672">import</span> norm
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>seed(<span style="color:#ae81ff">2025</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">importance_estimate</span>(samples, target_pdf, proposal_pdf, h):
</span></span><span style="display:flex;"><span>    qx <span style="color:#f92672">=</span> proposal_pdf(samples)
</span></span><span style="display:flex;"><span>    px <span style="color:#f92672">=</span> target_pdf(samples)
</span></span><span style="display:flex;"><span>    w <span style="color:#f92672">=</span> px <span style="color:#f92672">/</span> qx
</span></span><span style="display:flex;"><span>    wh <span style="color:#f92672">=</span> w <span style="color:#f92672">*</span> h(samples)
</span></span><span style="display:flex;"><span>    is_hat <span style="color:#f92672">=</span> wh<span style="color:#f92672">.</span>mean() <span style="color:#75715e"># IS estimate</span>
</span></span><span style="display:flex;"><span>    sn_hat <span style="color:#f92672">=</span> wh<span style="color:#f92672">.</span>sum() <span style="color:#f92672">/</span> w<span style="color:#f92672">.</span>sum() <span style="color:#75715e"># Self-normalized estimate</span>
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> is_hat, sn_hat, w
</span></span></code></pre></div><h3 id="examples">Examples</h3>
<h4 id="example-estimate--smooth-case">Example: Estimate $E_{N(0,1)}[X^2]$ (Smooth case)</h4>
<ul>
<li>Target $\pi=N(0,1)$</li>
<li>Estimate $E[X^2]$</li>
<li>Proposal $q=N(0,2^2)$</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>N1 <span style="color:#f92672">=</span> <span style="color:#ae81ff">5000</span>
</span></span><span style="display:flex;"><span>sigma_prop <span style="color:#f92672">=</span> <span style="color:#ae81ff">2.0</span>
</span></span><span style="display:flex;"><span>x_prop <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>normal(<span style="color:#ae81ff">0.0</span>, sigma_prop, size<span style="color:#f92672">=</span>N1)
</span></span><span style="display:flex;"><span>target_pdf <span style="color:#f92672">=</span> <span style="color:#66d9ef">lambda</span> x: norm<span style="color:#f92672">.</span>pdf(x, <span style="color:#ae81ff">0.0</span>, <span style="color:#ae81ff">1.0</span>)
</span></span><span style="display:flex;"><span>proposal_pdf <span style="color:#f92672">=</span> <span style="color:#66d9ef">lambda</span> x: norm<span style="color:#f92672">.</span>pdf(x, <span style="color:#ae81ff">0.0</span>, sigma_prop)
</span></span><span style="display:flex;"><span>h <span style="color:#f92672">=</span> <span style="color:#66d9ef">lambda</span> x: x<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span>
</span></span><span style="display:flex;"><span>is_hat1, sn_hat1, w1 <span style="color:#f92672">=</span> importance_estimate(x_prop, target_pdf, proposal_pdf, h)
</span></span><span style="display:flex;"><span>x_target <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>normal(<span style="color:#ae81ff">0.0</span>, <span style="color:#ae81ff">1.0</span>, size<span style="color:#f92672">=</span>N1)
</span></span><span style="display:flex;"><span>ref_est <span style="color:#f92672">=</span> (x_target<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span>)<span style="color:#f92672">.</span>mean()
</span></span><span style="display:flex;"><span>w_norm <span style="color:#f92672">=</span> w1 <span style="color:#f92672">/</span> w1<span style="color:#f92672">.</span>sum()
</span></span><span style="display:flex;"><span>ESS1 <span style="color:#f92672">=</span> <span style="color:#ae81ff">1.0</span> <span style="color:#f92672">/</span> np<span style="color:#f92672">.</span>sum(w_norm<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;=== Example: Estimate E_{N(0,1)}[X^2] ===&#34;</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;True Value = 1.0&#34;</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\t</span><span style="color:#e6db74">IS (unnorm) estimate = </span><span style="color:#e6db74">{</span>is_hat1<span style="color:#e6db74">:</span><span style="color:#e6db74">.6f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\t</span><span style="color:#e6db74">IS (self-norm) estimate = </span><span style="color:#e6db74">{</span>sn_hat1<span style="color:#e6db74">:</span><span style="color:#e6db74">.6f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\t</span><span style="color:#e6db74">Direct Sampling estimate (ref) = </span><span style="color:#e6db74">{</span>ref_est<span style="color:#e6db74">:</span><span style="color:#e6db74">.6f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;N = </span><span style="color:#e6db74">{</span>N1<span style="color:#e6db74">}</span><span style="color:#e6db74">, ESS (approx) = </span><span style="color:#e6db74">{</span>ESS1<span style="color:#e6db74">:</span><span style="color:#e6db74">.1f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>figure(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">8</span>,<span style="color:#ae81ff">6.5</span>))
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>hist(w1, bins<span style="color:#f92672">=</span><span style="color:#ae81ff">80</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>text(<span style="color:#ae81ff">0.5</span>, <span style="color:#f92672">-</span><span style="color:#ae81ff">120</span>, <span style="color:#e6db74">&#39;Histogram of importance weights w = π(x)/q(x)</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">Check concentration:</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">- Few samples dominate?</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">- Weights clustered?&#39;</span>, fontsize<span style="color:#f92672">=</span><span style="color:#ae81ff">12</span>, color<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;red&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#34;Importance weights histogram&#34;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;weight w = π(x)/q(x)&#34;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;count&#34;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>show()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>running_sn <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>cumsum(w1 <span style="color:#f92672">*</span> h(x_prop)) <span style="color:#f92672">/</span> np<span style="color:#f92672">.</span>cumsum(w1)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>figure(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">9</span>,<span style="color:#ae81ff">4</span>))
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>plot(running_sn)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>axhline(<span style="color:#ae81ff">1.0</span>, linestyle<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;--&#39;</span>, linewidth<span style="color:#f92672">=</span><span style="color:#ae81ff">1.5</span>, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#39;true E[X^2]=1&#39;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#34;Running self-normalized IS estimate of E[X^2]&#34;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;n (number of proposals used)&#34;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;estimate&#34;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>legend()
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>show()
</span></span></code></pre></div><pre><code>=== Example: Estimate E_{N(0,1)}[X^2] ===
True Value = 1.0
	IS (unnorm) estimate = 0.988525
	IS (self-norm) estimate = 0.995838
	Direct Sampling estimate (ref) = 0.975626
N = 5000, ESS (approx) = 3272.6
</code></pre>
<p><img src="/img/contents/post/mcmc-statics/3_monte-carlo/3_mcmc_monte-carlo_24_1.png" alt="png"></p>
<p><img src="/img/contents/post/mcmc-statics/3_monte-carlo/3_mcmc_monte-carlo_24_2.png" alt="png"></p>
<h4 id="example-estimating-probability">Example: Estimating Probability $p(Z>3)$</h4>
<blockquote>
<p>Shows IS reduces variance for rare events.</p></blockquote>
<p>Compare naive Monte Carlo with IS using $q=N(\mu,1)$ ($\mu=3.0, 2.5$).
True $p \approx 1.35 \times 10^{-3}$.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span>p_true <span style="color:#f92672">=</span> <span style="color:#ae81ff">1.0</span> <span style="color:#f92672">-</span> norm<span style="color:#f92672">.</span>cdf(<span style="color:#ae81ff">3.0</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;=== Example: Estimate tail probability p = P(Z&gt;3) ===&#34;</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;True p = </span><span style="color:#e6db74">{</span>p_true<span style="color:#e6db74">:</span><span style="color:#e6db74">.6e</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">single_run_compare</span>(N, mu_shift):
</span></span><span style="display:flex;"><span>    xs_naive <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>normal(<span style="color:#ae81ff">0.0</span>, <span style="color:#ae81ff">1.0</span>, size<span style="color:#f92672">=</span>N)
</span></span><span style="display:flex;"><span>    p_naive <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>mean(xs_naive <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">3.0</span>)
</span></span><span style="display:flex;"><span>    xs_is <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>normal(loc<span style="color:#f92672">=</span>mu_shift, scale<span style="color:#f92672">=</span><span style="color:#ae81ff">1.0</span>, size<span style="color:#f92672">=</span>N)
</span></span><span style="display:flex;"><span>    qx <span style="color:#f92672">=</span> norm<span style="color:#f92672">.</span>pdf(xs_is, loc<span style="color:#f92672">=</span>mu_shift, scale<span style="color:#f92672">=</span><span style="color:#ae81ff">1.0</span>)
</span></span><span style="display:flex;"><span>    px <span style="color:#f92672">=</span> norm<span style="color:#f92672">.</span>pdf(xs_is, loc<span style="color:#f92672">=</span><span style="color:#ae81ff">0.0</span>, scale<span style="color:#f92672">=</span><span style="color:#ae81ff">1.0</span>)
</span></span><span style="display:flex;"><span>    w <span style="color:#f92672">=</span> px <span style="color:#f92672">/</span> qx
</span></span><span style="display:flex;"><span>    indicators <span style="color:#f92672">=</span> (xs_is <span style="color:#f92672">&gt;</span> <span style="color:#ae81ff">3.0</span>)<span style="color:#f92672">.</span>astype(float)
</span></span><span style="display:flex;"><span>    p_is <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>mean(w <span style="color:#f92672">*</span> indicators)
</span></span><span style="display:flex;"><span>    ess <span style="color:#f92672">=</span> (w<span style="color:#f92672">.</span>sum()<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span>) <span style="color:#f92672">/</span> (np<span style="color:#f92672">.</span>sum(w<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span>) <span style="color:#f92672">+</span> <span style="color:#ae81ff">1e-300</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> p_naive, p_is, ess, w, xs_is
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>N <span style="color:#f92672">=</span> <span style="color:#ae81ff">2000</span>
</span></span><span style="display:flex;"><span>reps <span style="color:#f92672">=</span> <span style="color:#ae81ff">300</span>
</span></span><span style="display:flex;"><span>mus <span style="color:#f92672">=</span> [<span style="color:#ae81ff">3.0</span>, <span style="color:#ae81ff">2.5</span>]
</span></span><span style="display:flex;"><span>results <span style="color:#f92672">=</span> {}
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> mu <span style="color:#f92672">in</span> mus:
</span></span><span style="display:flex;"><span>    p_naive_list <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>    p_is_list <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>    ess_list <span style="color:#f92672">=</span> []
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">for</span> r <span style="color:#f92672">in</span> range(reps):
</span></span><span style="display:flex;"><span>        p_naive, p_is, ess, w, xs_is <span style="color:#f92672">=</span> single_run_compare(N, mu_shift<span style="color:#f92672">=</span>mu)
</span></span><span style="display:flex;"><span>        p_naive_list<span style="color:#f92672">.</span>append(p_naive)
</span></span><span style="display:flex;"><span>        p_is_list<span style="color:#f92672">.</span>append(p_is)
</span></span><span style="display:flex;"><span>        ess_list<span style="color:#f92672">.</span>append(ess)
</span></span><span style="display:flex;"><span>    p_naive_arr <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(p_naive_list)
</span></span><span style="display:flex;"><span>    p_is_arr <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array(p_is_list)
</span></span><span style="display:flex;"><span>    results[mu] <span style="color:#f92672">=</span> {
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;p_naive_mean&#34;</span>: p_naive_arr<span style="color:#f92672">.</span>mean(),
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;p_naive_std&#34;</span>: p_naive_arr<span style="color:#f92672">.</span>std(ddof<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>),
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;p_is_mean&#34;</span>: p_is_arr<span style="color:#f92672">.</span>mean(),
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;p_is_std&#34;</span>: p_is_arr<span style="color:#f92672">.</span>std(ddof<span style="color:#f92672">=</span><span style="color:#ae81ff">1</span>),
</span></span><span style="display:flex;"><span>        <span style="color:#e6db74">&#34;ESS_mean&#34;</span>: np<span style="color:#f92672">.</span>mean(ess_list)
</span></span><span style="display:flex;"><span>    }
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">&#34;Comparison results (N=2000, reps=300):&#34;</span>)
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">for</span> mu <span style="color:#f92672">in</span> mus:
</span></span><span style="display:flex;"><span>    r <span style="color:#f92672">=</span> results[mu]
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;</span><span style="color:#ae81ff">\n</span><span style="color:#e6db74">proposal N(</span><span style="color:#e6db74">{</span>mu<span style="color:#e6db74">}</span><span style="color:#e6db74">,1):&#34;</span>)
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;  naive: mean=</span><span style="color:#e6db74">{</span>r[<span style="color:#e6db74">&#39;p_naive_mean&#39;</span>]<span style="color:#e6db74">:</span><span style="color:#e6db74">.3e</span><span style="color:#e6db74">}</span><span style="color:#e6db74">, std=</span><span style="color:#e6db74">{</span>r[<span style="color:#e6db74">&#39;p_naive_std&#39;</span>]<span style="color:#e6db74">:</span><span style="color:#e6db74">.3e</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;  IS   : mean=</span><span style="color:#e6db74">{</span>r[<span style="color:#e6db74">&#39;p_is_mean&#39;</span>]<span style="color:#e6db74">:</span><span style="color:#e6db74">.3e</span><span style="color:#e6db74">}</span><span style="color:#e6db74">, std=</span><span style="color:#e6db74">{</span>r[<span style="color:#e6db74">&#39;p_is_std&#39;</span>]<span style="color:#e6db74">:</span><span style="color:#e6db74">.3e</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>    print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;  mean ESS (IS) ~ </span><span style="color:#e6db74">{</span>r[<span style="color:#e6db74">&#39;ESS_mean&#39;</span>]<span style="color:#e6db74">:</span><span style="color:#e6db74">.1f</span><span style="color:#e6db74">}</span><span style="color:#e6db74"> (out of N=</span><span style="color:#e6db74">{</span>N<span style="color:#e6db74">}</span><span style="color:#e6db74">)&#34;</span>)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">if</span> r[<span style="color:#e6db74">&#39;p_is_std&#39;</span>]<span style="color:#f92672">&gt;</span><span style="color:#ae81ff">0</span>:
</span></span><span style="display:flex;"><span>        print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;  variance reduction factor (naive_var / IS_var) ≈ </span><span style="color:#e6db74">{</span>(r[<span style="color:#e6db74">&#39;p_naive_std&#39;</span>]<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span>)<span style="color:#f92672">/</span>(r[<span style="color:#e6db74">&#39;p_is_std&#39;</span>]<span style="color:#f92672">**</span><span style="color:#ae81ff">2</span>)<span style="color:#e6db74">:</span><span style="color:#e6db74">.3f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Plots omitted for brevity, similar to Chinese version</span>
</span></span></code></pre></div><pre><code>=== Example: Estimate tail probability p = P(Z&gt;3) ===
True p = 1.349898e-03
Comparison results (N=2000, reps=300):

proposal N(3.0,1):
  naive: mean=1.372e-03, std=7.776e-04
  IS   : mean=1.353e-03, std=5.413e-05
  mean ESS (IS) ~ 18.6 (out of N=2000)
  variance reduction factor (naive_var / IS_var) ≈ 206.352

proposal N(2.5,1):
  naive: mean=1.412e-03, std=8.001e-04
  IS   : mean=1.352e-03, std=6.596e-05
  mean ESS (IS) ~ 35.6 (out of N=2000)
  variance reduction factor (naive_var / IS_var) ≈ 147.125
</code></pre>
<h2 id="variance-reduction-techniques">Variance Reduction Techniques</h2>
<p>In Monte Carlo, the core problem is <strong>large sample variance, slow convergence</strong>. We want to reduce variance under <strong>same sample budget</strong>.</p>
<h3 id="method-1-antithetic-variates">Method 1️⃣ Antithetic Variates</h3>
<p><strong>Idea</strong>: Construct pairs with <strong>negative correlation</strong> to reduce variance of sample mean.
For symmetric distributions (like $N(0,1)$), use pairs $(X, -X)$. If integrand $g$ is monotonic, $g(X)$ and $g(-X)$ are often negatively correlated.</p>
<p>Estimator: $\hat\mu_{\text{anti}}=\frac{1}{m}\sum_{i=1}^m \frac{g(X_i)+g(-X_i)}{2}$.</p>
<h3 id="method-2-control-variates">Method 2️⃣ Control Variates</h3>
<p><strong>Idea</strong>: Find variable $Y$ highly correlated with target $h$, having <strong>known expectation</strong>. Correct bias:
</p>
$$
\hat\mu_{\text{cv}}=\bar{h}-\beta(\bar{Y}-\mathbb{E}[Y]),
\quad \beta^*=\frac{\operatorname{Cov}(h,Y)}{\operatorname{Var}(Y)}.
$$<p>
Intuition: If $\bar{Y}$ is above true mean, $\bar{h}$ is likely above true mean too (if positively correlated), so pull it back.</p>
<h4 id="example-estimate--for">Example: Estimate $\mu_1=E[e^X]$ for $X\sim N(0,1)$</h4>
<p>True value $e^{0.5} \approx 1.6487$.</p>
<ul>
<li><strong>Antithetic</strong>: Pair $(X, -X)$.</li>
<li><strong>Control Variates</strong>: $Y=X^2-1$, known mean 0, strong correlation with $e^X$.</li>
</ul>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#75715e"># Code visualizing Naive vs Antithetic vs Control Variates</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># See Chinese version for full implementation; results show significant variance reduction.</span>
</span></span></code></pre></div><h3 id="method-3-stratified-sampling-1d--lhs">Method 3️⃣ Stratified Sampling (1D $\approx$ LHS)</h3>
<p><strong>Idea</strong>: Split domain into <strong>strata</strong> (sub-intervals), ensuring every sub-interval is sampled.
Avoids &ldquo;clumping&rdquo; of random points.</p>
<p>Mathematical Estimator:
</p>
$$
\hat{I}_{\text{strat}} = \frac{1}{N} \sum_{j=1}^N f\Big(U_j^*\Big), \quad U_j^* \sim \text{Uniform}\Big(\tfrac{j-1}{N}, \tfrac{j}{N}\Big).
$$<p><strong>Intuition</strong>: Forces uniform coverage over domain $\to$ extremely low variance for smooth functions.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-python" data-lang="python"><span style="display:flex;"><span><span style="color:#f92672">import</span> numpy <span style="color:#66d9ef">as</span> np
</span></span><span style="display:flex;"><span><span style="color:#f92672">import</span> matplotlib.pyplot <span style="color:#66d9ef">as</span> plt
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Integral target: exp(x) on [0,1]</span>
</span></span><span style="display:flex;"><span>f <span style="color:#f92672">=</span> <span style="color:#66d9ef">lambda</span> x: np<span style="color:#f92672">.</span>exp(x)
</span></span><span style="display:flex;"><span>true_val <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>e <span style="color:#f92672">-</span> <span style="color:#ae81ff">1</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">mc_integral</span>(N<span style="color:#f92672">=</span><span style="color:#ae81ff">1000</span>):
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>rand(N)
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> f(x)<span style="color:#f92672">.</span>mean()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">def</span> <span style="color:#a6e22e">stratified_integral</span>(N<span style="color:#f92672">=</span><span style="color:#ae81ff">1000</span>):
</span></span><span style="display:flex;"><span>    strata <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>linspace(<span style="color:#ae81ff">0</span>, <span style="color:#ae81ff">1</span>, N<span style="color:#f92672">+</span><span style="color:#ae81ff">1</span>)
</span></span><span style="display:flex;"><span>    u <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>random<span style="color:#f92672">.</span>rand(N)
</span></span><span style="display:flex;"><span>    <span style="color:#75715e"># Map u to each stratum</span>
</span></span><span style="display:flex;"><span>    x <span style="color:#f92672">=</span> strata[:<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>] <span style="color:#f92672">+</span> u <span style="color:#f92672">*</span> (strata[<span style="color:#ae81ff">1</span>:] <span style="color:#f92672">-</span> strata[:<span style="color:#f92672">-</span><span style="color:#ae81ff">1</span>])
</span></span><span style="display:flex;"><span>    <span style="color:#66d9ef">return</span> f(x)<span style="color:#f92672">.</span>mean()
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Comparison</span>
</span></span><span style="display:flex;"><span>R <span style="color:#f92672">=</span> <span style="color:#ae81ff">500</span>
</span></span><span style="display:flex;"><span>N <span style="color:#f92672">=</span> <span style="color:#ae81ff">1000</span>
</span></span><span style="display:flex;"><span>mc_vals <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array([mc_integral(N) <span style="color:#66d9ef">for</span> _ <span style="color:#f92672">in</span> range(R)])
</span></span><span style="display:flex;"><span>strat_vals <span style="color:#f92672">=</span> np<span style="color:#f92672">.</span>array([stratified_integral(N) <span style="color:#66d9ef">for</span> _ <span style="color:#f92672">in</span> range(R)])
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;True value = </span><span style="color:#e6db74">{</span>true_val<span style="color:#e6db74">:</span><span style="color:#e6db74">.6f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;MC: mean=</span><span style="color:#e6db74">{</span>mc_vals<span style="color:#f92672">.</span>mean()<span style="color:#e6db74">:</span><span style="color:#e6db74">.6f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">, std=</span><span style="color:#e6db74">{</span>mc_vals<span style="color:#f92672">.</span>std()<span style="color:#e6db74">:</span><span style="color:#e6db74">.6f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>print(<span style="color:#e6db74">f</span><span style="color:#e6db74">&#34;Stratified: mean=</span><span style="color:#e6db74">{</span>strat_vals<span style="color:#f92672">.</span>mean()<span style="color:#e6db74">:</span><span style="color:#e6db74">.6f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">, std=</span><span style="color:#e6db74">{</span>strat_vals<span style="color:#f92672">.</span>std()<span style="color:#e6db74">:</span><span style="color:#e6db74">.6f</span><span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>figure(figsize<span style="color:#f92672">=</span>(<span style="color:#ae81ff">8</span>,<span style="color:#ae81ff">5</span>))
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>hist(mc_vals, bins<span style="color:#f92672">=</span><span style="color:#ae81ff">30</span>, alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.6</span>, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Plain MC&#34;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>hist(strat_vals, bins<span style="color:#f92672">=</span><span style="color:#ae81ff">30</span>, alpha<span style="color:#f92672">=</span><span style="color:#ae81ff">0.6</span>, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;Stratified Sampling&#34;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>axvline(true_val, color<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;red&#34;</span>, linestyle<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;--&#34;</span>, label<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;True value&#34;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>title(<span style="color:#e6db74">&#34;MC vs Stratified Sampling (Integral of exp(x) on [0,1])&#34;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>xlabel(<span style="color:#e6db74">&#34;Estimate value&#34;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>ylabel(<span style="color:#e6db74">&#34;Frequency&#34;</span>)
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>legend()
</span></span><span style="display:flex;"><span>plt<span style="color:#f92672">.</span>show()
</span></span></code></pre></div><pre><code>True value = 1.718282
MC: mean=1.717769, std=0.015955
Stratified: mean=1.718282, std=0.000016
</code></pre>
<p><img src="/img/contents/post/mcmc-statics/3_monte-carlo/3_mcmc_monte-carlo_38_1.png" alt="png"></p>
<h2 id="practical-guide">Practical Guide</h2>
<ol>
<li><strong>Scenario Matching</strong>:
<ul>
<li>Monotonic/Symmetric: Try <strong>Antithetic</strong>.</li>
<li>Approx Linear/Known Mean feature: Try <strong>Control Variates</strong>.</li>
<li>Smooth 1D Integration: <strong>Stratified/LHS</strong> is very strong.</li>
</ul>
</li>
<li><strong>Selecting Control Variates</strong>:
<ul>
<li>Strong correlation with target.</li>
<li>Known expectation.</li>
</ul>
</li>
<li><strong>Stratification</strong>:
<ul>
<li>1D: Equal spacing is great.</li>
<li>Multi-D: Latin Hypercube Sampling (LHS).</li>
</ul>
</li>
<li><strong>Relationship with IS</strong>:
<ul>
<li>IS is for Rare Events/Tail or distribution mismatch.</li>
<li>Antithetic/Control/Stratified are for general variance reduction on &ldquo;normal&rdquo; tasks.</li>
<li>Can combine (e.g., Stratified + IS).</li>
</ul>
</li>
<li><strong>Diagnostics</strong>:
<ul>
<li>Run replicates to estimate Std Dev.</li>
<li>Monitor running estimates.</li>
</ul>
</li>
</ol>
<h1 id="further-reading">Further Reading</h1>
<ul>
<li>Monte Carlo Methods Explained</li>
</ul>


        
          <div class="blog-tags">
            
              <a href="http://localhost:1313/tags/monte-carlo/">Monte Carlo</a>&nbsp;
            
              <a href="http://localhost:1313/tags/sampling/">Sampling</a>&nbsp;
            
              <a href="http://localhost:1313/tags/mathematics/">Mathematics</a>&nbsp;
            
              <a href="http://localhost:1313/tags/python/">python</a>&nbsp;
            
          </div>
        

        
            <hr/>
            <section id="social-share">
              <div class="list-inline footer-links">
                

<div class="share-box" aria-hidden="true">
  <ul class="share">
    
    <li>
      <a
        href="//twitter.com/share?url=http%3a%2f%2flocalhost%3a1313%2fpost%2fmcmc-statics%2fmonte-carlo%2f&amp;text=Monte%20Carlo%20Sampling&amp;via="
        target="_blank"
        title="Share on Twitter"
        class="share-btn twitter"
      >
        <i class="fab fa-twitter"></i>
      </a>
    </li>

    
    <li>
      <a
        href="//www.facebook.com/sharer/sharer.php?u=http%3a%2f%2flocalhost%3a1313%2fpost%2fmcmc-statics%2fmonte-carlo%2f"
        target="_blank"
        title="Share on Facebook"
        class="share-btn facebook"
      >
        <i class="fab fa-facebook"></i>
      </a>
    </li>

    
    <li>
      <a
        href="//service.weibo.com/share/share.php?url=http%3a%2f%2flocalhost%3a1313%2fpost%2fmcmc-statics%2fmonte-carlo%2f&amp;appkey=&amp;title=Monte%20Carlo%20Sampling&amp;pic="
        target="_blank"
        title="Share on Weibo"
        class="share-btn weibo"
      >
        <i class="fab fa-weibo"></i>
      </a>
    </li>

    
    <li>
      <a
        href="javascript:void(0);"
        onclick="openWechatModal('http:\/\/localhost:1313\/post\/mcmc-statics\/monte-carlo\/')"
        title="Share on WeChat"
        class="share-btn wechat"
      >
        <i class="fab fa-weixin"></i>
      </a>
    </li>

    
    <li>
      <a
        href="//www.linkedin.com/shareArticle?url=http%3a%2f%2flocalhost%3a1313%2fpost%2fmcmc-statics%2fmonte-carlo%2f&amp;title=Monte%20Carlo%20Sampling"
        target="_blank"
        title="Share on LinkedIn"
        class="share-btn linkedin"
      >
        <i class="fab fa-linkedin"></i>
      </a>
    </li>

    
    <li>
      <a
        href="javascript:void(0);"
        onclick="copyToClipboard('http:\/\/localhost:1313\/post\/mcmc-statics\/monte-carlo\/', 'Monte Carlo Sampling')"
        title="Copy Link"
        class="share-btn copy-link"
      >
        <i class="fas fa-link"></i>
      </a>
    </li>
  </ul>
</div>


<div id="wechat-modal" class="wechat-modal">
  <div class="wechat-modal-content">
    <span class="wechat-close" onclick="closeWechatModal()">&times;</span>
    <h4>
      Scan to Share <br />
      微信扫一扫分享
    </h4>
    <div id="qrcode" class="qrcode-container"></div>
  </div>
</div>

<script type="text/javascript">
  function copyToClipboard(url, title) {
    navigator.clipboard.writeText(url).then(
      function () {
        
        var existingToast = document.getElementById("share-toast");
        if (existingToast) {
          existingToast.remove();
        }

        var toast = document.createElement("div");
        toast.id = "share-toast";
        toast.innerText = "Link copied to clipboard!";
        toast.style.position = "fixed";
        toast.style.bottom = "20px";
        toast.style.left = "50%";
        toast.style.transform = "translateX(-50%)";
        toast.style.backgroundColor = "rgba(0,0,0,0.8)";
        toast.style.color = "#fff";
        toast.style.padding = "10px 20px";
        toast.style.borderRadius = "5px";
        toast.style.zIndex = "10000";
        toast.style.opacity = "0";
        toast.style.transition = "opacity 0.5s ease-in-out";

        document.body.appendChild(toast);

        
        void toast.offsetWidth;

        toast.style.opacity = "1";

        setTimeout(function () {
          toast.style.opacity = "0";
          setTimeout(function () {
            if (toast.parentNode) toast.parentNode.removeChild(toast);
          }, 500);
        }, 3000);
      },
      function (err) {
        console.error("Could not copy text: ", err);
      },
    );
  }

  function openWechatModal(url) {
    var modal = document.getElementById("wechat-modal");
    modal.style.display = "flex";
    var qrcodeContainer = document.getElementById("qrcode");
    qrcodeContainer.innerHTML = "";
    var img = document.createElement("img");
    img.src =
      "https://api.qrserver.com/v1/create-qr-code/?size=200x200&data=" +
      encodeURIComponent(url);
    img.style.width = "200px";
    img.style.height = "200px";
    qrcodeContainer.appendChild(img);
  }

  function closeWechatModal() {
    var modal = document.getElementById("wechat-modal");
    modal.style.display = "none";
  }

  
  window.onclick = function (event) {
    var modal = document.getElementById("wechat-modal");
    if (event.target == modal) {
      modal.style.display = "none";
    }
  };
</script>


              </div>
            </section>
        

        
          
            
          

          
                  <h4 class="see-also">See also</h4>
                  <ul>
                
                
                    <li><a href="/post/mcmc-statics/markov-chains/">Understanding Markov Chains</a></li>
                
                    <li><a href="/post/mcmc-statics/intro-mcmc/">Introduction to MCMC</a></li>
                
                    <li><a href="/post/mcmc-statics/probability/">What is Probability?</a></li>
                
                    <li><a href="/post/mcmc-statics/random-variables/">Random Variables and Sampling</a></li>
                
                    <li><a href="/notes/probability_theory_preliminaries/">[Course Notes] Probability Theory and Mathematical Statistics | Preliminaries</a></li>
                
              </ul>

          
        
      </article>

      
        <ul class="pager blog-pager">
          
            <li class="previous">
              <a href="http://localhost:1313/post/mcmc-statics/intro-mcmc/" data-toggle="tooltip" data-placement="top" title="Introduction to MCMC">&larr; Previous Post</a>
            </li>
          
          
            <li class="next">
              <a href="http://localhost:1313/post/mcmc-statics/markov-chains/" data-toggle="tooltip" data-placement="top" title="Understanding Markov Chains">Next Post &rarr;</a>
            </li>
          
        </ul>
      


      

    </div>
    
    
    <div class="col-lg-3 visible-lg-block">
      
      
      <div class="sidebar-toc">
        <h2 class="sidebar-toc-title">目录</h2>
        <nav id="TableOfContents">
  <ul>
    <li><a href="#monte-carlo-method">Monte Carlo Method</a>
      <ul>
        <li><a href="#core-idea">Core Idea</a></li>
        <li><a href="#law-of-large-numbers--central-limit-theorem">Law of Large Numbers &amp; Central Limit Theorem</a>
          <ul>
            <li><a href="#example-1-estimating--via-monte-carlo-implementation">Example 1: Estimating  via Monte Carlo Implementation</a></li>
            <li><a href="#example-2-convergence-speed-visualization">Example 2: Convergence Speed Visualization</a></li>
          </ul>
        </li>
        <li><a href="#rejection-sampling">Rejection Sampling</a>
          <ul>
            <li><a href="#core-idea-1">Core Idea</a></li>
            <li><a href="#algorithm-steps">Algorithm Steps</a></li>
            <li><a href="#examples-in-code">Examples in Code</a></li>
            <li><a href="#example-3-estimating--via-rejection-sampling-wait-this-is-redundant-with-first-example-no-different-perspective">Example 3: Estimating  via Rejection Sampling (Wait, this is redundant with first example? No, different perspective)</a></li>
            <li><a href="#summary">Summary</a></li>
          </ul>
        </li>
        <li><a href="#importance-sampling-is">Importance Sampling (IS)</a>
          <ul>
            <li><a href="#goal-and-core-idea">Goal and Core Idea</a></li>
            <li><a href="#intuition-why-it-works">Intuition (Why it works)</a></li>
            <li><a href="#algorithm">Algorithm</a></li>
            <li><a href="#examples">Examples</a></li>
          </ul>
        </li>
        <li><a href="#variance-reduction-techniques">Variance Reduction Techniques</a>
          <ul>
            <li><a href="#method-1-antithetic-variates">Method 1️⃣ Antithetic Variates</a></li>
            <li><a href="#method-2-control-variates">Method 2️⃣ Control Variates</a></li>
            <li><a href="#method-3-stratified-sampling-1d--lhs">Method 3️⃣ Stratified Sampling (1D  LHS)</a></li>
          </ul>
        </li>
        <li><a href="#practical-guide">Practical Guide</a></li>
      </ul>
    </li>
    <li><a href="#further-reading">Further Reading</a></li>
  </ul>
</nav>
      </div>
      
    </div>
    
  </div>
</div>

      <footer>
  <div class="container">
    
    <div class="row">
      <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
        <ul class="list-inline text-center footer-links">
          
              <li>
		
		  <a href="mailto:ele.qiong@gmail.com" title="Email me">
		
                  <span class="fa-stack fa-lg">
                    <i class="fas fa-circle fa-stack-2x"></i>
                    <i class="fas fa-envelope fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
              <li>
		
		  <a href="https://github.com/ictar" title="GitHub">
		
                  <span class="fa-stack fa-lg">
                    <i class="fas fa-circle fa-stack-2x"></i>
                    <i class="fab fa-github fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
              <li>
		
		  <a href="https://linkedin.com/in/qiongjie-xu" title="LinkedIn">
		
                  <span class="fa-stack fa-lg">
                    <i class="fas fa-circle fa-stack-2x"></i>
                    <i class="fab fa-linkedin fa-stack-1x fa-inverse"></i>
                  </span>
                </a>
              </li>
          
          
          
        </ul>
        <p class="credits copyright text-muted">
          
            
              <a href="https://www.xuqiongjie.com">Qiongjie.X</a>
            
          

          &nbsp;&bull;&nbsp;&copy;
          
            2026
          

          
            &nbsp;&bull;&nbsp;
            <a href="http://localhost:1313/">Qiongjie&#39;s Notes</a>
          
        </p>
        
        <p class="credits theme-by text-muted">
          <a href="https://gohugo.io">Hugo v0.147.4</a> powered &nbsp;&bull;&nbsp; Theme <a href="https://github.com/halogenica/beautifulhugo">Beautiful Hugo</a> adapted from <a href="https://deanattali.com/beautiful-jekyll/">Beautiful Jekyll</a>
          
        </p>
      </div>
    </div>
  </div>
</footer><script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/katex.min.js" integrity="sha384-G0zcxDFp5LWZtDuRMnBkk3EphCK1lhEf4UEyEM693ka574TZGwo4IWwS6QLzM/2t" crossorigin="anonymous"></script>
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.7/dist/contrib/auto-render.min.js" integrity="sha384-+VBxd3r6XgURycqtZ117nYw44OOcIax56Z4dCRWbxyPt0Koah1uHoK0o4+/RRE05" crossorigin="anonymous" onload="renderMathInElement(document.body);"></script>
<script src="https://code.jquery.com/jquery-3.7.0.slim.min.js" integrity="sha384-w5y/xIeYixWvfM+A1cEbmHPURnvyqmVg5eVENruEdDjcyRLUSNej7512JQGspFUr" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@3.4.1/dist/js/bootstrap.min.js" integrity="sha384-aJ21OjlMXNL5UyIl/XNwTMqvzeRMZH2w8c5cRVpzpU8Y5bApTppSuUkhZXN0VxHd" crossorigin="anonymous"></script>

<script src="http://localhost:1313/js/main.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe.min.js" integrity="sha384-QELNnmcmU8IR9ZAykt67vGr9/rZJdHbiWi64V88fCPaOohUlHCqUD/unNN0BXSqy" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/photoswipe/4.1.2/photoswipe-ui-default.min.js" integrity="sha384-m67o7SkQ1ALzKZIFh4CiTA8tmadaujiTa9Vu+nqPSwDOqHrDmxLezTdFln8077+q" crossorigin="anonymous"></script><script src="http://localhost:1313/js/load-photoswipe.js"></script>









<script src="http://localhost:1313/js/toc-enhancements.js"></script>


    
  </body>
</html>

