---
title: "éšæœºä¼˜åŒ–ç®—æ³•è¯¦è§£ï¼šæ¨¡æ‹Ÿé€€ç«ä¸ Pincus å®šç†"
slug: "stochastic-optimization"
date: 2026-02-02
summary: "å½“ä¼˜åŒ–é—®é¢˜é™·äºå±€éƒ¨æœ€ä¼˜çš„è¿·å®«æ—¶ï¼Œç¡®å®šæ€§ç®—æ³•å¾€å¾€æŸæ‰‹æ— ç­–ã€‚æœ¬æ–‡å°†å¸¦ä½ è¿›å…¥éšæœºä¼˜åŒ–çš„ä¸–ç•Œï¼Œæ¢ç´¢å¦‚ä½•å°†å¯»æ‰¾æœ€å°èƒ½é‡çš„é—®é¢˜è½¬åŒ–ä¸ºå¯»æ‰¾æœ€å¤§æ¦‚ç‡çš„é—®é¢˜ã€‚æˆ‘ä»¬å°†æ·±å…¥å‰–ææ¨¡æ‹Ÿé€€ç«ç®—æ³•ï¼ˆSimulated Annealingï¼‰çš„ç‰©ç†ç›´è§‰ä¸æ•°å­¦åŸç†ï¼Œé€šè¿‡åŠ¨æ€å¯è§†åŒ–å±•ç¤ºå…¶â€œé«˜æ¸©æ¢ç´¢ã€ä½æ¸©é”å®šâ€çš„ä¼˜é›…æœºåˆ¶ï¼Œå¹¶è¯¦ç»†æ¨å¯¼ Pincus å®šç†ï¼Œä»æ•°å­¦ä¸Šè¯æ˜ä¸ºä½•é€€ç«ç®—æ³•èƒ½æ‰¾åˆ°å…¨å±€æœ€ä¼˜è§£ã€‚"
tags: ["éšæœºä¼˜åŒ–", "æ¨¡æ‹Ÿé€€ç«", "ä¼˜åŒ–ç®—æ³•", "æœºå™¨å­¦ä¹ ", "Pincuså®šç†", "Pythonå®ç°"]
keywords: ["éšæœºä¼˜åŒ–", "æ¨¡æ‹Ÿé€€ç«", "Simulated Annealing", "Pincus Theorem", "å…¨å±€æœ€ä¼˜", "éå‡¸ä¼˜åŒ–"]
series: ["MCMC"]
toc: true
draft: false
---

# éšæœºä¼˜åŒ–ï¼ˆStochastic Optimizationï¼‰

> åœ¨ä¸€ä¸ªå……æ»¡ä¸ç¡®å®šæ€§ï¼ˆå™ªå£°ï¼‰æˆ–è€…æå…¶å¤æ‚ï¼ˆéå‡¸ï¼‰çš„ç¯å¢ƒä¸­ï¼Œå¦‚ä½•åˆ©ç”¨â€œéšæœºæ€§â€æ¥æ‰¾åˆ°æœ€ä½³æ–¹æ¡ˆã€‚

## ä»ç¡®å®šæ€§ä¼˜åŒ–åˆ°éšæœºä¼˜åŒ–

### é—®é¢˜çš„å®šä¹‰ï¼šä»ç¡®å®šæ€§ä¸–ç•Œå‡ºå‘

ä¸€åˆ‡å§‹äºä¸€ä¸ªç»å…¸çš„ä¼˜åŒ–éš¾é¢˜ã€‚å‡è®¾æˆ‘ä»¬éœ€è¦å¯»æ‰¾ä¸€ä¸ªç³»ç»Ÿçš„æœ€ä¼˜çŠ¶æ€ï¼Œç”¨æ•°å­¦è¯­è¨€æè¿°å°±æ˜¯ï¼š
$$\min_{x \in Q} E(x) = m$$
å…¶ä¸­ï¼š
- $x$ æ˜¯æˆ‘ä»¬è¦å¯»æ‰¾çš„å‚æ•°ï¼ˆæ¯”å¦‚æ¨¡å‹çš„æƒé‡ã€åˆ†å­çš„æ„å‹ï¼‰ã€‚
- $E(x)$ æ˜¯æˆ‘ä»¬çš„èƒ½é‡å‡½æ•°ï¼ˆåœ¨æœºå™¨å­¦ä¹ ä¸­ç§°ä¸ºæŸå¤±å‡½æ•° Loss Functionï¼‰ã€‚æˆ‘ä»¬çš„ç›®æ ‡æ˜¯è®©å®ƒè¶Šå°è¶Šå¥½ã€‚
- $m$ æ˜¯ç†è®ºä¸Šçš„å…¨å±€æœ€å°å€¼ã€‚

åœ¨ç¡®å®šæ€§ä¼˜åŒ–ï¼ˆDeterministic Methodï¼‰çš„ä¸–ç•Œé‡Œï¼Œæˆ‘ä»¬é€šå¸¸åƒçå­ä¸‹å±±ä¸€æ ·ï¼Œæ²¿ç€æ¢¯åº¦çš„æ–¹å‘ä¸€æ­¥æ­¥æŒªåŠ¨ã€‚è¿™åœ¨ç®€å•çš„åœ°å½¢ï¼ˆå‡¸å‡½æ•°ï¼‰å¾ˆæœ‰æ•ˆï¼Œä½†åœ¨å¤æ‚çš„ç°å®é—®é¢˜ä¸­ï¼Œæˆ‘ä»¬å¾ˆå®¹æ˜“è¢«å›°åœ¨å±€éƒ¨æœ€ä¼˜çš„â€œå‘â€é‡Œå‡ºä¸æ¥ã€‚

### æ¬¢è¿æ¥åˆ°éšæœºä¸–ç•Œ (Welcome to Stochastic World)
ä¸ºäº†è·³å‡ºå±€éƒ¨æœ€ä¼˜çš„é™·é˜±ï¼Œæˆ‘ä»¬ä½¿ç”¨ä¸€ä¸ªå…³é”®çš„è½¬æ¢ï¼š**æˆ‘ä»¬å°†â€œå¯»æ‰¾æœ€å°èƒ½é‡â€çš„é—®é¢˜ï¼Œè½¬åŒ–ä¸ºäº†â€œå¯»æ‰¾æœ€å¤§æ¦‚ç‡â€çš„é—®é¢˜ã€‚**

è¿™ç§è½¬æ¢åŸºäºç‰©ç†å­¦ä¸­çš„ **[æ³¢å°”å…¹æ›¼åˆ†å¸ƒï¼ˆBoltzmann Distributionï¼‰](https://zh.wikipedia.org/wiki/%E7%8E%BB%E5%B0%94%E5%85%B9%E6%9B%BC%E5%88%86%E5%B8%83)**ã€‚æˆ‘ä»¬å®šä¹‰ä¸€ä¸ªæ–°çš„æ¦‚ç‡å¯†åº¦å‡½æ•°ï¼ˆPDFï¼‰ï¼š
$$f(x) = A e^{-E(x)}$$

å…¶ä¸­ï¼Œ
- $f(x)$ï¼šæ¦‚ç‡å¯†åº¦å‡½æ•°ï¼Œå¿…é¡»å¤§äºé›¶
- $A = \frac{1}{\int e^{-E(x)} \, dx}$æ˜¯ **å½’ä¸€åŒ–å¸¸æ•° (Normalization Constant)**
  - åœ¨ç»Ÿè®¡ç‰©ç†å­¦ä¸­ï¼Œ$A$ çš„å€’æ•°æœ‰ä¸€ä¸ªå¤§åé¼é¼çš„åå­—ï¼šé…åˆ†å‡½æ•° (Partition Function)ï¼Œé€šå¸¸ç”¨ç¬¦å· $Z$ è¡¨ç¤ºã€‚$$Z = \frac{1}{A} = \int e^{-E(x)} \, dx$$

è¿™é‡Œæœ‰ä¸€ä¸ªæå…¶å·§å¦™çš„å¯¹åº”å…³ç³»ï¼š
- $E(x)$ è¶Šå°ï¼ˆèƒ½é‡è¶Šä½ï¼Œæ˜¯æˆ‘ä»¬æƒ³è¦çš„ï¼‰ã€‚
- $e^{-E(x)}$ å°±è¶Šå¤§ã€‚
- è¿™æ„å‘³ç€ï¼Œ$E(x)$ çš„ **æœ€å°å€¼ç‚¹**ï¼Œæ°å¥½å¯¹åº”äº†æ¦‚ç‡åˆ†å¸ƒ $f(x)$ çš„ **å³°å€¼ï¼ˆæœ€å¤§å€¼ï¼‰**ã€‚

å› æ­¤ï¼ŒåŸé—®é¢˜ç­‰ä»·è½¬åŒ–ä¸ºï¼š
$$\min E(x) \iff \max f(x)$$

#### ä¸ºä»€ä¹ˆè¦åšè¿™ä¸ªè½¬æ¢ï¼Ÿ

å› ä¸ºåœ¨éšæœºä¸–ç•Œé‡Œï¼Œæˆ‘ä»¬ä¸å†æ‰§ç€äºâ€œæ¯ä¸€æ­¥å¿…é¡»å¾€ä½å¤„èµ°â€ï¼Œè€Œæ˜¯å°†è§£ç©ºé—´çœ‹ä½œä¸€ä¸ªæ¦‚ç‡åœºã€‚æˆ‘ä»¬å…è®¸ç®—æ³•åœ¨ä¸€å®šæ¦‚ç‡ä¸‹æ¥å—â€œåç»“æœâ€ï¼Œæ­£æ˜¯è¿™ç§æœºåˆ¶è®©æˆ‘ä»¬æœ‰æœºä¼šè·³å‡ºå±€éƒ¨é™·é˜±ã€‚

#### å¼•å…¥æ¸©åº¦å‚æ•° $\lambda$
ä¸ºäº†æ§åˆ¶æœç´¢çš„è¿‡ç¨‹ï¼Œæˆ‘ä»¬å¼•å…¥ä¸€ä¸ªè‡³å…³é‡è¦çš„å‚æ•° $\lambda$ã€‚äºæ˜¯è¿™ä¸ªæ¦‚ç‡å¯†åº¦å‡½æ•°å°±å˜æˆäº†ï¼š
$$f(x, \lambda) = A_\lambda e^{-\lambda E(x)}$$
å…¶ä¸­ï¼Œ$\lambda$ å¤§äºé›¶å¹¶ä¸æ¸©åº¦ $T$ æˆåæ¯”ï¼š$$\lambda = \frac{1}{T} \ge 0$$

æ•…è€Œï¼Œ$A$å°±å˜æˆäº†$A = \frac{1}{\int e^{-\lambda E(x)} \, dx}$

è¿™ä¸ª $\lambda$ï¼ˆæˆ– $T$ï¼‰å°±åƒæ˜¯ä¸€ä¸ªè°ƒèŠ‚å™¨ï¼Œå†³å®šäº†åœ°å½¢çš„â€œåˆ†è¾¨ç‡â€æˆ–â€œåå·®â€ã€‚æˆ‘ä»¬å¯ä»¥é€šè¿‡è°ƒèŠ‚å®ƒï¼Œæ¥æ”¹å˜æ¦‚ç‡åˆ†å¸ƒ $f(x, \lambda)$ çš„å½¢çŠ¶ã€‚

#### ä¸¤ä¸ªæé™çŠ¶æ€ï¼šæ¢ç´¢ä¸é”å®š
é€šè¿‡åˆ†æ $\lambda$ çš„æé™æƒ…å†µï¼Œæˆ‘ä»¬èƒ½å®Œç¾æ­ç¤ºéšæœºä¼˜åŒ–çš„è¿ä½œæœºåˆ¶ï¼š

**çŠ¶æ€ Aï¼šé«˜æ¸©æ¨¡å¼ (High Temperature)**

å½“ $\lambda \to 0$ æ—¶ï¼ˆæ„å‘³ç€ $T \to \infty$ï¼‰ï¼š
- æ•°å­¦ä¸Šï¼š$-\lambda E(x) \to 0$ï¼Œå¯¼è‡´ $e^{-\lambda E(x)} \to 1$ã€‚
- ç»“æœï¼š $f(x, \lambda) \to \text{Constant}$ã€‚
- ç‰©ç†å›¾æ™¯ï¼š æ­¤æ—¶æ¦‚ç‡åˆ†å¸ƒåœ¨æ•´ä¸ªç©ºé—´è¶‹äºå‡åŒ€ã€‚æ— è®º $E(x)$ é«˜ä½ï¼Œæ‰€æœ‰ç‚¹è¢«é‡‡æ ·çš„æ¦‚ç‡å‡ ä¹ç›¸ç­‰ã€‚
- æ„ä¹‰ï¼š è¿™æ˜¯å…¨å›¾æ¢ç´¢ (Exploration) é˜¶æ®µã€‚ç®—æ³•åƒæ°”ä½“åˆ†å­ä¸€æ ·åœ¨ç©ºé—´ä¸­å‰§çƒˆè¿åŠ¨ï¼Œèƒ½å¤Ÿè½»æ¾è·¨è¶Šä»»ä½•é«˜å±±å’Œæ·±è°·ï¼Œç¡®ä¿æˆ‘ä»¬ä¸ä¼šæ¼æ‰å…¨å±€æœ€ä¼˜è§£æ‰€åœ¨çš„åŒºåŸŸã€‚

**çŠ¶æ€ Bï¼šä½æ¸©æ¨¡å¼ (Low Temperature)**

å½“ $\lambda \to \infty$ æ—¶ï¼ˆæ„å‘³ç€ $T \to 0$ï¼‰ï¼š
- æ•°å­¦ä¸Šï¼šå·®å¼‚è¢«æ— é™æ”¾å¤§ã€‚åªè¦ $E(x)$ ç¨å¾®å¤§ä¸€ç‚¹ç‚¹ï¼Œ$e^{-\lambda E(x)}$ å°±ä¼šè¡°å‡å¾—æå¿«ã€‚
- ç»“æœï¼š æ¦‚ç‡åˆ†å¸ƒå˜æˆäº†ä¸€ä¸ªå°–å³°ï¼ˆç±»ä¼¼äºç‹„æ‹‰å…‹ $\delta$ å‡½æ•°ï¼‰ï¼Œä»…åœ¨èƒ½é‡æœ€ä½ç‚¹ $m$ å¤„æœ‰å€¼ã€‚
- ç‰©ç†å›¾æ™¯ï¼š ç³»ç»Ÿâ€œå†»ç»“â€äº†ã€‚
- æ„ä¹‰ï¼š è¿™æ˜¯ç²¾ç»†å¼€å‘ (Exploitation) é˜¶æ®µã€‚ç®—æ³•é”å®šäº†å½“å‰åŒºåŸŸçš„æœ€ä½ç‚¹ï¼Œä¸å†ä¹±è·‘ï¼Œä»è€Œè·å¾—é«˜ç²¾åº¦çš„è§£ã€‚


```python
import numpy as np
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation, PillowWriter

# --- 1. å®šä¹‰èƒ½é‡å‡½æ•° (Energy Function) ---
# æˆ‘ä»¬è®¾è®¡ä¸€ä¸ªä¸å¯¹ç§°çš„åŒåŠ¿é˜±ï¼š
# ä¸€ä¸ªæ·±å‘ï¼ˆå…¨å±€æœ€ä¼˜ï¼‰ï¼Œä¸€ä¸ªæµ…å‘ï¼ˆå±€éƒ¨æœ€ä¼˜ï¼‰
def energy_function(x):
    # (x^2 - 1)^2 æ˜¯æ ‡å‡†çš„Wå½¢åŒäº•
    # + 0.3*x ç”¨æ¥å€¾æ–œå®ƒï¼Œä½¿å·¦è¾¹çš„å‘æ¯”å³è¾¹çš„æ·±
    return (x**2 - 1)**2 + 0.3 * x

# --- 2. å‡†å¤‡æ•°æ® ---
x = np.linspace(-2.5, 2.5, 500)
E = energy_function(x)

# æ‰¾åˆ°çœŸæ­£çš„å…¨å±€æœ€å°å€¼ï¼Œç”¨äºç»˜å›¾æ ‡è®°
min_idx = np.argmin(E)
global_min_x = x[min_idx]
global_min_y = E[min_idx]

# --- 3. è®¾ç½®ç»˜å›¾å¸ƒå±€ ---
fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(8, 10), constrained_layout=True)

# ä¸Šå›¾ï¼šèƒ½é‡æ™¯è§‚ E(x) - æ°¸è¿œä¸å˜
ax1.plot(x, E, 'k-', linewidth=3, label='Energy $E(x)$')
ax1.scatter(global_min_x, global_min_y, color='gold', s=150, zorder=5, edgecolors='k', label='Global Min')
ax1.set_title("The Problem: Energy Landscape $E(x)$", fontsize=14)
ax1.set_ylabel("Energy")
ax1.grid(True, alpha=0.3)
ax1.legend()
ax1.set_xlim(-2.5, 2.5)

# ä¸‹å›¾ï¼šæ¦‚ç‡åˆ†å¸ƒ f(x) - éšæ¸©åº¦å˜åŒ–
line, = ax2.plot([], [], 'r-', linewidth=3, alpha=0.8)
fill_poly = ax2.fill_between(x, np.zeros_like(x), np.zeros_like(x), color='red', alpha=0.3)
ax2.set_xlim(-2.5, 2.5)
ax2.set_ylabel("Probability Density $f(x)$")
ax2.set_xlabel("x")
ax2.grid(True, alpha=0.3)

# åŠ¨æ€æ–‡æœ¬ï¼šæ˜¾ç¤ºå½“å‰çš„ Lambda å’Œ Temperature
text_info = ax2.text(0.05, 0.9, '', transform=ax2.transAxes, fontsize=12, 
                     bbox=dict(facecolor='white', alpha=0.8))

# --- 4. åŠ¨ç”»é€»è¾‘ ---
# Lambda ä» 0.1 (é«˜æ¸©) å˜åˆ° 10.0 (ä½æ¸©)
# æˆ‘ä»¬ç”¨å¯¹æ•°åˆ»åº¦ï¼Œè®©é«˜æ¸©é˜¶æ®µå±•ç¤ºå¾—æ…¢ä¸€ç‚¹ï¼Œä½æ¸©é˜¶æ®µå¿«ä¸€ç‚¹
lambdas = np.logspace(np.log10(0.1), np.log10(15.0), 100)

def init():
    line.set_data([], [])
    return line,

def update(frame_lambda):
    global fill_poly
    
    # === æ ¸å¿ƒç‰©ç†è®¡ç®— ===
    # 1. è®¡ç®—ç»å°”å…¹æ›¼å› å­ (æœªå½’ä¸€åŒ–æ¦‚ç‡)
    # e^(-lambda * E)
    unnormalized_prob = np.exp(-frame_lambda * E)
    
    # 2. è®¡ç®—å½’ä¸€åŒ–å¸¸æ•° A (Partition Function Z)
    # åˆ©ç”¨æ¢¯å½¢æ³•åˆ™è¿›è¡Œæ•°å€¼ç§¯åˆ†
    integral_Z = np.trapezoid(unnormalized_prob, x)
    A = 1.0 / integral_Z
    
    # 3. å¾—åˆ°æœ€ç»ˆæ¦‚ç‡åˆ†å¸ƒ f(x)
    # f(x) = A * e^(-lambda * E)
    pdf = A * unnormalized_prob
    # =================
    
    # æ›´æ–°æ›²çº¿
    line.set_data(x, pdf)
    
    # æ›´æ–°å¡«å……åŒºåŸŸ (éœ€è¦ç§»é™¤æ—§çš„ï¼Œç”»æ–°çš„)
    fill_poly.remove()
    fill_poly = ax2.fill_between(x, 0, pdf, color='red', alpha=0.3)
    
    # åŠ¨æ€è°ƒæ•´Yè½´é«˜åº¦ (å› ä¸ºå°–å³°ä¼šè¶Šæ¥è¶Šé«˜)
    ax2.set_ylim(0, np.max(pdf) * 1.2)
    
    # æ›´æ–°æ ‡é¢˜å’Œæ–‡å­—
    T = 1 / frame_lambda
    ax2.set_title(f"The Stochastic Solution: Probability Distribution", fontsize=14)
    text_info.set_text(f"$\lambda$ = {frame_lambda:.2f} (Inverse Temp)\n$T$ = {T:.2f} (Temperature)")
    
    return line, fill_poly, text_info

# --- 5. ç”Ÿæˆå¹¶ä¿å­˜åŠ¨ç”» ---
print("æ­£åœ¨ç”ŸæˆåŠ¨ç”»ï¼Œè¯·ç¨å€™...")
ani = FuncAnimation(fig, update, frames=lambdas, init_func=init, blit=False)

# ä¿å­˜ä¸º GIF (éœ€è¦å®‰è£… imagemagick æˆ–ä½¿ç”¨ pillow)
ani.save('simulated_annealing.gif', writer=PillowWriter(fps=15))
print("âœ… åŠ¨ç”»å·²ä¿å­˜ä¸º 'simulated_annealing.gif'")

# å¦‚æœåœ¨ Jupyter Notebook ä¸­ï¼Œå¯ä»¥ç›´æ¥è§£å¼€ä¸‹é¢è¿™è¡Œæ³¨é‡Šæ¥æ˜¾ç¤º
#plt.show()
```

![](/img/contents/post/mcmc-statics/10_stochastic_optimization/simulated_annealing.gif)

è¿™æ˜¯ä¸€ä¸ªç»å…¸çš„ **â€œåŒåŠ¿é˜±â€ï¼ˆDouble Wellï¼‰** èƒ½é‡å‡½æ•°ï¼š
- å®ƒæœ‰ä¸€ä¸ªå…¨å±€æœ€ä¼˜è§£ï¼ˆæ·±å‘ï¼‰ã€‚
- è¿˜æœ‰ä¸€ä¸ªå±€éƒ¨æœ€ä¼˜è§£ï¼ˆæµ…å‘ï¼‰ã€‚

åœ¨é«˜æ¸©æ—¶ï¼Œæ¦‚ç‡åˆ†å¸ƒåŒæ—¶è¦†ç›–ä¸¤ä¸ªå‘ï¼ˆç”± $A$ ç»Ÿç®¡ï¼‰ï¼›éšç€æ¸©åº¦é™ä½ï¼ˆ$\lambda$ å˜å¤§ï¼‰ï¼Œæ¦‚ç‡åˆ†å¸ƒæ˜¯å¦‚ä½•é€æ¸â€œæŠ›å¼ƒâ€å±€éƒ¨æœ€ä¼˜ï¼Œå…¨éƒ¨æŒ¤åˆ°å…¨å±€æœ€ä¼˜é‚£ä¸ªâ€œå°–å³°â€é‡Œçš„ã€‚

## ä» MCMC åˆ°ä¼˜åŒ–â€”â€”é€€ç«çš„è‰ºæœ¯ (The Bridge: Simulated Annealing)

**æ¨¡æ‹Ÿé€€ç«** (Simulated Annealingï¼ŒSA) æ˜¯ä¸€ç§é€šç”¨æ¦‚ç‡ä¼˜åŒ–ç®—æ³•ã€‚
- åå­—æ¥æºï¼šæ¥è‡ªäºå†¶é‡‘å­¦ä¸­çš„â€œé€€ç«â€å·¥è‰ºã€‚
  - ç‰©ç†é€€ç«ï¼šæŠŠé‡‘å±åŠ çƒ­åˆ°å¾ˆé«˜æ¸©ï¼ˆåŸå­ä¹±è·‘ï¼‰ï¼Œç„¶åæ…¢æ…¢å†·å´ã€‚è¿™æ ·åŸå­æœ‰è¶³å¤Ÿçš„æ—¶é—´æ‰¾åˆ°èƒ½é‡æœ€ä½çš„æ™¶ä½“ç»“æ„ï¼Œé‡‘å±å°±ä¼šå˜å¾—åšç¡¬ä¸”æ— ç¼ºé™·ã€‚
  - ç®—æ³•é€€ç«ï¼šæŠŠå‚æ•° $x$ æ‰”åˆ°å¾ˆé«˜æ¸©ï¼ˆéšæœºä¹±è·‘ï¼‰ï¼Œç„¶åæ…¢æ…¢é™ä½ $T$ã€‚è¿™æ · $x$ æœ‰è¶³å¤Ÿçš„æ—¶é—´è·³å‡ºå±€éƒ¨æœ€ä¼˜ï¼Œæœ€ç»ˆè½å…¥å…¨å±€æœ€ä¼˜ã€‚
- æ ¸å¿ƒç‰¹å¾ï¼šå®ƒæ˜¯ä¸€ç§ **â€œå…è®¸åæ‚”â€** çš„ç®—æ³•ã€‚ä¹Ÿå°±æ˜¯åœ¨æœç´¢è¿‡ç¨‹ä¸­ï¼Œå®ƒä¸ä»…æ¥å—â€œå¥½â€çš„è§£ï¼Œä¹Ÿä¼šä»¥ä¸€å®šæ¦‚ç‡æ¥å—â€œåâ€çš„è§£ï¼ˆä¸ºäº†è·³å‡ºå‘ï¼‰ã€‚

ä¹‹å‰æåˆ°çš„çš„ Steepest Descent (æ¢¯åº¦ä¸‹é™) æ˜¯ä¸ªâ€œåŠ¿åˆ©çœ¼â€ï¼Œåªå¾€ä½å¤„èµ°ã€‚å¦‚æœåœ°å½¢æ˜¯åƒ é¸¡è›‹æ‰˜ç›˜ é‚£æ ·çš„ï¼ˆæ— æ•°ä¸ªå°å‘ï¼‰ï¼Œæ¢¯åº¦ä¸‹é™æ‰è¿›ç¬¬ä¸€ä¸ªå‘å°±æ­»åœ¨é‚£é‡Œäº†ã€‚

è€Œ SA çš„ä¼˜åŠ¿åœ¨äºï¼š
- å…¨å±€æœç´¢èƒ½åŠ›ï¼šå› ä¸ºå®ƒåœ¨é«˜æ¸©æ—¶æ¥å—â€œåè§£â€ï¼Œæ‰€ä»¥å®ƒèƒ½çˆ¬å¡ç¿»è¶Šå±±å²­ï¼Œå»æ¢ç´¢æœªçŸ¥çš„é¢†åŸŸã€‚
- ä¸ä¾èµ–æ¢¯åº¦ï¼šå®ƒä¸éœ€è¦æ±‚å¯¼ï¼ˆ$f(x)$ ç”šè‡³å¯ä»¥æ˜¯ä¸è¿ç»­çš„ï¼‰ã€‚
- ä¸‡é‡‘æ²¹ï¼šä¸ç®¡å‡½æ•°é•¿å¤šä¸‘ï¼Œåªè¦ä½ èƒ½ç®—å‡ºå‡½æ•°å€¼ï¼Œå®ƒå°±èƒ½è·‘ã€‚
  - æ— è®º$f(x)$æ˜¯å¦å‡¸ï¼Œéƒ½èƒ½åº”ç”¨

### ç®—æ³•æµç¨‹

1. å®šä¹‰è½¬æ¢ (Transform): æˆ‘ä»¬ä¸ç›´æ¥å»è§£ $\min E(x)$ï¼Œè€Œæ˜¯æ„å»ºä¸€ä¸ªæ¦‚ç‡åˆ†å¸ƒï¼š$$f(x) \propto e^{-E(x)/T}$$
   - è¿™é‡Œ $\lambda = 1/T$
   - ç›´è§‰ï¼šæŠŠâ€œåœ°å½¢é«˜åº¦â€å˜æˆâ€œæ¦‚ç‡å¯†åº¦â€ã€‚å‘è¶Šæ·±ï¼ˆ$E$ è¶Šå°ï¼‰ï¼Œæ¦‚ç‡è¶Šå¤§ï¼›å±±è¶Šé«˜ï¼ˆ$E$ è¶Šå¤§ï¼‰ï¼Œæ¦‚ç‡è¶Šå°ã€‚
2. é«˜æ¸©æ¢ç´¢ (Explore) (é«˜æ¸©é‡‡æ ·): 
   - æ“ä½œï¼šè®¾ç½®ä¸€ä¸ªå¾ˆé«˜çš„åˆå§‹æ¸©åº¦ $T_{max}$ã€‚
   - ç°è±¡ï¼š
     - å½“ $T$ å¾ˆå¤§æ—¶ï¼Œ$E(x)/T \approx 0$ï¼Œæ‰€ä»¥ $e^0 \approx 1$ã€‚
     - æ•´ä¸ªæ¦‚ç‡åˆ†å¸ƒæ˜¯æ‰å¹³çš„ï¼ˆFlatï¼‰ï¼Œæ¥è¿‘å‡è¡¡åˆ†å¸ƒã€‚
     - è¿™æ—¶å€™ä½ ä¸¢ä¸‹å»çš„â€œç²’å­â€ï¼ˆé‡‡æ ·ç‚¹ï¼‰ä¼šæ»¡åœ°å›¾ä¹±è·‘ï¼ˆå› ä¸ºå»åˆ°å“ªé‡Œçš„æ¦‚ç‡åŸºæœ¬ä¸€è‡´ï¼‰ï¼Œå¯ä»¥è½»æ˜“ç¿»è¿‡é«˜å±±ï¼Œè·³å‡ºå±€éƒ¨é™·é˜±ã€‚
3. é™æ¸©è¿‡ç¨‹ (Cooling / Annealing): æ…¢æ…¢é™ä½æ¸©åº¦ $T$ï¼ˆå¢å¤§ $\lambda$ï¼‰ã€‚
   - æ“ä½œï¼šæŒ‰ç…§ä¸€ä¸ªæ—¶é—´è¡¨é€æ¸é™ä½ $T$ã€‚
     - ä¾‹å¦‚ï¼š$T(t) \sim \frac{c}{\log(1+t)}$
       - è¿™æ˜¯ä¸€ä¸ªéå¸¸è‘—åçš„ç†è®ºå…¬å¼ï¼ˆGeman & Geman, 1984ï¼‰ï¼Œä¿è¯èƒ½æ‰¾åˆ°å…¨å±€æœ€ä¼˜ï¼Œä½†å®ƒé™æ¸©ææ…¢ã€‚
     - å®é™…å·¥ç¨‹ä¸­ï¼Œæˆ‘ä»¬é€šå¸¸ç”¨æ›´å¿«çš„æ–¹æ³•ï¼Œæ¯”å¦‚ $T_{new} = T_{old} \times 0.99$ã€‚
   - ç°è±¡ï¼šéšç€æ¸©åº¦é™ä½ï¼Œåˆ†å¸ƒå›¾å¼€å§‹â€œå˜å½¢â€ã€‚åŸæœ¬å¹³å¦çš„åœ°æ–¹å˜ä½ï¼ŒåŸæœ¬æ·±å‘çš„åœ°æ–¹å˜å¾—æ›´æ·±ï¼ˆæ¦‚ç‡å³°å€¼æ›´å°–ï¼‰ã€‚
4. ä½æ¸©å¼€å‘ (Exploit) ï¼šæŒç»­é‡‡æ · (Loop till Low T)
   - æ“ä½œï¼šç»§ç»­å¾ªç¯â€œé‡‡æ · -> é™æ¸© -> é‡‡æ ·â€ï¼Œç›´åˆ°æ¸©åº¦ $T$ éå¸¸ä½
     - âš ï¸ ä½†ä¸èƒ½ç­‰äº 0ï¼Œå¦åˆ™é™¤æ•°æ— æ„ä¹‰ã€‚
   - ç°è±¡ï¼šæ­¤æ—¶æ¦‚ç‡åˆ†å¸ƒå·²ç»å˜æˆäº†ä¸€æ ¹é’ˆï¼ˆDirac Deltaï¼‰ã€‚ç²’å­åŸºæœ¬è¢«â€œé”æ­»â€åœ¨é‚£ä¸ªæœ€æ·±çš„å‘é‡Œï¼Œå¾ˆéš¾å†è·³å‡ºæ¥äº†ã€‚
5. å‡å€¼ä¼°ç®— (Sample & Average)
   - æ“ä½œï¼šåœ¨ä½æ¸©é˜¶æ®µé‡‡é›†ä¸€å †æ ·æœ¬ $x_1, x_2, ..., x_n$ï¼Œç®—å‡ºå®ƒä»¬çš„å¹³å‡å€¼ã€‚
   - ç»“è®ºï¼šè¿™ä¸ªå¹³å‡å€¼ $\bar{x}$ å°±æ˜¯æˆ‘ä»¬ä¼°è®¡çš„å…¨å±€æœ€å°å€¼ä½ç½® $x_{min}$ã€‚

> æ³¨æ„ï¼š
> - åˆšå¼€å§‹ $T$ å¾ˆå¤§ï¼Œ$\Delta E / T$ å¾ˆå°ï¼Œ$P$ æ¥è¿‘ 1ã€‚ç®—æ³•å‡ ä¹æ¥å—æ‰€æœ‰åè§£ï¼ˆç–¯ç‹‚ä¹±è·‘ï¼‰ã€‚
> - åæ¥ $T$ å¾ˆå°ï¼Œ$\Delta E / T$ å¾ˆå¤§ï¼Œ$P$ æ¥è¿‘ 0ã€‚ç®—æ³•å‡ ä¹æ‹’ç»æ‰€æœ‰åè§£ï¼ˆå˜æˆäº†æ¢¯åº¦ä¸‹é™ï¼‰ã€‚

#### ç¤ºä¾‹

##### ä¸€ç»´
è¿™é‡Œä½¿ç”¨ä¸€ä¸ªæœ‰å¤šå¤„é™·é˜±çš„å‡½æ•°æ¥å±•ç¤ºâ€œæ¸©åº¦æ§åˆ¶â€å’Œâ€œMetropolisé‡‡æ ·â€çš„ç»“åˆï¼š$E(x) = x^2 - \cos(\pi x)$ã€‚


```python
import numpy as np
import matplotlib.pyplot as plt

# --- 1. ç›®æ ‡å‡½æ•° (Energy Function) ---
def E(x):
    return x**2 - np.cos(np.pi * x)

# --- 2. é‡‡æ ·æ ¸å¿ƒ: Metropolis å‡†åˆ™ ---
# è¿™æ˜¯ä¸€ä¸ª"æŠ½æ ·æœº"ï¼Œè´Ÿè´£æ ¹æ®å½“å‰æ¸©åº¦ T ç”Ÿæˆæ ·æœ¬
def sample_one_step(x_curr, T):
    # a. æè®® (Propose): éšæœºå¾€å·¦æˆ–å¾€å³è¿ˆä¸€æ­¥
    x_next = x_curr + np.random.uniform(-0.5, 0.5)
    
    # b. èƒ½é‡å·® (Delta E)
    dE = E(x_next) - E(x_curr)
    
    # c. æ¥å—/æ‹’ç» (Accept/Reject)
    # æ ¸å¿ƒé€»è¾‘ï¼šå¦‚æœæ–°ä½ç½®èƒ½é‡ä½ï¼Œä¸€å®šå»ï¼›å¦‚æœé«˜ï¼Œæœ‰ä¸€å®šæ¦‚ç‡å»ï¼ˆå–å†³äºæ¸©åº¦Tï¼‰
    if dE < 0 or np.random.rand() < np.exp(-dE / T):
        return x_next # æ¥å—ç§»åŠ¨
    else:
        return x_curr # æ‹’ç»ç§»åŠ¨ï¼Œå¾…åœ¨åŸåœ°

# --- ä¸»æµç¨‹: å¯¹åº”ä½ çš„ç¬”è®°æ­¥éª¤ ---
def run_stochastic_optimization():
    # åˆå§‹åŒ–
    x = -2.5       # èµ·ç‚¹ (æ•…æ„é€‰åœ¨ä¸€ä¸ªè¾ƒè¿œçš„å±€éƒ¨æœ€ä¼˜é™„è¿‘)
    T = 10.0       # T_max (é«˜æ¸©)
    T_min = 0.01   # T_min (ä½æ¸©æˆªæ­¢)
    alpha = 0.99   # é™æ¸©ç³»æ•° (å®é™…å¸¸ç”¨çš„é™æ¸©æ–¹å¼)
    
    path = []      # è®°å½•èµ°è¿‡çš„è·¯å¾„
    temps = []     # è®°å½•æ¸©åº¦å˜åŒ–
    
    print(f"{'Step':<6} | {'Temp':<8} | {'Current x':<10} | {'Action'}")
    print("-" * 45)
    
    step = 0
    # æµç¨‹ 4: ç›´åˆ°æ¸©åº¦éå¸¸ä½ (Till a very low T)
    while T > T_min:
        
        # æµç¨‹ 2 & 3: é‡‡æ · å¹¶ é™æ¸©
        x = sample_one_step(x, T)
        
        # è®°å½•æ•°æ®
        path.append(x)
        temps.append(T)
        
        # æ‰“å°ä¸­é—´è¿‡ç¨‹ (æ¯éš”200æ­¥)
        if step % 200 == 0:
            status = "Explore ğŸ²" if T > 1.0 else "Exploit ğŸ¯"
            print(f"{step:<6} | {T:<8.4f} | {x:<10.4f} | {status}")
            
        # é™æ¸© (Decrease T)
        T = T * alpha 
        step += 1
        
    # æµç¨‹ 5: ç»Ÿè®¡å‡å€¼ (Avg Samples)
    # å–æœ€å 100 ä¸ªä½æ¸©æ ·æœ¬çš„å‡å€¼
    final_samples = path[-100:]
    estimated_min = np.mean(final_samples)
    
    print("-" * 45)
    print(f"âœ… æœ€ç»ˆä¼°ç®—ç»“æœ: x = {estimated_min:.4f}")
    print(f"âœ… çœŸå®æœ€å°å€¼: x = 0.0000 (å¤§æ¦‚ç‡é‡åˆ)")
    
    return path, temps

# --- è¿è¡Œå¹¶å¯è§†åŒ– ---
path, temps = run_stochastic_optimization()

# ç”»å›¾å±•ç¤ºç²’å­æ˜¯å¦‚ä½•"ä»ä¹±è·‘"åˆ°"å½’ä½"çš„
plt.figure(figsize=(10, 6))
plt.plot(path, alpha=0.6, label='Particle Path')
plt.xlabel('Iterations (Time)')
plt.ylabel('Position x')
plt.title('Algorithm Flow: From Exploration (High T) to Exploitation (Low T)')
plt.axhline(0, color='r', linestyle='--', label='Global Min (x=0)')
plt.grid(True, alpha=0.3)
plt.legend()
plt.show()
```

    Step   | Temp     | Current x  | Action
    ---------------------------------------------
    0      | 10.0000  | -2.5000    | Explore ğŸ²
    200    | 1.3398   | 2.2058     | Explore ğŸ²
    400    | 0.1795   | 0.2473     | Exploit ğŸ¯
    600    | 0.0241   | -0.0782    | Exploit ğŸ¯
    ---------------------------------------------
    âœ… æœ€ç»ˆä¼°ç®—ç»“æœ: x = -0.0115
    âœ… çœŸå®æœ€å°å€¼: x = 0.0000 (å¤§æ¦‚ç‡é‡åˆ)



    
![png](/img/contents/post/mcmc-statics/10_stochastic_optimization/10_mcmc_stochastic_optimization_5_1.png)
    


ä¸Šé¢ç”Ÿæˆçš„å›¾
- å‰åŠæ®µ (å·¦è¾¹)ï¼šæ›²çº¿éœ‡è¡éå¸¸å‰§çƒˆã€‚è¿™å°±æ˜¯é«˜æ¸©æ¢ç´¢ï¼Œç²’å­æ ¹æœ¬ä¸åœ¨ä¹é‚£é‡Œæ˜¯å‘ï¼Œå®ƒåœ¨æ•´ä¸ªåŒºåŸŸä¹±è·³ã€‚
- ååŠæ®µ (å³è¾¹)ï¼šæ›²çº¿å˜æˆäº†ä¸€æ¡ç›´çº¿ã€‚è¿™å°±æ˜¯ä½æ¸©é”å®šï¼Œç²’å­è¢«å›°åœ¨äº† $x=0$ é™„è¿‘ã€‚
- ç»“æœï¼šæœ€åæˆ‘ä»¬æŠŠååŠæ®µé‚£äº›â€œé™æ­¢â€çš„ç‚¹å–å¹³å‡ï¼Œå°±å¾—åˆ°äº†ç²¾å‡†çš„æœ€å°å€¼ã€‚

##### N ç»´

ä¸ºäº†æ¼”ç¤º N ç»´çš„æŒ‘æˆ˜æ€§ï¼Œæˆ‘ä»¬é€‰ç”¨è‘—åçš„ Rastrigin å‡½æ•°ã€‚è¿™æ˜¯ä¸€ä¸ªâ€œæ¶åæ˜­å½°â€çš„æµ‹è¯•å‡½æ•°ï¼šå®ƒå°±åƒä¸€ä¸ªå¸ƒæ»¡é¸¡è›‹æ‰˜ç›˜çš„å¤§ç¢—ï¼Œå®è§‚ä¸Šçœ‹æ˜¯ä¸ªç¢—ï¼ˆæœ‰å…¨å±€æœ€ä¼˜ï¼‰ï¼Œä½†å¾®è§‚ä¸Šåˆ°å¤„éƒ½æ˜¯å‘ï¼ˆå±€éƒ¨æœ€ä¼˜ï¼‰ã€‚

N ç»´ Rastrigin å‡½æ•°å®šä¹‰å…¬å¼å¦‚ä¸‹ï¼ˆ$A=10$ï¼‰ï¼š
$$f(\mathbf{x}) = 10n + \sum_{i=1}^n (x_i^2 - 10 \cos(2\pi x_i))$$
å®ƒçš„å…¨å±€æœ€å°å€¼åœ¨åŸç‚¹ $\mathbf{x} = [0, 0, \dots, 0]$ï¼Œå‡½æ•°å€¼ä¸º 0ã€‚


```python
import numpy as np
import matplotlib.pyplot as plt

# --- 1. å®šä¹‰ N ç»´ç›®æ ‡å‡½æ•° (Rastrigin Function) ---
def rastrigin(x):
    # x æ˜¯ä¸€ä¸ªå‘é‡ (numpy array)
    # A * n + sum(x^2 - A * cos(2*pi*x))
    A = 10
    n = len(x)
    return A * n + np.sum(x**2 - A * np.cos(2 * np.pi * x))

# --- 2. N ç»´é‚»åŸŸç”Ÿæˆ (Proposal) ---
def get_neighbor(x_curr, step_size=0.5):
    # å…³é”®ç‚¹ï¼šæˆ‘ä»¬åœ¨ N ç»´ç©ºé—´ä¸­éšæœºæ¸¸èµ°
    # size=len(x_curr) ä¿è¯äº†ç”Ÿæˆçš„æ‰°åŠ¨å‘é‡å’Œ x ç»´åº¦ä¸€è‡´
    perturbation = np.random.uniform(-step_size, step_size, size=len(x_curr))
    return x_curr + perturbation

# --- 3. æ¨¡æ‹Ÿé€€ç«ä¸»ç¨‹åº ---
def simulated_annealing_nd(n_dim=2, n_iter=2000):
    # åˆå§‹åŒ–ï¼šåœ¨ä¸€ä¸ªèŒƒå›´å†…éšæœºç”Ÿæˆèµ·ç‚¹ (-5.12 åˆ° 5.12 æ˜¯ Rastrigin çš„æ ‡å‡†å®šä¹‰åŸŸ)
    current_x = np.random.uniform(-5.12, 5.12, size=n_dim)
    current_E = rastrigin(current_x)
    
    # è®°å½•æœ€ä½³è§£ (Best So Far)ï¼Œé˜²æ­¢è·‘ä¸¢äº†
    best_x = current_x.copy()
    best_E = current_E
    
    # æ¸©åº¦è®¾ç½®
    T = 100.0
    T_min = 1e-4
    alpha = 0.99  # é™æ¸©ç³»æ•°
    
    path = [current_x] # è®°å½•è·¯å¾„ç”¨äºç”»å›¾
    energy_history = [current_E]

    print(f"å¼€å§‹ {n_dim} ç»´ä¼˜åŒ–...")
    print(f"èµ·ç‚¹: {np.round(current_x, 2)}, Energy: {current_E:.2f}")

    iter_count = 0
    while T > T_min and iter_count < n_iter:
        # 1. æè®®æ–°ä½ç½® (å‘é‡åŠ æ³•)
        new_x = get_neighbor(current_x)
        
        # é˜²æ­¢è·‘å‡ºå®šä¹‰åŸŸ (Rastrigin é€šå¸¸é™åˆ¶åœ¨ [-5.12, 5.12])
        new_x = np.clip(new_x, -5.12, 5.12)
        
        new_E = rastrigin(new_x)
        
        # 2. è®¡ç®—èƒ½é‡å·®
        dE = new_E - current_E
        
        # 3. Metropolis å‡†åˆ™ (å’Œ 1 ç»´ä¸€æ¨¡ä¸€æ ·)
        if dE < 0 or np.random.rand() < np.exp(-dE / T):
            current_x = new_x
            current_E = new_E
            
            # æ›´æ–°å†å²æœ€ä½³
            if current_E < best_E:
                best_x = current_x.copy()
                best_E = current_E
        
        path.append(current_x)
        energy_history.append(current_E)
        
        T *= alpha
        iter_count += 1
        
    print(f"ç»“æŸ. æœ€ç»ˆä½ç½®: {np.round(best_x, 4)}")
    print(f"æœ€ç»ˆèƒ½é‡: {best_E:.6f} (ç†è®ºæœ€ä¼˜æ˜¯ 0.0)")
    
    return np.array(path), energy_history, best_x

# --- è¿è¡Œ: è¿™é‡Œæˆ‘ä»¬è®¾ä¸º 2 ç»´ä»¥ä¾¿ç”»å›¾ï¼Œä½†ç®—æ³•æ”¯æŒ N ç»´ ---
DIMENSION = 2
path, energies, final_sol = simulated_annealing_nd(n_dim=DIMENSION, n_iter=3000)

# --- 4. å¯è§†åŒ– (ä»…é€‚ç”¨äº 2D) ---
if DIMENSION == 2:
    plt.figure(figsize=(12, 5))
    
    # å­å›¾ 1: åœ°å½¢å›¾å’Œè·¯å¾„
    plt.subplot(1, 2, 1)
    x_grid = np.linspace(-5.12, 5.12, 100)
    y_grid = np.linspace(-5.12, 5.12, 100)
    X, Y = np.meshgrid(x_grid, y_grid)
    # è®¡ç®—ç½‘æ ¼ä¸Šæ¯ä¸ªç‚¹çš„ Z å€¼
    Z = np.zeros_like(X)
    for i in range(X.shape[0]):
        for j in range(X.shape[1]):
            Z[i,j] = rastrigin(np.array([X[i,j], Y[i,j]]))
            
    plt.contourf(X, Y, Z, levels=50, cmap='viridis', alpha=0.7)
    plt.colorbar(label='Energy')
    
    # ç”»è·¯å¾„ï¼šèµ·ç‚¹æ˜¯ç™½è‰²ï¼Œç»ˆç‚¹æ˜¯çº¢è‰²
    plt.plot(path[:, 0], path[:, 1], 'w-', linewidth=0.5, alpha=0.6)
    plt.scatter(path[0, 0], path[0, 1], c='white', s=50, label='Start')
    plt.scatter(final_sol[0], final_sol[1], c='red', marker='*', s=200, label='End')
    plt.legend()
    plt.title(f"2D Rastrigin Optimization Path\n(Escaping many local minima)")
    
    # å­å›¾ 2: èƒ½é‡ä¸‹é™æ›²çº¿
    plt.subplot(1, 2, 2)
    plt.plot(energies)
    plt.yscale('log') # ç”¨å¯¹æ•°åæ ‡çœ‹ï¼Œå› ä¸ºåæœŸä¸‹é™å¾ˆå¾®å°
    plt.xlabel('Iteration')
    plt.ylabel('Energy (Log Scale)')
    plt.title('Energy Minimization Process')
    plt.grid(True, which="both", ls="--")
    
    plt.tight_layout()
    plt.show()
```

    å¼€å§‹ 2 ç»´ä¼˜åŒ–...
    èµ·ç‚¹: [-0.04  4.85], Energy: 28.08
    ç»“æŸ. æœ€ç»ˆä½ç½®: [1.0266 2.0164]
    æœ€ç»ˆèƒ½é‡: 5.312337 (ç†è®ºæœ€ä¼˜æ˜¯ 0.0)



    
![png](/img/contents/post/mcmc-statics/10_stochastic_optimization/10_mcmc_stochastic_optimization_8_1.png)
    


1. ä»£ç ä¸­çš„å…³é”®è¡Œï¼š`perturbation = np.random.uniform(-step_size, step_size, size=len(x_curr))`è¿™å°±æ˜¯ N ç»´æ‰©å±•çš„æ ¸å¿ƒã€‚æˆ‘ä»¬ä¸€æ¬¡æ€§ç”Ÿæˆäº†ä¸€ä¸ª N ç»´çš„éšæœºå‘é‡ã€‚
   - åœ¨æ•°å­¦ä¸Šï¼Œè¿™ç›¸å½“äºåœ¨ N ç»´è¶…çƒä½“ï¼ˆæˆ–è¶…ç«‹æ–¹ä½“ï¼‰ä¸­éšæœºé€‰ä¸€ä¸ªæ–¹å‘è·³å‡ºå»ã€‚
2. Rastrigin çš„åœ°å½¢ (å·¦å›¾)ï¼šä½ ä¼šçœ‹åˆ°æœ‰å¾ˆå¤šæ·±è“è‰²çš„åœˆåœˆï¼Œæ¯ä¸€ä¸ªéƒ½æ˜¯ä¸€ä¸ªå±€éƒ¨é™·é˜±ã€‚
   - å¦‚æœæ˜¯ **æ¢¯åº¦ä¸‹é™(Gradient Descent)**ï¼šå®ƒå¤§æ¦‚ç‡ä¼šæ‰è¿›ç¦»èµ·ç‚¹æœ€è¿‘çš„é‚£ä¸ªè“è‰²åœˆåœˆé‡Œï¼Œç„¶åæ­»åœ¨é‚£é‡Œã€‚
   - **æ¨¡æ‹Ÿé€€ç«**ï¼šä½ ä¼šçœ‹åˆ°ç™½è‰²çš„è·¯å¾„åœ¨å›¾ä¸Šä¹±çªœï¼ˆç‰¹åˆ«æ˜¯å‰æœŸï¼‰ã€‚å®ƒä¼šè·³è¿›ä¸€ä¸ªå‘ï¼Œè·³å‡ºæ¥ï¼Œå†è·³è¿›å¦ä¸€ä¸ªå‘ï¼Œç›´åˆ°æ¸©åº¦é™ä½ï¼Œè¢«â€œå¸â€è¿›æœ€ä¸­é—´é‚£ä¸ªæœ€æ·±çš„å‘ï¼ˆçº¢è‰²äº”è§’æ˜Ÿï¼‰ã€‚
3. Pincus Theorem åœ¨ N ç»´çš„æ„ä¹‰ï¼šå³ä½¿æ˜¯ N ç»´ï¼ŒPincus Theorem ä¾ç„¶æˆç«‹ï¼š$$\lim_{\lambda \to \infty} \frac{\int_{\mathbb{R}^N} \mathbf{x} e^{-\lambda E(\mathbf{x})} d\mathbf{x}}{\int_{\mathbb{R}^N} e^{-\lambda E(\mathbf{x})} d\mathbf{x}} = \mathbf{x}_{min}$$
   - è¿™è¯´æ˜æ— è®ºç»´åº¦å¤šé«˜ï¼Œåªè¦æˆ‘ä»¬èƒ½é€šè¿‡é™æ¸©è¿‡ç¨‹æ­£ç¡®åœ°ä»é‚£ä¸ª N ç»´æ¦‚ç‡åˆ†å¸ƒä¸­é‡‡æ ·ï¼Œå‡å€¼ï¼ˆæˆ–æœ€ååœç•™çš„ä½ç½®ï¼‰ä¾ç„¶æ˜¯å…¨å±€æœ€ä¼˜ã€‚

### è¯æ˜é€€ç«ç®—æ³•çš„æ­£ç¡®æ€§ï¼šPincus Theorem
> Pincus Theorem ä¸ºæ¨¡æ‹Ÿé€€ç«ç®—æ³•æä¾›äº†æ”¶æ•›æ€§çš„ç†è®ºä¿è¯ï¼ˆTheoretical Guaranteeï¼‰ã€‚
> Pincus Theorem è¯æ˜äº†â€œå¦‚æœæ¸©åº¦é™åˆ° 0ï¼Œè¿™ä¸€å †æ ·æœ¬çš„å¹³å‡å€¼å°±æ˜¯å…¨å±€æœ€ä¼˜è§£â€ï¼› æ¨¡æ‹Ÿé€€ç«ç®—æ³•åˆ™è´Ÿè´£â€œå¦‚ä½•å®‰å…¨ã€å¹³ç¨³åœ°æŠŠæ¸©åº¦é™åˆ° 0ï¼Œè€Œä¸è®©æ ·æœ¬å¡åœ¨åŠè·¯â€ã€‚

#### Pincus Theorem (1968å¹´ç”± Mark Pincus æå‡º)

Pincus Theorem æ˜¯ä¸€ä¸ªæ•°å­¦æ¡¥æ¢ï¼Œå®ƒè¯æ˜äº†ï¼šå½“æˆ‘ä»¬æŠŠæ¸©åº¦é™åˆ°æä½ï¼ˆ$\lambda \to \infty$ï¼‰æ—¶ï¼Œä¸€ä¸ªå‡½æ•°çš„â€œåŠ æƒå¹³å‡å€¼â€ï¼ˆæœŸæœ›ï¼‰ï¼Œå°±ä¼šæ”¶æ•›äºè¿™ä¸ªå‡½æ•°çš„â€œå…¨å±€æœ€å°å€¼ç‚¹â€ã€‚

å®ƒæŠŠä¸€ä¸ª **â€œå¯»æ‰¾æå€¼çš„é—®é¢˜â€ï¼ˆOptimizationï¼‰å˜æˆäº†ä¸€ä¸ªâ€œè®¡ç®—ç§¯åˆ†çš„é—®é¢˜â€**ï¼ˆIntegrationï¼‰ã€‚

å‡è®¾ä½ æœ‰ä¸€ä¸ªç›®æ ‡å‡½æ•° $f(x)$ï¼Œå®šä¹‰åŸŸä¸º $D$ï¼Œä½ æƒ³è¦æ‰¾åˆ°å®ƒçš„å…¨å±€æœ€å°å€¼ç‚¹ $x^*$ã€‚Pincus Theorem æŒ‡å‡ºï¼š
$$x^* = \lim_{\lambda \to \infty} \frac{\int_D x \cdot e^{-\lambda f(x)} \, dx}{\int_D e^{-\lambda f(x)} \, dx}$$
æˆ–è€…å†™æˆç»Ÿè®¡å­¦çš„æœŸæœ›å½¢å¼ï¼š
$$x^* = \lim_{\lambda \to \infty} \mathbb{E}_{\lambda}[x]$$
å…¶ä¸­ $\lambda$ æ˜¯ä¸€ä¸ªå‚æ•°ï¼ˆå¯¹åº”ç‰©ç†ä¸­çš„ $1/T$ï¼‰ã€‚


#### è¯æ˜

æˆ‘ä»¬çš„ç›®æ ‡æ˜¯æ±‚è¿™ä¸ªåˆ†å¼çš„æé™ï¼š
$$\langle x \rangle_\lambda = \frac{\int x \cdot e^{-\lambda E(x)} \, dx}{\int e^{-\lambda E(x)} \, dx}$$
æˆ‘ä»¬è¦è¯æ˜ï¼šå½“ $\lambda \to \infty$ æ—¶ï¼Œè¿™ä¸ªç»“æœç­‰äº $x^*$ï¼ˆå³ $E(x)$ çš„å…¨å±€æœ€å°å€¼ç‚¹ï¼‰ã€‚

å…³é”®æŠ€å·§ï¼šæ—¢ç„¶ $\lambda$ å¾ˆå¤§ï¼Œä¸ºäº†çœ‹æ¸…è°åœ¨ä¸»å¯¼ï¼Œæˆ‘ä»¬æŠŠåˆ†å­å’Œåˆ†æ¯åŒæ—¶æå–å‡ºé‚£ä¸ªâ€œæœ€å¤§çš„é¡¹â€ã€‚

**ç¬¬ä¸€æ­¥ï¼šæå–â€œæœ€å¤§å…¬çº¦æ•°â€**

å‡è®¾ $x^*$ æ˜¯å”¯ä¸€çš„å…¨å±€æœ€å°å€¼ç‚¹ã€‚é‚£ä¹ˆå¯¹äºä»»ä½• $x \neq x^*$ï¼Œéƒ½æœ‰ $E(x) > E(x^*)$ã€‚

æˆ‘ä»¬åœ¨åˆ†å­å’Œåˆ†æ¯ä¸­ï¼ŒåŒæ—¶æå‡º $e^{-\lambda E(x^*)}$ è¿™ä¸€é¡¹ï¼š
- åˆ†æ¯ï¼š$$\int e^{-\lambda E(x)} \, dx = \int e^{-\lambda [E(x^*) + (E(x) - E(x^*))]} \, dx = e^{-\lambda E(x^*)} \int e^{-\lambda (E(x) - E(x^*))} \, dx$$
- åˆ†å­ï¼š$$\int x e^{-\lambda E(x)} \, dx = e^{-\lambda E(x^*)} \int x \cdot e^{-\lambda (E(x) - E(x^*))} \, dx$$

æŠŠå®ƒä»£å›åŸå¼ï¼Œä½ ä¼šå‘ç° $e^{-\lambda E(x^*)}$ åœ¨åˆ†å­åˆ†æ¯ä¸­çº¦åˆ†æ¶ˆæ‰äº†ï¼
$$\langle x \rangle_\lambda = \frac{\int x \cdot e^{-\lambda (E(x) - E(x^*))} \, dx}{\int e^{-\lambda (E(x) - E(x^*))} \, dx}$$

è¿™ä¸€æ­¥éå¸¸å…³é”®ã€‚ç°åœ¨ç§¯åˆ†é‡Œçš„æŒ‡æ•°å˜æˆäº† $-\lambda (E(x) - E(x^*))$ã€‚æ³¨æ„æ‹¬å·é‡Œçš„ $\Delta E = E(x) - E(x^*)$ æ°¸è¿œæ˜¯å¤§äºç­‰äº 0 çš„ã€‚

**ç¬¬äºŒæ­¥ï¼šåˆ‡åˆ†ç§¯åˆ†åŒºåŸŸ (é‚»åŸŸ vs. è¿œæ–¹)**

ç°åœ¨æˆ‘ä»¬æŠŠç§¯åˆ†åŒºåŸŸåˆ†æˆä¸¤éƒ¨åˆ†ï¼š
1. æå°å€¼é™„è¿‘çš„å°é‚»åŸŸ $U_\epsilon$ï¼š $|x - x^*| < \epsilon$ï¼ˆè¿™é‡Œ $\epsilon$ æ˜¯ä¸ªå¾ˆå°çš„æ•°ï¼‰ã€‚
2. å…¶ä½™åŒºåŸŸ $R$ï¼šè¿œç¦»æœ€å°å€¼çš„åœ°æ–¹ã€‚

è®©æˆ‘ä»¬çœ‹çœ‹å½“ $\lambda \to \infty$ æ—¶ï¼Œè¿™ä¸¤éƒ¨åˆ†åˆ†åˆ«å‘ç”Ÿäº†ä»€ä¹ˆã€‚
- åˆ†æâ€œå…¶ä½™åŒºåŸŸ Râ€ï¼ˆè¿œç¦»æœ€å°å€¼çš„åœ°æ–¹ï¼‰ï¼šåœ¨è¿™äº›åœ°æ–¹ï¼Œ$\Delta E = E(x) - E(x^*)$ è‚¯å®šæœ‰ä¸€ä¸ªå¤§äº 0 çš„æœ€å°å€¼ï¼Œè®¾ä¸º $\delta > 0$ã€‚é‚£ä¹ˆæŒ‡æ•°é¡¹ $e^{-\lambda \Delta E} \le e^{-\lambda \delta}$ã€‚å½“ $\lambda \to \infty$ æ—¶ï¼Œè¿™ä¸€é¡¹ä¼šä»¥æŒ‡æ•°çº§é€Ÿåº¦è¡°å‡åˆ° 0ã€‚è¿™æ„å‘³ç€ï¼šåœ¨æé™æƒ…å†µä¸‹ï¼Œæ‰€æœ‰è¿œç¦» $x^*$ çš„åŒºåŸŸï¼Œå¯¹ç§¯åˆ†çš„è´¡çŒ®éƒ½å¯ä»¥å¿½ç•¥ä¸è®¡ã€‚
- åˆ†æâ€œé‚»åŸŸ $U_\epsilon$â€ï¼ˆæå°å€¼é™„è¿‘ï¼‰ï¼šåœ¨è¿™ä¸ªå¾®å°çš„åŒºåŸŸé‡Œï¼Œ$\Delta E \approx 0$ï¼Œæ‰€ä»¥ $e^{-\lambda \Delta E} \approx 1$ï¼ˆæˆ–è€…è¡°å‡å¾—å¾ˆæ…¢ï¼‰ã€‚æ•´ä¸ªç§¯åˆ†çš„å€¼ï¼Œå®Œå…¨ç”±è¿™ä¸€å°å—åŒºåŸŸä¸»å¯¼ã€‚

**ç¬¬ä¸‰æ­¥ï¼šå±€éƒ¨æ³°å‹’å±•å¼€ (Taylor Expansion)**

ä¸ºäº†æ›´ç²¾ç¡®ï¼Œæˆ‘ä»¬åœ¨ $x^*$ é™„è¿‘å¯¹ $E(x)$ åšæ³°å‹’å±•å¼€ï¼š
$$E(x) \approx E(x^*) + E'(x^*)(x-x^*) + \frac{1}{2}E''(x^*)(x-x^*)^2$$

å› ä¸º $x^*$ æ˜¯æå€¼ç‚¹ï¼Œä¸€é˜¶å¯¼æ•° $E'(x^*) = 0$ã€‚ä¸”å‡è®¾å®ƒæ˜¯æå°å€¼ï¼ŒäºŒé˜¶å¯¼æ•° $E''(x^*) = k > 0$ã€‚æ‰€ä»¥ï¼š
$$E(x) - E(x^*) \approx \frac{1}{2} k (x-x^*)^2$$
ä»£å…¥æˆ‘ä»¬çš„ç§¯åˆ†å¼ï¼ˆåªçœ‹é‚»åŸŸéƒ¨åˆ†ï¼‰ï¼š
$$\text{åˆ†æ¯} \approx \int_{x^*-\epsilon}^{x^*+\epsilon} e^{-\lambda \frac{1}{2} k (x-x^*)^2} \, dx$$

çœ‹ï¼è¿™å˜æˆäº†ä¸€ä¸ªæ ‡å‡†çš„é«˜æ–¯ç§¯åˆ† (Gaussian Integral)ã€‚å¦‚æœä½ è¿˜è®°å¾—é«˜æ–¯ç§¯åˆ†å…¬å¼ $\int e^{-ax^2} dx = \sqrt{\frac{\pi}{a}}$ï¼Œé‚£è¿™é‡Œ $a = \frac{\lambda k}{2}$ã€‚

æ‰€ä»¥åˆ†æ¯å¤§çº¦æ˜¯ï¼š
$$\text{åˆ†æ¯} \approx \sqrt{\frac{2\pi}{\lambda k}}$$

åŒç†ï¼Œåˆ†å­ç”±ä¸¤éƒ¨åˆ†ç»„æˆï¼š$x$ å’Œé«˜æ–¯åˆ†å¸ƒã€‚å› ä¸ºç§¯åˆ†èŒƒå›´éå¸¸å°ï¼ˆåœ¨ $x^*$ é™„è¿‘ï¼‰ï¼Œæˆ‘ä»¬å¯ä»¥æŠŠ $x$ è¿‘ä¼¼çœ‹ä½œå¸¸æ•° $x^*$ æå‡ºæ¥ï¼š
$$
\text{åˆ†å­} \approx \int_{x^*-\epsilon}^{x^*+\epsilon} x \cdot e^{-\lambda \frac{1}{2} k (x-x^*)^2} \, dx \approx x^* \cdot \underbrace{\int e^{-\dots} dx}_{\text{åˆ†æ¯çš„ç§¯åˆ†}}
$$
$$
\text{åˆ†å­} \approx x^* \cdot \sqrt{\frac{2\pi}{\lambda k}}
$$

**ç¬¬å››æ­¥ï¼šè§è¯å¥‡è¿¹çš„çº¦åˆ†**

ç°åœ¨æˆ‘ä»¬æŠŠåˆ†å­åˆ†æ¯é‡æ–°æ”¾åœ¨ä¸€èµ·ï¼š
$$\lim_{\lambda \to \infty} \langle x \rangle_\lambda \approx \frac{x^* \cdot \sqrt{\frac{2\pi}{\lambda k}}}{\sqrt{\frac{2\pi}{\lambda k}}}$$
é‚£å †å¤æ‚çš„æ ¹å·ã€$\pi$ã€äºŒé˜¶å¯¼æ•° $k$ã€ç”šè‡³ $\lambda$ æœ¬èº«ï¼Œå…¨éƒ¨åœ¨åˆ†å­åˆ†æ¯ä¸­æŠµæ¶ˆäº†ï¼æœ€åå‰©ä¸‹çš„åªæœ‰ï¼š
$$= x^*$$
